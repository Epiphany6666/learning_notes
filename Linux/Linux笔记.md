Linux笔记

1. 修改root密码：`sudo passwd root`

2. whereis 查找Linux系统里是否含有该工具

3. mkdir -p family/{father, mother}

4. 一般情况下，type命令被用于判断另外一个命令是否是内置命令，但是它实际上有更多的用法。

   1.判断一个名字当前是否是alias、keyword、function、builtin、file或者什么都不是：

   type ls 的输出是 ls 是 `ls --color=auto' 的别名

   type if 的输出是 if 是 shell 关键字

   type type 的输出是 type 是 shell 内嵌

   type frydsh 的输出是 bash: type: frydsh: 未找到

5. 主目录和根目录：

   > 根目录：就是相当于windows里面的c盘，是所有文件的根，用 **/** 表示；
   > 主目录（家目录）：就是根目录下面的home目录下，一般用 ~ 表示，也是/home/;此目录是拿来存放用户的。比如[Linux](https://so.csdn.net/so/search?q=Linux&spm=1001.2101.3001.7020)系统下有个用户lisi,他的主目录就是/home/lisi;

6. > *.bak / .bck 都是一个备份文件，为文件格式扩展名。*
   >
   > ![image-20231009153233591](.\img\image-20231009153233591.png)

7. gzip也可以压缩，压缩文件为.gz

8. ;（分号）：无论前面执不执行成功，后面都会执行

9. ubuntu修改密码：

   ```
   sudo passwd root
   ```

10. Ubuntu修改网络：

    vim /etc/netplan/01-network-manager-all.yaml

    重启：netplan apply



## 1.Linux导学

## 2.操作系统概述

**硬件和软件**

> 我们所熟知的计算机是由：硬件和软件所组成。
>
> 硬件：计算机系统中由电子，机械和光电元件等组成的各种物理装置的总称。
> 			硬件就是看得见摸得到的
>
> 软件：是用户和计算机硬件之间的接口和桥梁，用户通过软件与计算机进行交流。
>
> 而操作系统，就是软件的一类。
>
> 一个完整的计算机：
>
> ![image-20231006122919645](.\img\image-20231006122919645.png)

操作系统是计算机软件的一种，它主要负责操作计算机底层应用的软件（即最底层的软件）：

作为用户和计算机硬件之间的桥梁，调度和管理计算机硬件进行工作。

而计算机，如果没有操作系统，就是一堆无法使用的塑料而已。

> 当计算机拥有了操作系统，就相当于拥有了灵魂，操作系统可以：
>
> •调度CPU进行工作
>
> •调度内存进行工作
>
> •调度硬盘进行数据存储
>
> •调度网卡进行网络通讯
>
> •调度音响发出声音
>
> •调度打印机打印内容
>
> •......

![image-20231006123338471](.\img\image-20231006123338471.png)

**用户使用操作系统，操作系统安排硬件干活**

![image-20231006123311137](.\img\image-20231006123311137.png)

**常见操作系统**

> PC端：Windows、Linux、MacOS
>
> 移动端：Android、IOS、鸿蒙系统（华为的）

![image-20231006123400768](.\img\image-20231006123400768.png)

![image-20231006123416958](.\img\image-20231006123416958.png)

> **不管是PC操作系统**
>
> **还是移动操作系统**
>
> **其功能都是：调度硬件进行工作**
>
> **充当用户和硬件之间的桥梁**

## 3.Linux初始

Linux创始人: 林纳斯 托瓦兹

Linux 诞生于1991年，作者上大学期间

![image-20231129200221713](.\img\image-20231129200221713.png)

因为创始人在上大学期间经常需要浏览新闻和处理邮件，发现现有的操作系统不好用, 于是他决心自己写一个保护模式下的操作系统，这就是Linux的原型， 当时他21岁，后来经过全世界网友的支持, 现在能够兼容多种硬件，成为最为流行的服务器操作系统之一。

![image-20231129201725877](.\img\image-20231129201725877.png)

Linux是一套免费使用和自由传播的类Unix操作系统，是一个基于POSIX和UNIX的多用户多任务、支持多线程和多CPU的操作系统。Linux能运行主要的UNIX工具软件应用程序和网络协议。它支持32位和64位硬件。Linux继承了Unix以网络为核心的设计思想，是一个性能稳定的多用户网络操作系统

![image-20231006123629082](.\img\image-20231006123629082.png)

> 这只企鹅是有名字的：Tux，Tux中文翻译为晚礼服，看起来是穿着晚礼服的企鹅

![image-20231006123641991](.\img\image-20231006123641991.png)

**Linux内核**

> Linux系统的组成如下：
>
> •Linux系统内核
>
> •系统级应用程序
>
> 两部分组成。
>
> •内核提供系统最核心的功能，如：调度CPU、调度内存、调度文件系统、调度网络通讯、调度IO等。
>
> •系统级应用程序，可以理解为出厂自带程序，可供用户快速上手操作系统，如：
>
>  文件管理器、任务管理器、图片查看、音乐播放等。
>
> •比如，播放音乐，无论用户使用自带音乐播放器或是自行安装的第三方播放器
>
> •均是由播放器程序，调用内核提供的相关功能，由内核调度CPU解码、音响发声等。
>
> ![image-20231006123738838](.\img\image-20231006123738838.png)
>
> ![image-20231006123754121](.\img\image-20231006123754121.png)

可以看出，内核是Linux操作系统最核心的所在，系统级应用程序只是锦上添花。

Linux内核是免费开源的，任何人都可以下载内核源码并查看且修改。

可以通过：https://www.kernel.org  去下载Linux内核

![image-20231006123851851](.\img\image-20231006123851851.png)

**Linux****发行版**

> 内核是免费、开源的，这也就代表了：
>
> •任何人都可以获得并修改内核，并且自行集成系统级程序
>
> •提供了内核+系统级程序的完整封装，称之为Linux发行版

![image-20231006123923359](.\img\image-20231006123923359.png)

![image-20231006123926055](.\img\image-20231006123926055.png)

> 基于同一个内核，同一个版本的Linux kernel在外围添加上不同的shell以及不同的应用程序，这样就构建出了不同的Linux整体操作系统，这样的操作系统，我们统称叫GNU/Linux
>
> 所以一般来说，我们提到的完整的、具体的、可以直接上手使用的Linux，往往就是GNU/Linux，往往我们使用的是它的发行版本。
>
> 狭义的Linux就是Linux kernel
>
> 如果我们要给自己的电脑安装操作系统，安装的应该是广义的GNU/Linux

![image-20231129203440032](.\img\image-20231129203440032.png)

> 任何人都可以封装Linux，目前市面上由非常多的Linux发行版，常用的、知名的如下：
>
> 本次课程，我们将基于：
>
> •**主要**基于CentOS操作系统进行讲解
>
> •**辅助**讲解Ubuntu系统的相关知识

![image-20231006124005541](.\img\image-20231006124005541.png)

> Red Hat：桌面可能不够华丽，但是性能很强悍，很稳定

![image-20231129204257086](.\img\image-20231129204257086.png)

>  **不同的发行版：**
>
>  •**基础命令100%是相同的（课程讲解内容）**
>
>  •**部分操作不同（如软件安装）**
>
>  **同学们不用纠结选择什么发行版**
>
>  **不论用什么发行版，都是Linux，学到的东西都是通用的。**

![image-20231129204614380](.\img\image-20231129204614380.png)

# CentOS下载

CentOS官网：https://www.centos.org/

![image-20231129205214891](.\img\image-20231129205214891.png)

![image-20231129205247790](.\img\image-20231129205247790.png)

![image-20231129205345165](.\img\image-20231129205345165.png)

![image-20231129205410286](.\img\image-20231129205410286.png)

随便点击一个

![image-20231129205551164](.\img\image-20231129205551164.png)

![image-20231129210518632](.\img\image-20231129210518632.png)

> CentOS到2024.6就不再维护了，官方的计划就使用CentOS Stream去取代。
>
> Stream可能会一直不断更新。

> 老师的ios文件是下载在Tools/Images文件夹中

## 4.虚拟机介绍

> 学习Linux系统，就需要有一个可用的Linux系统。
>
> 如何获得？将自己的电脑重装系统为Linux？
>
> NoNo。这不现实，因为Linux系统并不适合日常办公使用。
>
> 我们需要借助虚拟机来获得可用的Linux系统环境进行学习。

**虚拟机**

那么，什么是虚拟机呢？

![image-20231006124300179](.\img\image-20231006124300179.png)

借助虚拟化技术，我们可以在系统中，通过软件：模拟计算机硬件，并给虚拟硬件安装真实的操作系统。

这样，就可以在电脑中，虚拟出一个完整的电脑，以供我们学习Linux系统。

![image-20231006124329519](.\img\image-20231006124329519.png)

## 5.VMWare Workstation虚拟化软件

> 在Windows环境下，它其实就自带了Linux系统：WSL（Windows Subsystem for Linux）
>
> 这个系统有限制：首先需要在Linux环境下，其次至少要win10以上，而且在配置过程中有很多坑。

>  通过虚拟化技术，可以虚拟出计算机的硬件，那么如何虚拟呢？
>
> 我们可以通过提供虚拟化的软件来获得虚拟机。或者可以使用docker

![image-20231006124532974](.\img\image-20231006124532974.png)

![image-20231006124544210](.\img\image-20231006124544210.png)

![image-20231006124552684](.\img\image-20231006124552684.png)

**VMware WorkStation**

课程选用VMware WorkStation软件来提供虚拟机。

下载地址： https://www.vmware.com/cn/products/workstation-pro.html

![image-20231006124619548](.\img\image-20231006124619548.png)

![image-20231006124630471](.\img\image-20231006124630471.png)

![image-20231006124726675](.\img\image-20231006124726675.png)

> 这里可以新建一层目录，叫做：vmware

![image-20231006124705779](.\img\image-20231006124705779.png)

![image-20231006124749058](.\img\image-20231006124749058.png)

![image-20231006124805739](.\img\image-20231006124805739.png)

![image-20231006124823296](.\img\image-20231006124823296.png)

![image-20231006124835180](.\img\image-20231006124835180.png)

> 软件安装完成后，验证一下网络适配器是否正常配置。
>
> **或者通过快捷键：win + r**
>
> **输入ncpa.cpl回车即可打开**

![image-20231006124934641](.\img\image-20231006124934641.png)

![image-20231006124956602](.\img\image-20231006124956602.png)

> 检查是否存在以下两个，如果没有这两个的话，虚拟机是无法上网的。原因是安装出问题了。

![image-20231006125036218](.\img\image-20231006125036218.png)

## 6.VMWare Workstation中安装CentOS7 Linux操作系统

**下载CentOS操作系统**

> 首先，我们需要下载操作系统的安装文件，本次使用CentOS7.6版本进行学习：
>
> https://vault.centos.org/7.6.1810/isos/x86_64/  (最后的/不要漏掉）
>
> ![image-20231006125510548](.\img\image-20231006125510548.png)
>
> •或者直接使用如下链接下载：
>
> https://vault.centos.org/7.6.1810/isos/x86_64/CentOS-7-x86_64-DVD-1810.iso
>
> •或者从课程资料中获取安装包

**在VMware中安装CentOS操作系统**

按照步骤创建虚拟机：

> 选择高级会有很多默认设置，但如果是刚接触的就选择典型即可

![image-20231006130413057](.\img\image-20231006130413057.png)

![image-20231006130539894](.\img\image-20231006130539894.png)

![image-20231006130743049](.\img\image-20231006130743049.png)

![image-20231006130806735](.\img\image-20231006130806735.png)

![image-20231006130849123](.\img\image-20231006130849123.png)

> 如果不想使用推荐配置的话，可以点击自定义硬件
>
> 内存一般1G就够了
>
> 处理器1核也够了
>
> 总的来说默认的就够了

![image-20231006130903825](.\img\image-20231006130903825.png)

# 更加细节的创建虚拟机

![image-20231129213014451](.\img\image-20231129213014451.png)

我们这里VMWare选用软件的版本是17，所以直接选择默认即可，如果是苹果电脑的话，应该选择Fusion

![image-20231129213145879](.\img\image-20231129213145879.png)

> 这里选择少受安装操作系统，我们就像安装一个真实的机器一样，先把这个机器存起来，之后再在空白的硬盘上去安装操作系统

![image-20231129213308704](.\img\image-20231129213308704.png)

> 这里选择什么样的版本其实不是特别重要，因为VMWare主要想要通过我们所选择的版本来分配什么样的硬件资源。

![image-20231129213408963](.\img\image-20231129213408963.png)

![image-20231130131509547](.\img\image-20231130131509547.png)

> 这个时候就正式开始我们DIY电脑的时候了
>
> 物理机又叫做主机，都指的是自己的电脑，通过自己创建出来的电脑叫虚拟机。
>
> 这里对处理器配置，相当于是向自己电脑借一些过来
>
> 先看看我们自己电脑上的：
>
> > 插槽1：主板上给CPU只有一个插槽，即给CPU的个数只有一个
> >
> > 内核：当前CPU里独立出来的内部处理核心到底有几个，这个是真正提升计算机性能的关键
> >
> > 逻辑处理器：
> > 超线程（HT）：当前的一个内核可以扩展出两个逻辑核心来，eg：2核四线程，说的就是当前内核的数量，以及扩展出的逻辑处理器数量
>
> ![image-20231129213924803](.\img\image-20231129213924803.png)

处理器数量：即CPU的数量，每一个CPU又可以有几个内核，每一个内核又可以扩展出两个逻辑内核

虚拟的话我可以给它配置两个处理器，反正是虚拟的，每个CPU是4核的。但如果内核超出自己主机的内核，就会失败。

![image-20231130131542890](.\img\image-20231130131542890.png)

  内存大小有一定要求，建议 4g，不能给太多，后期会有多台虚拟机同时启动。  

![image-20231130131616964](.\img\image-20231130131616964.png)

> 桥接：假装把虚拟机扯出来了，把主机当做一座桥连接到外面的系统，此时主机和虚拟机是完全平等的
>
> NAT：虚拟机是完全依托于主机来跟外部进行网络连接的

![image-20231130131656815](.\img\image-20231130131656815.png)

  2）没有 VMware 之前物理机的网络适配器信息（每个人不同，我只有 3 个）  

![image-20231130131833609](.\img\image-20231130131833609.png)

  3）安装 VMware 之后物理机的网络适配器信息（会多两个 vmnet1 和 vmnet8）

![image-20231130131848533](.\img\image-20231130131848533.png)

  注：vmnet8 是虚拟机使用 NAT 模式上网的网卡  

I/O控制器直接选择默认的即可

![image-20231129215204661](.\img\image-20231129215204661.png)

磁盘类型选择默认

![image-20231129215227039](.\img\image-20231129215227039.png)

默认

![image-20231130131956247](.\img\image-20231130131956247.png)

![image-20231129215329094](.\img\image-20231129215329094.png)

磁盘文件直接使用默认的即可，它用的就是当前的主机名

![image-20231130132033229](.\img\image-20231130132033229.png)

![image-20231130132045540](.\img\image-20231130132045540.png)

**安装操作系统**

VMWare如果想要启动一个虚拟机，主机必须支持虚拟化技术，Intel处理器，这个技术叫做：VT-x

> 如果没有启动，就必须到BIOS里面将其开启
>
> 搜索：启动BIOS虚拟化设置/启动CPU虚拟化
>
>   （3）如果发现 bios 虚拟化没有开启怎么办，重启电脑，在加载界面时按 f1-f10,或者电  
>
>   脑旁边一个小洞，具体怎么进入得去查一下（按照自己电脑的型号去查）  
>
>   （4）修改虚拟化为开启（thinkpad 为例）找到 security 里面的 VT 并改成 enabled  
>
>   注：如果虚拟化没有开启报的是以下错误。  
>
> ![image-20231130132154163](.\img\image-20231130132154163.png)

![image-20231129215608151](.\img\image-20231129215608151.png)

安装操作系统在光驱里安装

双击：

![image-20231129215816417](.\img\image-20231129215816417.png)

选择centos镜像

![image-20231129215901227](.\img\image-20231129215901227.png)

点击开启虚拟机做系统安装

![image-20231129215931206](.\img\image-20231129215931206.png)

**在VMware中安装CentOS操作系统**

![image-20231130132231131](.\img\image-20231130132231131.png)

  耐心等待它的安装。  

![image-20231130132246529](.\img\image-20231130132246529.png)

  会自动跳转下面的界面。  

> 如果是生产中的服务器中文可能会出现各种不兼容或者处理复杂的状况，使用英文是最好的方式

![image-20231130132311540](.\img\image-20231130132311540.png)

**需要定制化的内容**  

按照编号依次点击。

![image-20231130132507856](.\img\image-20231130132507856.png)

  1）调整时间差  

> 上海：标准东八区

![image-20231130132531743](.\img\image-20231130132531743.png)

  2）安装 GHOME（图形化界面的方式）注意图上标注的点击顺序  

> KDE：很多比较华丽的桌面都是基于KDE构建出来的，像Ubuntu、Suse
>
> 但是我们这里希望有一个桌面环境，但是又不需要太华丽，所以我们勾选GNOME
>
> 一般会勾选上开发工具，但是我们先不选，以后用到再装

![image-20231130132605132](.\img\image-20231130132605132.png)

  3）配置磁盘分区  

分区在装操作系统之前就需要分好

> 在windows电脑里一般会有盘符，但是在Linux里面是没有盘符概念的
> 但其实它只是逻辑上把它隔离开了，物理上其实还是一块硬盘
>
> A、B盘不是硬盘的盘符，而是软盘的盘符。但电脑现在都没有软区了
>
> Linux里面全部使用文件管理。
>
> 万物皆文件。
>
> 如果想对Linux做分区，我们可以专门制定一下，这个指定操作叫：挂载
> 即：把某一个区域直接挂载到某一个目录下面去，这个目录就成为了它的挂载点。
> 以后我访问到/C这个目录下边的时候，就相当于访问了这一片空间
>
> 在Linux新加一个硬盘后，它会先格式化，然后把这个硬盘做分区，然后挂载到对应的目录
>
> Linux只是使用一个非常瘪平化的目录结构表示了我们在windows里面的盘符。

![image-20231130132641395](.\img\image-20231130132641395.png)

  （1）手动添加分区  

![image-20231130132700592](.\img\image-20231130132700592.png)

  （2） 添加 boot 区（引导分区） 给上 1G 容量后点击添加挂载点  

> Linux里面目录结构是有专门规定的
>
> 需要靠boot启动柜

![image-20231130132716501](.\img\image-20231130132716501.png)

> Linux里面最金典的系统格式是：ext4，这就是所谓的：第四代扩展文件系统，整个文件系统的容量可以达到1EB，1024G是一个T，1024个T是一个E。单个文件容量可以达到16TB。centOS6默认选择的就是ext4。但我们现在使用的是xfs。
>
> xfs是一个新的高性能日志文件系统，特别擅长处理大文件。64位系统里最大能支持到8EB的文件系统。而且它的性能和可扩展性比ext4都要更强。

文件系统选择默认的即可

![image-20231130140103158](.\img\image-20231130140103158.png)

  （3）添加 swap 交换分区  

> 1. 注意：没有斜杠
> 2. 交换分区就是我们需要单独的设置硬盘里的一片区域。我们需要拿出单独的区域来作为扩展的内存。可以理解为虚拟内存，后补源
> 3. 一般给实际内存的一倍或者两倍即可

![](.\img\image-20231130132748775.png)

![image-20231130132758463](.\img\image-20231130132758463.png)

> 它的文件系统格式必须是swap类型，因为Linux里面的swap分区系统模式，对内存的交换专门做了优化
>
> 如果有高性能硬盘的话，推荐把高速的硬盘作为一个分区，然后挂载到swap上面

![image-20231130132819171](.\img\image-20231130132819171.png)

  （4）配置根(/)目录  

> /boot其实也是在/目录结构下，但是我们把它作为额外的一个分区拿出来。

![image-20231130132836818](.\img\image-20231130132836818.png)

  根目录作为存储使用，将剩下的空间都给他（50 - 4 - 1）= 45  

![image-20231130132858088](.\img\image-20231130132858088.png)

  3 个分区都配置完毕过后可以点击完成。  

> 文件系统也是默认的xfs

![image-20231130140928145](.\img\image-20231130140928145.png)

  （5）分区配置完毕，点击接受更改  

![image-20231130133001765](.\img\image-20231130133001765.png)

  4）关闭 kdump 本身虚拟机内存就不够，他会吃掉一部分内存，我们尽量省一点  

![image-20231130141120744](.\img\image-20231130141120744.png)

![image-20231130133032325](.\img\image-20231130133032325.png)

  5）修改主机名  

![image-20231130133052876](.\img\image-20231130133052876.png)

  6）是否打开安全协议（开启与否都可以）  

![image-20231130133115577](.\img\image-20231130133115577.png)

  7）开始安装  

![image-20231130133131666](.\img\image-20231130133131666.png)

  8）安装时间比较长 大概需要 10 几分钟（设置 root 用户密码，一定要设置）  

![image-20231130133150896](.\img\image-20231130133150896.png)

  密码设置成什么自己决定，但是不要忘，建议使用（123456）  

![image-20231130133207095](.\img\image-20231130133207095.png)

同时也可以创建一个普通的用户

> 因为root用户太危险了，有所有的权限

![image-20231130141343826](.\img\image-20231130141343826.png)

**虚拟机的使用引导界面**  

  1） 安装完成 重启虚拟机  

![image-20231130133303897](.\img\image-20231130133303897.png)

  2）进入引导界面(以下内容就按照图片走，就不做过多解释)  

![image-20231130133320320](.\img\image-20231130133320320.png)





![image-20231006131448907](.\img\image-20231006131448907.png)

> 默认是使用普通用户进行登录，如果想使用root用户进行登录，可以选择下面的：未列出
>
> 用户名选择root

![image-20231006131459176](.\img\image-20231006131459176.png)

点击用户名：

![image-20231006131526520](.\img\image-20231006131526520.png)

输入密码：

![image-20231006131542403](.\img\image-20231006131542403.png)

体验Linux的快乐吧。

![image-20231006131609554](.\img\image-20231006131609554.png)



> super：就是windows
>
> super + 上：将窗口最大化
>
> super + 下：恢复窗口
>
> super + 右：向右的一个分屏
>
> super +  左：向左的一个分屏



## 8.远程连接Linux系统

最简单的远程连接方式就是ssh

**图形化、命令行**

> 对于操作系统的使用，有2种使用形式：
>
> •图形化页面使用操作系统
>
> •以命令的形式使用操作系统
>
> 不论是Windows还是Linux亦或是MacOS系统，都是支持这两种使用形式。
>
> •图形化：使用操作系统提供的图形化页面，以获得**图形化反馈**的形式去使用操作系统。
>
> •命令行：使用操作系统提供的各类命令，以获得**字符反馈**的形式去使用操作系统。

**Windows系统的图形化和命令行**

![image-20231006131850580](.\img\image-20231006131850580.png)

![image-20231006131904459](.\img\image-20231006131904459.png)

**Linux****系统的图形化和命令行**

![image-20231006131947824](.\img\image-20231006131947824.png)

![image-20231006132000050](.\img\image-20231006132000050.png)

**使用命令行学习****Linux****系统**

> 尽管图形化是大多数人使用计算机的第一选择，但是在Linux操作系统上，这个选择被反转了。
>
> 无论是企业开发亦或是个人开发，使用Linux操作系统，多数都是使用的：**命令行**。
>
> 这是因为：
>
> •Linux从诞生至今，在图形化页面的优化上，并未重点发力。所以Linux操作系统的图形化页面：不好用、不稳定。
>
> •在开发中，使用命令行形式，效率更高，更加直观，并且资源占用低，程序运行更稳定。
>
> 所以，后续的课程学习中，我们：
>
> •除了在少数需要做对照讲解的情况下会使用图形化页面
>
> •其余都会以命令行的形式去讲解Linux操作系统的使用

**FinalShell**

> 既然决定使用命令行去学习Linux操作系统，那么就必须丰富一下工具的使用。
>
> 我们使用VMware可以得到Linux虚拟机，但是在VMware中操作Linux的命令行页面不太方便，主要是：
>
> •内容的复制、粘贴跨越VMware不方便
>
> •文件的上传、下载跨越VMware不方便
>
> •也就是和Linux系统的各类交互，跨越VMware不方便
>
> 我们可以通过第三方软件，FinalShell，远程连接到Linux操作系统之上。
>
> 并通过FinalShell去操作Linux系统。
>
> 这样各类操作都会十分的方便。

FinalShell的下载地址为：

Windows: 

http://www.hostbuf.com/downloads/finalshell_install.exe

Mac: 

http://www.hostbuf.com/downloads/finalshell_install.pkg

下载完成后双击打开安装。

**Windows系统安装FinalShell**

按照提示一直下一步即可安装完成。

![image-20231006132151049](.\img\image-20231006132151049.png)

![image-20231006132205834](.\img\image-20231006132205834.png)

![image-20231006132217533](.\img\image-20231006132217533.png)

![image-20231006132229294](.\img\image-20231006132229294.png)

> 此时这里需要下载一个依赖软件

![image-20231006132243039](.\img\image-20231006132243039.png)

![image-20231006132258553](.\img\image-20231006132258553.png)

![image-20231006132314000](.\img\image-20231006132314000.png)

![image-20231006132330961](.\img\image-20231006132330961.png)

![image-20231006132345226](.\img\image-20231006132345226.png)

![image-20231006132356348](.\img\image-20231006132356348.png)

![image-20231006132406678](.\img\image-20231006132406678.png)

> 安装完成后，它会自动在浏览器把官方文件打开，同时自动打开finalShell

**连接到Linux系统**

> •在Linux操作系统中，桌面空白右键点击：open in terminal

![image-20231006133525604](.\img\image-20231006133525604.png)

> •输入ifconfig，即可看到IP地址

![image-20231006133535697](.\img\image-20231006133535697.png)

打开Finshell软件，配置到Linux系统的连接

![image-20231006133613471](.\img\image-20231006133613471.png)

![image-20231006133624572](.\img\image-20231006133624572.png)

按图示配置连接，并点击确定

![image-20231006133643934](.\img\image-20231006133643934.png)

打开连接管理器

![image-20231006133715595](.\img\image-20231006133715595.png)

双击刚刚配置好的连接

![image-20231006133733209](.\img\image-20231006133733209.png)

点击接受并保存

![image-20231006133753008](.\img\image-20231006133753008.png)

如图连接成功

![image-20231006133807157](.\img\image-20231006133807157.png)

> **注意：**
>
> **Linux虚拟机如果重启，有可能，发生IP改变**
>
> **如果改变IP需要在FinalShell中修改连接的IP地址**
>
> **后面我们会讲解如何固定IP地址不发生改变**
>
> 如果更改了，需要重新设置ip
>
> ![image-20231006151510514](.\img\image-20231006151510514.png)

上传下载文件也可以使用scp

## 9.Win10配置WSL（Ubuntu）环境

> Windows Subsystem for Linux

发行版

![image-20231006134634864](.\img\image-20231006134634864.png)

WSL章节仅仅作为扩展章节，并不是学习重点。

主要目的是扩展同学们的知识面，可以更简单、更轻松的获得Linux操作系统环境。

同时基于WSL我们可以得到Ubuntu发行版环境，可以拓展除CentOS发行版之外的额外体验和知识。

课程后续的学习中，依旧是以VMware虚拟机中创建的CentOS操作系统环境为主。

部分内容会以WSL中得到的Ubuntu环境为辅（非重点知识、可跳过）

**为什么要用WSL**

WSL作为Windows10系统带来的全新特性，正在逐步颠覆开发人员既有的选择。

•传统方式获取Linux操作系统环境，是安装完整的虚拟机，如VMware

•使用WSL，可以以非常轻量化的方式，得到Linux系统环境

目前，开发者正在逐步抛弃以虚拟机的形式获取Linux系统环境，而在逐步拥抱WSL环境。

所以，课程也紧跟当下趋势，为同学们讲解如何使用WSL，简单、快捷的获得Linux系统环境。

所以，为什么要用WSL，其实很简单：

•开发人员都在用，大家都用的，我们也要学习

•实在是太方便了，简单、好用、轻量化、省内存

> 但不管怎么样，安装完整的虚拟机依旧是主流，WSL是辅助的手段

**什么是WSL**

> WSL：Windows Subsystem for Linux，是用于Windows系统之上的Linux子系统。
>
> 作用很简单，可以在Windows系统中获得Linux系统环境，并完全直连计算机硬件，无需通过虚拟机虚拟硬件。
>
> 简而言之：
>
> Windows10的WSL功能，可以无需单独虚拟一套硬件设备
>
> 就可以直接使用主机的物理硬件，构建Linux操作系统
>
> 并不会影响Windows系统本身的运行

![image-20231006134937775](.\img\image-20231006134937775.png)

•WSL是Windows10自带功能，需要开启，无需下载

win10：

![image-20231006135102990](.\img\image-20231006135102990.png)

win11：

![image-20231006135226184](.\img\image-20231006135226184.png)

![image-20231006135246766](.\img\image-20231006135246766.png)

将红框地方打上勾即可！然后点击确定

![image-20231006135313699](.\img\image-20231006135313699.png)

**WSL部署**

> 点击确定后会进行部署
>
> 最后重启即可。

![image-20231006135456196](.\img\image-20231006135456196.png)

![image-20231006135507247](.\img\image-20231006135507247.png)

•打开Windows应用商店

![image-20231006135530449](.\img\image-20231006135530449.png)

•搜索Ubuntu

![image-20231006135544125](.\img\image-20231006135544125.png)

![image-20231006135610211](.\img\image-20231006135610211.png)

![image-20231006135620554](.\img\image-20231006135620554.png)

点击启动

![image-20231006135635776](.\img\image-20231006135635776.png)

输入用户名用以创建一个用户：

![image-20231006135649896](.\img\image-20231006135649896.png)

输入两次密码确认（注意，输入密码没有反馈，不用理会，正常输入即可）

![image-20231006135710092](.\img\image-20231006135710092.png)

> 如果打开ubuntu会出现输入任何键退出的错误，就是电脑的window的hyper-V功能没开启，打开就行了。
>
> <img src=".\img\image-20231006142319064.png" alt="image-20231006142319064" style="zoom:50%;" />

至此，得到了一个可用的Ubuntu操作系统环境

![image-20231006135815917](.\img\image-20231006135815917.png)

**安装****Windows Terminal****软件**

Ubuntu自带的终端窗口软件不太好用，我们可以使用微软推出的：Windows Terminal软件

在应用商店中搜索terminal关键字，找到Windows Terminal软件下载并安装

![image-20231006135844614](.\img\image-20231006135844614.png)

**安装****Windows Terminal****软件**

![image-20231006135908030](.\img\image-20231006135908030.png)

![image-20231006135920022](.\img\image-20231006135920022.png)

再次打开Windows Terminal软件，即默认使用Ubuntu系统了（WSL）

![image-20231006135938376](F:\BaiduSyncdisk\other\Linux\img\image-20231006135938376.png)

> 首先：
>
> •无论是基于VMware Workstation软件构建的CentOS Linux环境
>
> •或者是WSL获得的Ubuntu Linux环境
>
> •均满足课程学习需求（不管是CentOS还是Ubuntu，命令是通用的）
>
> 
>
> 课程推荐大家使用VMware WorkStation内构建的CentOS Linux环境进行学习
>
> 因为WSL虽然好用，但是是直连我们自己的电脑的，如果误操作可能带来重要文件的丢失甚至损坏系统。
>
> 所以，在虚拟机内操作最好，虚拟机内怎么折腾都行，不会影响自己的电脑的。
>
> WSL作为一个备用，等同学们熟练Linux的使用后，在去尝试重度使用。

## 10.虚拟机的快照

在学习阶段我们无法避免的可能损坏Linux操作系统。

如果损坏的话，重新安装一个Linux操作系统就会十分麻烦。

VMware虚拟机（Workstation和Funsion）支持为虚拟机制作快照。

通过快照将当前虚拟机的状态保存下来，在以后可以通过快照恢复虚拟机到保存的状态。

![image-20231006150111293](.\img\image-20231006150111293.png)

> 这里建议关机保存快照，如果不关机，可能需要很久

![image-20231006150203723](.\img\image-20231006150203723.png)

![image-20231006150255300](.\img\image-20231006150255300.png)

> 给它一个名字，描述可填可不填

![image-20231006150332815](.\img\image-20231006150332815.png)

恢复快照

> 恢复快照的时候同样建议把虚拟机关闭

![image-20231006150308036](.\img\image-20231006150308036.png)

![image-20231006150346849](.\img\image-20231006150346849.png)

> 1. 快照有什么作用？
>
>    快照可以保存虚拟机的状态， 当虚拟机出现问题的时候， 可以通过预先制作的快照恢复到制作时候的状态， 用作备份用。
>
> 2. VMware Workstation 和 VMware Fusion 都支持制作快照去使用

## 11.Linux目录结构

Linux的目录结构是一个树型结构

Windows 系统可以拥有多个盘符, 如 C盘、D盘、E盘

Linux没有盘符这个概念, 只有一个根目录 /, 所有文件都在它下面

![image-20231006150932411](.\img\image-20231006150932411.png)

![image-20231006150948679](.\img\image-20231006150948679.png)

![image-20231006150958848](.\img\image-20231006150958848.png)

目录结构简介：

Linux里所有的硬件也是通过文件来管理的。

Linux里是斜杠/，而windows里是反斜杠\，windows下的路径其实是有问题的，因为底层字符编码的时候，ASCII本身用来表示转义字符的，如果要表示一个斜杠，就需要再写一个\，这一样就很麻烦

- /bin

  Binary的缩写，这个目录存放着最经常使用的命令

  > 这个小箭头表示，这个bin目录其实不是存放在这个根目录下面的，它的实际逻辑位置

  <img src=".\img\image-20231201141841636.png" alt="image-20231201141841636" style="zoom:50%;" />

  它本身是一个文件夹的链接，指向的是usr/bin

  ![image-20231201142004524](.\img\image-20231201142004524.png)

- /sbin

  s是Super User的意思，这里存放的是系统管理员使用的系统管理工具

- /lib

  Library。系统开机所需要最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。

  C盘中的Windows/System32里面就有非常多的dll文件，很多都是系统必要的。

- /lib64

  一些比较特殊的库文件。有些应用程序所需要的共享库也会放在这里。

  像windows里的System和System32一样。

- /usr

  这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于windows里的Program Files

- /local

  用户本地的应用程序相关的文件数据

- /boot

  里面存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件，自己的安装别放这里。

  给的空间100M -  500M就够了

- dev

  类似于windows的设备管理器，把所有的硬件用文件的形式存储。

- /etc

  所有的系统管理所需要的配置文件和子目录

- /home

  存放**普通用户**的主目录，在Linux中每个用户都有一个自己的目录，一般该目录是以用户的账号命名的。

- /root

  该目录为系统管理员，也称作超级权限者的用户主目录。

- /opt

  optional的缩写，即：可选目录。

  这是给主机额外安装软件所摆放的目录。比如你安装一个mysql数据库，则就可以放到这个目录下。默认是空的。

- media(CentOS6)

  - Linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，Linux会把识别的设备挂载到这个目录下。
  - CentOS7迁移到/run/media

- /mnt

  系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将外部的存储挂载在/mnt/上，然后进入该目录就可以查看里面的内容了。

- /proc

  process：进程

  这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。

  （我们把分区，挂载点都配置好后，就不考虑它具体存放在哪，只要了解它逻辑结构就行了，所以有时候会把Linux的这种目录叫做虚拟目录，因为它并不是真正意义上分区文件的存放方式）

- /run

  跟/proc有点像，但是又不太一样。

  运行目录存放的就是当前系统运行以来的所有实时信息。它只是一个临时的文件系统，重启之后它就被干掉了。

- /srv

  service缩写，该目录存放一些服务启动之后需要提取的数据。

- /sys

  system的缩写，存放的是跟系统硬件相关的文件。

  这是Linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统sysfs。

- /tmp

  这个目录是用来存放一些临时文件的。

  当磁盘空间不够的时候，往往回来清理这个目录。

- /var

  variable（变量）

  这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。

- /lost + found

  这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。



**Linux路径的描述方式**

•在Linux系统中，路径之间的层级关系，使用：/ 来表示

•在Windows系统中，路径之间的层级关系，使用： \ 来表示

> **D:\data\work\hello.txt**
>
> **注意：**
>
> •**D:表示D盘**
>
> •**\表示层级关系**

![image-20231006151043709](.\img\image-20231006151043709.png)

> **/usr/local/hello.txt**
>
> **注意：**
>
> •**开头的/表示根目录**
>
> •**后面的/表示层级关系**

![image-20231006151205756](.\img\image-20231006151205756.png)

## 12.Linux命令基础

命令行、命令和终端

![](.\img\命令行、命令和终端.png)

**Linux命令基础格式**

> 无论是什么命令，用于什么用途，在Linux中，命令有其通用的格式：
>
> ![image-20231006153744307](.\img\image-20231006153744307.png)
>
> •command： 命令本身
>
> •-options：[可选，非必填]命令的一些选项，可以通过选项控制命令的行为细节
>
> •parameter：[可选，非必填]命令的参数，多数用于命令的指向目标等
>
> 语法中的[]，表示可选的意思
>
> 下面，让我们学习第一个Linux命令：ls命令
>
> 并通过它，去理解命令的基础格式

## 13.ls命令入门

list

ls命令的作用是列出目录下的内容，语法细节如下：

![image-20231006154023742](.\img\image-20231006154023742.png)

•-a -l -h 是可选的选项

•Linux路径是此命令可选的参数

当不使用选项和参数，直接使用ls命令本体，表示：以平铺形式，列出当前工作目录下的内容

![image-20231006154053743](.\img\image-20231006154053743.png)

**HOME目录和工作目录**

> Linux命令行在执行命令的时候，需要一个工作目录，打开命令行程序（终端）默认设置工作目录在用户的HOME目录。

直接输入ls命令，表示列出当前工作目录下的内容，当前工作目录是？

Linux系统的命令行终端，在启动的时候，默认会加载:

•**当前登录用户的HOME目录作为当前工作目录**，所以ls命令列出的是HOME目录的内容

•HOME目录：每个Linux操作用户在Linux系统的个人账户目录，路径在：/home/用户名

•如，图中的Linux用户是itheima，其HOME目录是：/home/itheima

•Windows系统和Linux系统，均设有用户的HOME目录，如图：

![image-20231006154203007](.\img\image-20231006154203007.png)

![image-20231006154149570](.\img\image-20231006154149570.png)

## 14.ls命令的参数和选项

![image-20231006154620259](.\img\image-20231006154620259.png)

•当ls不使用参数，表示列出：当前工作目录的内容，即用户的HOME目录

•当使用参数，ls命令的参数表示：指定一个Linux路径，列出指定路径的内容

如：

![image-20231006154642060](.\img\image-20231006154642060.png)

•-a选项，表示：all的意思，即列出全部文件（包含隐藏的文件/文件夹）

![image-20231006154742865](.\img\image-20231006154742865.png)

•图中以.开头的，表示是Linux系统的隐藏文件/文件夹（只要以.开头，就能自动隐藏）

•只有通过-a选项，才能看到这些隐藏的文件/文件夹

•-l选项，表示：以列表（竖向排列）的形式展示内容，并展示更多信息

![image-20231006154807383](.\img\image-20231006154807383.png)

**-l选项**其实和图形化中，文件夹以列表形式排列是一个意思

语法中的选项是可以组合使用的，比如学习的-a和-l可以组合应用。

写法：

•ls -l -a

•ls -la

•ls -al

上述三种写法，都是一样的，表示同时应用-l和-a的功能

![image-20231006154841641](.\img\image-20231006154841641.png)

除了选项本身可以组合以外，选项和参数也可以一起使用。

![image-20231006154947220](.\img\image-20231006154947220.png)

•-h 表示以易于阅读的形式，列出文件大小，如K、M、G
 l会显示出大小，但是不会显示出单位

•-h选项必须要搭配 -l 一起使用

![image-20231006155012119](.\img\image-20231006155012119.png)

## 15.cd-pwd命令

**cd** **切换工作目录**

> 当Linux终端（命令行）打开的时候，会默认以用户的HOME目录作为当前的工作目录
>
> 我们可以通过cd命令，更改当前所在的工作目录。
>
> cd命令来自英文：Change Directory
>
> 语法：
>
> •cd命令无需选项，只有参数，表示要切换到哪个目录下
>
> •cd命令直接执行，不写参数，表示回到用户的HOME目录
>
> ~表示家目录
>
> /表示根目录
>
> ![image-20231006155433788](.\img\image-20231006155433788.png)

![image-20231006155218384](.\img\image-20231006155218384.png)

**pwd** **查看当前工作目录**

> 通过ls来验证当前的工作目录，其实是不恰当的。
>
> 我们可以通过pwd命令，来查看当前所在的工作目录。
>
> pwd命令来自：Print Work Directory
>
> 语法：
>
> •pwd命令，无选项，无参数，直接输入pwd即可

## 16.相对路径和特殊路径符

> 通过pwd得知当前所在是HOME目录：/home/itheima
>
> 现在想要通过cd命令，切换工作目录到Desktop文件夹中去。
>
> 那么，cd命令的参数（Linux路径）如何写呢？
>
> •cd /home/itheima/Desktop（绝对路径）
>
> •cd Desktop（相对路径）
>
> 上述两种写法，都可以正确的切换目录到指定的Desktop中。

绝对路径：以根目录为起点，描述路径的一种写法，路径描述以/开头

相对路径：以当前目录为起点，描述路径的一种写法，路径描述无需以/开头

> 特殊路径符：
>
> . 表示当前目录，比如 cd ./Desktop 表示切换到当前目录下的Desktop目录内，和cd Desktop效果一致
>
> .. 表示上一级目录，比如：cd ..  即可切换到上一级目录，cd ../.. 切换到上二级的目录
>
> ~ 表示HOME目录，比如：cd ~  即可切换到HOME目录或cd ~/Desktop，切换到HOME内的Desktop目录
>
> ~ == /home/itheima

## 17.mkdir命令

通过mkdir命令可以创建新的目录（文件夹）

mkdir来自英文：Make Directory

语法：![image-20231006160450371](.\img\image-20231006160450371.png)

•参数必填，表示Linux路径，即要创建的文件夹的路径，相对路径或绝对路径均可

•-p选项可选，表示自动创建不存在的父目录，适用于创建连续多层级的目录

> **注意：创建文件夹需要修改权限，请确保操作均在HOME目录内，不要在HOME外操作**
>
> **涉及到权限问题，HOME外无法成功**
>
> **后续我们会讲解权限管控的知识**

ctrl + l：清屏

## 18.touch-cat-more命令

**touch** **创建文件**

> 可以通过touch命令创建文件
>
> 语法：![image-20231006161519378](.\img\image-20231006161519378.png)
>
> •touch命令无选项，参数必填，表示要创建的文件路径，相对、绝对、特殊路径符均可以使用

区分文件和文件夹：

> 1. 深色的表示文件夹，浅色的表示文件
>
> 2. ls -l
>    前面标识为d的代表文件夹，directory
>
>    前面标识为-，表示文件
>
> ![image-20231006161809076](.\img\image-20231006161809076.png)

**cat命令** **查看文件内容**

> 语法：![image-20231006161918564](.\img\image-20231006161918564.png)
>
> •cat同样没有选项，只有必填参数，参数表示：被查看的文件路径，相对、绝对、特殊路径符都可以使用

**more命令查看文件内容**

> more命令同样可以查看文件内容，同cat不同的是：
>
> •cat是直接将内容全部显示出来
>
> •more支持翻页，如果文件内容过多，可以一页页的展示
>
> 语法：![image-20231006162101806](.\img\image-20231006162101806.png)
>
> •同样没有选项，只有必填参数，参数表示：被查看的文件路径，相对、绝对、特殊路径符都可以使用
>
> Linux系统内置有一个文件，路径为：/etc/services，可以使用more命令查看
>
> more /etc/services
>
> •在查看的过程中，通过空格翻页
>
> •通过q退出查看

## 19.cp-mv-rm-命令

**cp** **命令复制文件文件夹**

> cp命令可以用于复制文件\文件夹，cp命令来自英文单词：copy
>
> 语法：![image-20231006162927034](.\img\image-20231006162927034.png)
>
> •-r选项，可选，用于复制文件夹使用，表示递归
>
> •参数1，Linux路径，表示**被复制**的文件或文件夹
>
> •参数2，Linux路径，表示要**复制**去的地方
>
> 复制文件夹，必须使用-r选项，否则不会生效 ! ! !

**mv移动文件或文件夹**

>  mv命令可以用于移动文件\文件夹，mv命令来自英文单词：move
>
> 语法：![image-20231006163210713](.\img\image-20231006163210713.png)
>
> •参数1，Linux路径，表示被移动的文件或文件夹
>
> •参数2，Linux路径，表示要移动去的地方，如果目标不存在，则进行**改名**，确保目标存在
>
> ![image-20231006163239913](.\img\image-20231006163239913.png)

**rm删除文件、文件夹**

> rm命令可用于删除文件、文件夹
>
> rm命令来自英文单词：remove
>
> 语法：![image-20231006163320730](.\img\image-20231006163320730.png)
>
> •同cp命令一样，-r选项用于删除文件夹
>
> •-f表示force，强制删除（不会弹出提示确认信息）
>
> •普通用户删除内容不会弹出提示，只有root管理员用户删除内容会有提示
>
> •所以一般普通用户用不到-f选项
>
> •参数1、参数2、......、参数N 表示要删除的文件或文件夹路径，**按照空格隔开**

**rm删除文件、文件夹** **-**  **通配符**

**通配符**

> rm命令支持通配符 *，用来做模糊匹配
>
> •符号* 表示通配符，即匹配任意内容（包含空），示例：
>
> •test*，表示匹配任何以test开头的内容
>
> •*test，表示匹配任何以test结尾的内容
>
> •*test*，表示匹配任何包含test的内容

> rm是一个危险的命令，特别是在处于root（超级管理员）用户的时候。
>
> 请谨慎使用。
>
> 如下命令，请千万千万不要在root管理员用户下执行：
>
> rm -rf /
>
> rm -rf /*
>
> 效果等同于在Windows上执行C盘格式化。

> -f普通用户一般用不到，一般都是root用户使用的，因为root用户删除的时候会有个提示
>
> •可以通过 su - root，并输入密码123456（和普通用户默认一样）临时切换到root用户体验
>
> •通过输入exit命令，退回普通用户。（临时用root，用完记得退出，不要一直用，关于root我们后面会讲解）
>
> ![image-20231006163822438](.\img\image-20231006163822438.png)

## 20.which-find命令

**which ****命令**

> 我们在前面学习的Linux命令，其实它们的本体就是一个个的二进制可执行程序。
>
> 和Windows系统中的.exe文件，是一个意思。
>
> 我们可以通过which命令，查看所使用的一系列命令的程序文件存放在哪里
>
> 语法：![image-20231006164728313](.\img\image-20231006164728313.png)
>
> ![image-20231006164747959](.\img\image-20231006164747959.png)

**find** **命令** **-** **按文件名查找文件**

> 在图形化中，我们可以方便的通过系统提供的搜索功能，搜索指定的文件。
>
> ![image-20231006164857174](.\img\image-20231006164857174.png)
>
> 同样，在Linux系统中，我们可以通过find命令去搜索指定的文件。
>
> 语法：
>
> ![image-20231006164908919](.\img\image-20231006164908919.png)
>
> -name表示以文件名的形式查找，记得加双引号
>
> -exec command {} \;	匹配条件的文件执行command命令
> eg：find . -name ".bck" -exec  -ls -l {} \;
>
> -type b/c/d/f/l	查找指定类型的文件。b（块设备）、c（字符设备）、d（目录）、f（普通文件）、l（符号连接）
>
> 为了确保后续演示，拥有最大的权限，可以在整个系统完成搜索
>
> 我们可以切换到root用户以获得管理员权限
>
> 执行命令：
>
> su - root
>
> 输入密码：123456（和你普通用户的密码一样）

**find** **命令** **-** **按文件大小查找文件**

> 语法：![image-20231006165525787](.\img\image-20231006165525787.png)
>
> •+、- 表示大于和小于
>
> •n表示大小数字
>
> •kMG表示大小单位，k(小写字母)表示kb，M表示MB，G表示GB
>
> 示例：
>
> •查找小于10KB的文件： find / -size -10k
>
> •查找大于100MB的文件：find / -size +100M
>
> •查找大于1GB的文件：find / -size +1G
>
> ctrl + c：终止输出

## 21.grep-wc-管道符

**grep** **命令**

> 可以通过grep命令，从文件中通过关键字过滤文件行。
>
> 语法：![image-20231006170751250](.\img\image-20231006170751250.png)
>
> •选项-n，可选，表示在结果中显示匹配的行的行号。
>
> -c：统计包含 “查找字符串” 的行数
>
> •参数，关键字，必填，表示过滤的关键字，带有空格或其它特殊符号，**建议使用” ”将关键字包围起来**
>
> •参数，文件路径，必填，表示要过滤内容的文件路径，可作为内容输入端口
>
> -v：取反

**wc** **命令做数量统计**

> 可以通过wc命令统计文件的行数、单词数量等
>
> 语法：![image-20231006171701185](.\img\image-20231006171701185.png)
>
> •选项，-c，统计bytes数量
>
> •选项，-m，统计字符数量
>
> •选项，-l，统计行数
>
> •选项，-w，统计单词数量
>
> •参数，文件路径，被统计的文件，可作为内容输入端口
>
> 如果就一个wc，什么选项也不带的话：
> 对应的是：行数、单词数、字节数、文件名
>
> ![image-20231006171603317](.\img\image-20231006171603317.png)
>
> 后面可以跟多个文件，用空格隔开

**管道符**

> 学习了grep命令后，我们在来学习一个新的特殊符号，管道符：|
>
> 管道符的含义是：将管道符左边命令的结果，作为右边命令的输入
>
> ![image-20231006171958888](.\img\image-20231006171958888.png)
>
> 如上图：
>
> •cat itheima.txt的输出结果（文件内容），左边只要是能产生内容输出的命令都能与管道符配合
>
> •作为右边grep命令的输入（被过滤文件）
>
> •cat itheima.txt | grep itcast | grep itheima，可以嵌套使用哦
>
> ![image-20231006173413617](.\img\image-20231006173413617.png)
>
> •cat itheima.txt的结果给 grep itcast 使用
>
> •cat itheima.txt | grep itcast 的结果给 grep itheima使用 

## 22.echo-tail-重定符

**echo** **命令**

>  可以使用echo命令在命令行内输出指定内容
>
> 语法：![image-20231006184657849](.\img\image-20231006184657849.png)
>
> •无需选项，只有一个参数，表示要输出的内容，复杂内容可以用” ”包围
>
> •带有空格或\等特殊符号，建议使用双引号包围
>
> •因为不包围的话，空格后很容易被识别为参数2，尽管echo不受影响，但是要养成习惯哦

**反引号** **`**

> 看一下如下命令：echo pwd
>
> ![image-20231006184818774](.\img\image-20231006184818774.png)
>
> 本意是想，输出当前的工作路径，但是pwd被作为普通字符输出了。
>
> 我们可以通过将命令用反引号（通常也称之为飘号）`将其包围
>
> 被`包围的内容，会被作为命令执行，而非普通字符
>
> ![image-20231006184843244](.\img\image-20231006184843244.png)

**重定向符**

> 我们再来学习两个特殊符号，重定向符：>和>>
>
> •>，将左侧命令的结果，覆盖写入到符号右侧指定的文件中
>
> •>>，将左侧命令的结果，追加写入到符号右侧指定的文件中
>
> 演示：
>
> •echo “Hello Linux” > itheima.txt
>
> •![image-20231006184916514](.\img\image-20231006184916514.png)
>
> •echo “Hello itheima” > itheima.txt，再次执行，覆盖新内容
>
> •![image-20231006184928712](.\img\image-20231006184928712.png)
>
> •echo “Hello itcast” >> itheima.txt，再次执行，使用>>追加新内容
>
> ![image-20231006184940814](.\img\image-20231006184940814.png)
>
> 但其实只要是能产生结果的都能往右边去写

**tail** **命令**

> 使用tail命令，可以查看文件尾部内容，跟踪文件的最新更改，语法如下：
>
> ![image-20231006185213693](.\img\image-20231006185213693.png)
>
> •参数，Linux路径，表示被跟踪的文件路径
>
> •选项，-f，表示持续跟踪
>
> •选项, -num，表示，查看尾部多少行，不填默认10行

**tail** **持续跟踪文件更改**

>  使用-f选项，可以持续跟踪文件更改
>
> •复制一个新的FinalShell的标签
>
> •![image-20231006185308359](.\img\image-20231006185308359.png)
>
> •在第一个标签中，执行：touch test.txt，创建一个test.txt文件
>
> •在第一个标签中，执行：tail -f test.txt，持续跟踪文件更改
>
> •在第二个标签中，多次执行：echo “内容” >> test.txt，向文件追加内容
>
> •观察第一个标签的变化
>
> ctrl + c：强制停止

## 23.vi编辑器

**vi** **\vim** **编辑器介绍**

> VI 是 Unix 操作系统和类 Unix 操作系统中最通用的文本编辑器。
>
> VIM 编辑器是从 VI 发展出来的一个性能更强大的文本编辑器。可以主动的以字体颜 色辨别语法的正确性，方便程序设计。VIM 与 VI 编辑器完全兼容。

> 还有个编辑器叫emacs。
>
> vim被称为编辑器之神（就做文本编辑器，做到极致），emacs被称为神之编辑器（有很多大神都在用）。
>
> emacs功能非常强化，但是体系太庞大了，启动就很慢。
>
> 而vim是emacs的微型。

> 添加输入法：
>
> ![image-20231201150219603](.\img\image-20231201150219603.png)
>
> super + 空格：切换输入法

> vi\vim是visual interface的简称, 是Linux中最经典的文本编辑器
>
> 同图形化界面中的 文本编辑器一样，vi是命令行下对文本文件进行编辑的绝佳选择。
>
> vim 是 vi 的加强版本，兼容 vi 的所有指令，不仅能编辑文本，而且还具有 shell 程序编辑的功能，可以不同颜色的字体来辨别语法的正确性，极大方便了程序的设计和编辑性。

**vi** **\vim** **编辑器的三种工作模式**

> 命令模式（Command mode）
>
>  命令模式下，所敲的按键编辑器都理解为命令，以命令驱动执行不同的功能。
>
>  此模型下，不能自由进行文本编辑。
>
> 输入模式（Insert mode）
>
>  也就是所谓的编辑模式、插入模式。
>
>  此模式下，可以对文件内容进行自由编辑。
>
> 底线命令模式（Last line mode），也叫作末行模式
>
>  以：开始，通常用于文件的保存、退出。
>
> ![image-20231006190140907](.\img\image-20231006190140907.png)

**命令模式**

> 如果需要通过vi/vim编辑器编辑文件，请通过如下命令：
>
> vim兼容全部的vi功能，后续全部使用vim命令
>
> •![image-20231006190217442](.\img\image-20231006190217442.png)
>
> •如果文件路径表示的文件不存在，那么此命令会用于编辑新文件
>
> •如果文件路径表示的文件存在，那么此命令用于编辑已有文件

**命令模式快捷键**

![image-20231006190637226](.\img\image-20231006190637226.png)

![image-20231006190756761](.\img\image-20231006190756761.png)

![image-20231006190815128](.\img\image-20231006190815128.png)



| 语法           | 功能描述                       |
| -------------- | ------------------------------ |
| yy             | 复制光标当前一行               |
| y 数字 y       | 复制一段（从第几行到第几行）   |
| p              | 箭头移动到目的行粘贴           |
| u              | 撤销上一步                     |
| dd             | 删除光标当前行                 |
| d 数字 d       | 删除光标（含）后多少行         |
| x              | 剪切一个字母，相当于 del       |
| X              | 剪切一个字母，相当于 Backspace |
| yw             | 复制一个词                     |
| dw             | 删除一个词                     |
| shift+6  （^） | 移动到行头                     |
| shift+4  （$） | 移动到行尾                     |
| 1+shift+g      | 移动到页头，数字               |
| shift+g        | 移动到页尾                     |
| 数字+shift+g   | 移动到目标行                   |
| y$             | 复制到当前行的结尾             |
|                |                                |



> 3gg：跑到第三行
>
> p：粘贴到下一行
>
> P：粘贴到上一行
>
> |   命令    |                             作用                             |
> | :-------: | :----------------------------------------------------------: |
> |   /word   |         从当前光标位置开始，向下搜索名为word的字符串         |
> |   ?word   |         从当前光标位置开始，向上搜索名为word的字符串         |
> |     n     |   复制前一个搜的动作（如果默认是向下搜索的则继续向下搜索）   |
> |     N     | 反向复制前一个搜索的动作（如果默认是向上搜索的则继续向上搜） |
> | :%s/A/B/g | 搜索全文，把符合A的全部内容全部替换为B，“/”为分隔符（@、#亦可） |
> |           |                                                              |
> |           |                                                              |
>
> :noh取消高亮

**底线命令模式**

编辑模式没有什么特殊的，进入编辑模式后，任何快捷键都没有作用，就是正常输入文本而已。

唯一大家需要记住的，就是：通过esc，可以退回到命令模式中即可。

在命令模式内，输入: ，即可进入底线命令模式，支持如下命令：

> w：write 
>
> q：quit
>
> x：相当于wq，无论有没有修改文件，wq会对文件修改时间做更改。
> 但是x如果没有修改文件，则不会对文件修改时间做更改！
>
> :set paste
> 主要用于外部粘贴，外面复制的是什么样，粘贴就会怎么样，不会产生格式的错乱

set nonu：取消显示行号

![image-20231006190853380](.\img\image-20231006190853380.png)

## 24.Linux的root用户

**root** **用户（超级管理员）**

> 无论是Windows、MacOS、Linux均采用多用户的管理模式进行权限管理。
>
> •在Linux系统中，拥有最大权限的账户名为：root（超级管理员）
>
> •而在前期，我们一直使用的账户是普通的用户：itheima
>
> ![image-20231006191619743](.\img\image-20231006191619743.png)

>  root用户拥有最大的系统操作权限，而普通用户在许多地方的权限是受限的。
>
> •普通用户的权限，一般在其HOME目录内是不受限的
>
> •一旦出了HOME目录，大多数地方，普通用户仅有只读和执行权限，无修改权限

**su和exit命令**

> 在前面，我们接触过su命令切换到root账户。
>
> su命令就是用于账户切换的系统命令，其来源英文单词：Switch User
>
> 语法：![image-20231006191737306](.\img\image-20231006191737306.png)
>
> •- 符号是可选的，表示是否在切换用户后加载环境变量（后续讲解），建议带上
>
> •参数：用户名，表示要切换的用户，用户名也可以省略，省略表示切换到root
>
> •切换用户后，可以通过exit命令退回上一个用户，也可以使用快捷键：ctrl + d
>
> •使用普通用户，切换到其它用户需要输入密码，如切换到root用户
>
> •使用root用户切换到其它用户，无需密码，可以直接切换

**sudo** **命令**

> 在我们得知root密码的时候，可以通过su命令切换到root得到最大权限。
>
> 但是我们不建议长期使用root用户，避免带来系统损坏。
>
> 我们可以使用sudo命令，为普通的命令授权，临时以root身份执行。
>
> 语法：
>
> •在其它命令之前，带上sudo，即可为这一条命令临时赋予root授权
>
> •但是并不是所有的用户，都有权利使用sudo，我们需要为普通用户配置sudo认证

**为普通用户配置sudo认证**

> •切换到root用户，执行visudo命令，会自动通过vi编辑器打开：/etc/sudoers
>
> •在文件的最后添加：（中间是tab键，NOPASSWD：后面需要加空格！
>
> •![image-20231006192105492](.\img\image-20231006192105492.png)
>
> •其中最后的NOPASSWD:ALL 表示使用sudo命令，无需输入密码
>
> •最后通过 wq 保存

## 25.**用户和用户组**

**用户、用户组**

> Linux系统中可以：![image-20231006192827802](.\img\image-20231006192827802.png)
>
> •配置多个用户
>
> •配置多个用户组
>
> •用户可以加入多个用户组中
>
> 
>
> Linux中关于权限的管控级别有2个级别，分别是：
>
> •针对用户的权限控制
>
> •针对用户组的权限控制
>
> 比如，针对某文件，可以控制用户的权限，也可以控制用户组的权限。
>
> 所以，我们需要学习在Linux中进行用户、用户组管理的基础命令，为后面学习权限控制打下基础。
>
> •Linux可以支持多用户、多用户组、用户加入多个组
>
> •Linux权限管控的单元是用户级别和用户组级别

**用户组管理**

> 以下命令需root用户执行
>
> •创建用户组
>
> groupadd 用户组名
>
> •删除用户组
>
> groupdel 用户组名
>
> 为后续演示，我们创建一个itcast用户组：groupadd itcast

**用户管理**

> 以下命令需root用户执行
>
> •创建用户
>
> useradd [-g -d] 用户名
>
> •选项：-g指定用户的组，不指定-g，会创建同名组并自动加入
> 比如创建test用户，如果不指定-g，它会创建一个test组，并让这个test用户加入这个组里
>
> 指定-g**需要组已经存在**，如已存在同名组，必须使用-g
>
> •选项：-d指定用户HOME路径，不指定，HOME目录默认在：/home/用户名
>
> -m：创建主目录
>
> -s：指定用户账户登录时使用的Shell解释器
>
> 不带参数也能创建，但是它无法登录，home目录下也没有这个用户的目录！
>
> > 如果要变成可用用户：vim /etc/passwd，修改shell为/bin/bash
> >
> > 但依旧很多权限不够 
>
> ll：linux下命令“ll”是“ls -al"的别名。
>
> logout：*是一种让用户退出系统的Linux命令*
>
> 
>
> •删除用户
>
> userdel [-r] 用户名
>
> •选项：-r，删除用户的HOME目录，不使用-r，删除用户时，HOME目录保留
>
> •查看用户所属组
>
> 
>
> id [用户名]
>
> •参数：用户名，被查看的用户，如果不提供则查看自身
>
> •修改用户所属组
>
> usermod -aG 用户组 用户名，将指定用户加入指定用户组
> 此时它并不会将这个用户名从原来的组移除，只是多加了一个组

**getent**

> 使用getent命令，可以查看当前系统中有哪些用户
>
> 语法： getent passwd
>
> ![image-20231006194907843](.\img\image-20231006194907843.png)
>
> ![image-20231006194921869](.\img\image-20231006194921869.png)
>
> 共有7份信息，分别是：
>
> 用户名:密码(x):用户ID:组ID:描述信息(无用):HOME目录:执行终端(默认bash)

> 使用getent命令，同样可以查看当前系统中有哪些用户组
>
> 语法：getent group
>
> ![image-20231006195003223](.\img\image-20231006195003223.png)
>
> ![image-20231006195011705](.\img\image-20231006195011705.png)
>
> 包含3份信息，组名称:组认证(显示为x):组ID

## 26.查看权限控制信息

**认知权限信息**

> 通过ls -l 可以以列表形式查看内容，并显示权限细节
>
> ![image-20231006195208409](.\img\image-20231006195208409.png)
>
> •序号1，表示文件、文件夹的权限控制信息
>
> 连接数：比如有两个应用打卡
>
> •序号2，表示文件、文件夹所属用户
>
> •序号3，表示文件、文件夹所属用户组
>
> 修改时间

**认知权限信息**

> 让我们来解析一下序号1，权限细节
>
> 权限细节总共分为10个槽位
>
> ![image-20231006195249215](.\img\image-20231006195249215.png)
>
> 举例：drwxr-xr-x，表示：
>
> •这是一个文件夹，首字母d表示
>
> •所属用户(右上角图序号2)的权限是：有r有w有x，rwx
>
> •所属用户组(右上角图序号3)的权限是：有r无w有x，r-x （-表示无此权限）
>
> •其它用户的权限是：有r无w有x，r-x

**rwx**

> 那么，rwx到底代表什么呢？
>
> •r表示读权限 read
>
> •w表示写权限 write
>
> •x表示执行权限 execute
>
> 针对文件、文件夹的不同，rwx的含义有细微差别
>
> •r，针对文件可以查看文件内容
>
> •针对文件夹，可以查看文件夹内容，如ls命令
>
> •w，针对文件表示可以修改此文件
>
> •针对文件夹，可以在文件夹内：创建、删除、改名等操作
>
> •x，针对文件表示可以将文件作为程序执行
>
> •针对文件夹，表示可以更改工作目录到此文件夹，即cd进入
>
> 
>
> 案例：
>
> ![image-20231006195708487](.\img\image-20231006195708487.png)
>
> 当前用户itheima，非文件所属用户和用户组，锁定最后三位权限为：---，无读取权限
>
> ![image-20231006195808047](.\img\image-20231006195808047.png)
>
> ![image-20231006195819719](.\img\image-20231006195819719.png)
>
> ![image-20231006195832078](.\img\image-20231006195832078.png)

## 27.chmod命令

change mode

> 我们可以使用chmod命令，修改文件、文件夹的权限信息。
>
> 注意，只有文件、文件夹的所属用户或root用户可以修改。
>
> 语法：![image-20231006201507298](.\img\image-20231006201507298.png)
>
> •选项：-R，对文件夹内的全部内容应用同样的操作
>
> 
>
> 示例：
>
> •chmod u=rwx,g=rx,o=x hello.txt ，将文件权限修改为：rwxr-x--x
>
> •其中：u表示user所属用户权限，g表示group组权限，o表示other其它用户权限
>
> •chmod -R u=rwx,g=rx,o=x test，将文件夹test以及文件夹内全部内容权限设置为：rwxr-x--x
>
> > 这种引人注目的颜色的表示这个文件很危险
> >
> > ![image-20231006202533180](.\img\image-20231006202533180.png)
>
> 除此之外，还有快捷写法：chmod 751 hello.txt
>
> 将hello.txt的权限修改为751
>
> 那么问题来了，751表示什么意思呢？

**权限的数字序号**

> 权限可以用3位数字来代表，第一位数字表示用户权限，第二位表示用户组权限，第三位表示其它用户权限。
>
> 数字的细节如下：r记为4，w记为2，x记为1，可以有：
>
> •0：无任何权限， 即 ---
>
> •1：仅有x权限， 即 --x
>
> •2：仅有w权限 即 -w-
>
> •3：有w和x权限 即 -wx
>
> •4：仅有r权限 即 r--
>
> •5：有r和x权限 即 r-x
>
> •6：有r和w权限 即 rw-
>
> •7：有全部权限 即 rwx
>
> 所以751表示： rwx(7) r-x(5) --x(1)

## 28.**chown命令**

**chown** **命令**

change owner

> 使用chown命令，可以修改文件、文件夹的所属用户和用户组
>
> 普通用户无法修改所属为其它用户或组，所以**此命令只适用于root用户执行**
>
> 语法：![image-20231006203227979](.\img\image-20231006203227979.png)
>
> •选项，-R，同chmod，对文件夹内全部内容应用相同规则
>
> •选项，用户，修改所属用户
>
> •选项，用户组，修改所属用户组
>
> •:用于分隔用户和用户组
>
> 示例：
>
> •chown root hello.txt，将hello.txt所属用户修改为root（只修改所属用户，而不修改所属用户组）
>
> •chown :root hello.txt，将hello.txt所属用户组修改为root（只修改组，不修改用户）
>
> •chown root:itheima hello.txt，将hello.txt所属用户修改为root，用户组修改为itheima
>
> •chown -R root test，将文件夹test的所属用户修改为root并对文件夹内全部内容应用同样规则

chgrp = chage group：修改所属组

## 29.各类小技巧快捷键

**ctrl + c** **强制停止**

> •Linux某些程序的运行，如果想要强制停止它，可以使用快捷键ctrl + c
>
> •![image-20231006204009085](.\img\image-20231006204009085.png)
>
> •命令输入错误，也可以通过快捷键ctrl + c，退出当前输入，重新输入
>
> ![image-20231006204032967](.\img\image-20231006204032967.png)

**ctrl + d** **退出或登出**

> •可以通过快捷键：ctrl + d，退出账户的登录
>
> •![image-20231006204112138](.\img\image-20231006204112138.png)
>
> •或者退出某些特定程序的专属页面
>
> ![image-20231006204132002](.\img\image-20231006204132002.png)
>
> ps：不能用于退出vi/vim

**历史命令搜索**

> •可以通过history命令，查看历史输入过的命令
>
> ![image-20231006204156304](.\img\image-20231006204156304.png)
>
> > 并且可以通过grep结合history使用：
> >
> > history | grep ch
>
> •可以通过：!命令前缀，自动执行上一次匹配前缀的命令
>
> ![image-20231006204305773](.\img\image-20231006204305773.png)
>
> 
>
> •可以通过快捷键：ctrl + r，输入内容去匹配历史命令
>
> •![image-20231006204345387](.\img\image-20231006204345387.png)
>
> 如果搜索到的内容是你需要的，那么：
>
> •回车键可以直接执行
>
> •键盘左右键，可以得到此命令（不执行）

**光标移动快捷键**

> •ctrl + a，跳到命令开头
>
> •ctrl + e，跳到命令结尾
>
> •ctrl + 键盘左键，向左跳一个单词
>
> •ctrl + 键盘右键，向右跳一个单词

**清屏**

> •通过快捷键ctrl + l，可以清空终端内容
>
> •或通过命令clear得到同样效果

## 30.软件安装

**Linux系统的应用商店**

> 操作系统安装软件有许多种方式，一般分为：
>
> •下载安装包自行安装
>
> •如win系统使用exe文件、msi文件等
>
> •如mac系统使用dmg文件、pkg文件等
>
> •系统的应用商店内安装
>
> •如win系统有Microsoft Store商店
>
> •如mac系统有AppStore商店
>
> Linux系统同样支持这两种方式，我们首先，先来学习使用：Linux命令行内的”应用商店”，yum命令安装软件

**yum** **命令**

> yum：RPM包软件管理器，用于自动化安装配置Linux软件，并可以自动解决依赖问题。
>
> 语法：![image-20231006204933564](.\img\image-20231006204933564.png)
>
> •选项：-y，自动确认，无需手动确认安装或卸载过程
>
> •install：安装
>
> •remove：卸载
>
> •search：搜索
>
> 
>
> yum命令需要root权限哦，可以su切换到root，或使用sudo提权。
>
> yum命令需要联网

> •yum [-y] install wget， 通过yum命令安装wget程序
>
> •![image-20231006204824475](.\img\image-20231006204824475.png)
>
> •yum [-y] remove wget，通过yum命令卸载wget命令
>
> •yum search wget，通过yum命令，搜索是否有wget安装包

apt命令 - 扩展

> 前面学习的各类Linux命令，都是通用的。 但是软件安装，CentOS系统和Ubuntu是使用不同的包管理器。
>
> > 主要原因是因为他们两个软件安装包的格式不一样，所以它们对应的自动化安装程序也不一样
> > CentOS的安装包叫.rmp文件
> > Ubuntu的安装包叫.deb文件
>
> CentOS使用yum管理器，Ubuntu使用apt管理器
>
> 通过前面学习的WSL环境，我们可以得到Ubuntu运行环境。
>
> 
>
> 语法：
>
> 用法和yum一致，同样需要root权限
>
> •apt install wget，安装wget
>
> •apt remove wget，移除wget
>
> •apt search wget，搜索wget



# service

所有的服务都是一个后台进程，整个系统运行的时候可能需要很多后台的服务来支撑，这些服务往往是在系统一启动就起来了，直到系统关闭才终止，所有的这些服务我们统称为系统服务，具体执行这些服务的进程，我们往往会把它叫做守护进程。

守护线程：daemon。在Linux里面，有很多服务带d结尾，表示的是当前的进程是一个守护进程。

整个系统的服务想要启动起来，就需要有一个守护进程来进行管理和操作，守护进程守护的就是我们的系统服务。所以在Linux里面，可以认为系统服务和守护线程是一回事。



计算机中，一个正在执行的程序或命令，被叫做“进程”（process）。 启动之后一只存在、常驻内存的进程，一般被称作“服务”（service）。



**1**） 基本语法（**CentOS** **6** 版本**-** 了解）（但现在已经废弃了）

service 服务名 start | stop |  restart | status

**2**） 经验技巧

查看服务的方法：/etc/init.d/服务名 ,发现只有两个服务保留在 service



## （25）.系统运行级别（runlevel）

![image-20231201175023060](.\img\image-20231201175023060.png)

**2**）CentOS7 的运行级别简化为**:**

multi-user.target 等价于原运行级别 3 （多用户有网，无图形界面）

graphical.target 等价于原运行级别 5 （多用户有网，有图形界面）

 

**3**） 查看当前运行级别**:**

systemctl get-default

 

**4**）修改当前运行级别

systemctl set-default TARGET.target  （这里 TARGET 取 multi-user 或者 graphical）

init 3

init 5





## 31.systemctl控制软件启动关闭

**systemctl命令**

> Linux系统很多软件（内置或第三方）均支持使用systemctl命令控制：启动、停止、开机自启
>
> 能够被systemctl管理的软件，一般也称之为：服务
>
> 语法：![image-20231006210431586](.\img\image-20231006210431586.png)
>
> > •start 启动
> >
> > •stop 关闭
> >
> > •status 查看状态
> >
> > •enable 开启开机自启
> >
> > •disable 关闭开机自启
>
> 系统内置的服务比较多，比如：
>
> •NetworkManager，主网络服务
>
> •network，副网络服务
>
> •firewalld，防火墙服务
>
> •sshd，ssh服务（FinalShell远程登录Linux使用的就是这个服务）

> 除了内置的服务以外，部分第三方软件安装后也可以以systemctl进行控制。
>
> •yum install -y ntp（时间同步的软件），安装ntp软件，它安装完成之后，会自动把自己注册为系统服务，此时我们就可以通过systemctl控制。
>
> 可以通过ntpd（它的软件名叫ntp，但是它注册的服务名叫nptd）服务名，配合systemctl进行控制
>
> •yum install -y httpd，安装apache服务器软件
>
> 可以通过httpd服务名，配合systemctl进行控制
>
> 部分软件安装后没有自动集成到systemctl中，我们可以手动添加。

## 32.软连接

**ln命令创建软连接**

> 在系统中创建软链接，可以将文件、文件夹链接到其它位置。
>
> 类似Windows系统中的《快捷方式》
>
> 语法：ln -s 参数1 参数2
>
> •-s选项，创建软连接而非硬链接
>
> •参数1：被链接的文件或文件夹
>
> •参数2：要链接去的目的地
>
> PS：软连接的时候一定要使用绝对路径！
>
> 实例：
>
> •ln -s /etc/yum.conf ~/yum.conf
>
> •ln -s /etc/yum ~/yum
>
> ![image-20231006212746252](.\img\image-20231006212746252.png)

## 33.日期和时区

**date** **命令**

> 通过date命令可以在命令行中查看系统的时间
>
> 语法：![image-20231006213226094](.\img\image-20231006213226094.png)
>
> •-d 按照给定的字符串显示日期，一般用于日期计算
>
> •格式化字符串：通过特定的字符串标记，来控制显示的日期格式
>
> •**%Y  年**
>
> •**%y  年份后两位数字 (00..99)**
>
> •**%m  月份 (01..12)**
>
> •**%d  日 (01..31)**
>
> •**%H**  **小时** **(00..23)**
>
> •**%M**  **分钟** **(00..59)**
>
> •**%S  秒 (00..60)**
>
> •**%s  自 1970-01-01 00:00:00 UTC** **到现在的秒数**

演示

> •使用date命令本体，无选项，直接查看时间
>
> •![image-20231006213304907](.\img\image-20231006213304907.png)
>
> 可以看到这个格式非常的不习惯。我们可以通过格式化字符串自定义显示格式
>
> •按照2022-01-01的格式显示日期
>
> •![image-20231006213322462](.\img\image-20231006213322462.png)
>
> •按照2022-01-01 10:00:00的格式显示日期
>
> •![image-20231006213352732](.\img\image-20231006213352732.png)
>
> 如上，由于中间带有空格，所以使用双引号包围格式化字符串，作为整体。

**date命令进行日期加减**

> •-d选项，可以按照给定的字符串显示日期，一般用于日期计算
>
> 记得加双引号，因为中间有空格
>
> •![image-20231006213657321](.\img\image-20231006213657321.png)
>
> •其中支持的时间标记为：
>
> •**year****年**
>
> •**month****月**
>
> •**day****天**
>
> •**hour****小时**
>
> •**minute****分钟**
>
> •**second****秒**
>
> •-d选项可以和 格式化字符串配合一起使用哦

**修改系统时间**

-s参数

> date -s "2022-07-11 22:22:22"

**修改Linux时区**

> 细心的同学可能会发现，通过date查看的日期时间是不准确的，这是因为：系统默认时区非中国的东八区。
>
> 使用root权限，执行如下命令，修改时区为东八区时区
>
> ![image-20231006213953087](.\img\image-20231006213953087.png)
>
> 将系统自带的localtime文件删除，并将/usr/share/zoneinfo/Asia/Shanghai文件链接为localtime文件即可

**ntp程序**

> 我们可以通过ntp程序自动校准系统时间
>
> 安装ntp：yum -y install ntp
>
> 启动并设置开机自启：
>
> •systemctl start ntpd
>
> •systemctl enable ntpd
>
> 当ntpd启动后会定期的帮助我们联网校准系统的时间
>
> 
>
> •也可以手动校准（需root权限）：ntpdate -u ntp.aliyun.com（通过-u选项）
>
> 通过阿里云提供的服务网址配合ntpdate（安装ntp后会附带这个命令）命令自动校准
>
> ![image-20231006214446153](.\img\image-20231006214446153.png)

## 34.IP地址和主机名

**IP地址**

> 每一台联网的电脑都会有一个地址，用于和其它计算机进行通讯
>
> IP地址主要有2个版本，V4版本和V6版本（V6很少用，课程暂不涉及）
>
> IPv4版本的地址格式是：a.b.c.d，其中abcd表示0~255的数字，如192.168.88.101就是一个标准的IP地址
>
> 
>
> 可以通过命令：ifconfig，查看本机的ip地址，如无法使用ifconfig命令，可以安装：yum -y install net-tools
>
> > Linux系统一般的主网卡都会叫做ens33（只需要关心这个即可）
> >
> > lo：表示的是本地回环的网卡
> >
> > virbr0：虚拟机专用的网卡
>
> ![image-20231006214813062](.\img\image-20231006214813062.png)

**特殊IP地址**

> 除了标准的IP地址以外，还有几个特殊的IP地址需要我们了解：
>
> •127.0.0.1，这个IP地址用于指代本机
>
> ![image-20231006215141292](.\img\image-20231006215141292.png)
>
> 
>
> •0.0.0.0，特殊IP地址
>
> •可以用于指代本机
>
> •可以在端口绑定中用来确定绑定关系（后续讲解）
>
> •在一些IP地址限制中，表示所有IP的意思，如放行规则设置为0.0.0.0，表示允许任意IP访问

**主机名**

> 每一台电脑除了对外联络地址（IP地址）以外，也可以有一个名字，称之为主机名
>
> 无论是Windows或Linux系统，都可以给系统设置主机名
>
> 
>
> •Windows系统主机名
>
> •![image-20231006215226082](.\img\image-20231006215226082.png)
>
> •Linux系统主机名
>
> •![image-20231006215238965](.\img\image-20231006215238965.png)

**在****Linux****中修改主机名**

> •可以使用命令：hostname查看主机名
>
> •![image-20231006215312489](.\img\image-20231006215312489.png)
>
> •可以使用命令：hostnamectl set-hostname 主机名，修改主机名（需root）
>
> •![image-20231006215325443](.\img\image-20231006215325443.png)
>
> •重新登录FinalShell即可看到主机名已经正确显示
>
> ![image-20231006215336056](.\img\image-20231006215336056.png)

## **域名解析**

> IP地址实在是难以记忆，有没有什么办法可以通过主机名或替代的字符地址去代替数字化的IP地址呢？
>
> 实际上，我们一直都是通过字符化的地址去访问服务器，很少指定IP地址
>
> 比如，我们在浏览器内打开：www.baidu.com，会打开百度的网址
>
> 其中，www.baidu.com，是百度的网址，我们称之为：域名

> 不是说通过IP地址才能访问服务器吗？
>
> 为什么域名这一串好记的字符，也可以呢？
>
> 这一切，都是域名解析帮助我们解决的。
>
> 通过域名去访问服务器，叫做域名解析

> 访问www.baidu.com的流程如下：
>
> 检查百度的域名和ip地址是否有对应关系：
>
> ![image-20231006215512925](.\img\image-20231006215512925.png)
>
> 即：
>
> •先查看本机的记录（私人地址本）
>
> •Windows看：C:\Windows\System32\drivers\etc\hosts
>
> •Linux看：/etc/hosts
>
> •浏览器就会再联网去DNS服务器（如114.114.114.114，8.8.8.8等）询问（你把百度的域名告诉我，我就可以把ip地址告诉你）

**配置主机名映射**

> 比如，我们FinalShell是通过IP地址连接到的Linux服务器，那有没有可能通过域名（主机名）连接呢？
>
> 
>
> 可以，我们只需要在Windows系统的：C:\Windows\System32\drivers\etc\hosts文件中配置记录即可
>
> ![image-20231007124658798](.\img\image-20231007124658798.png)
>
> ![image-20231007124845976](.\img\image-20231007124845976.png)
>
> ![image-20231007124857653](.\img\image-20231007124857653.png)
>
> ![image-20231007124913307](.\img\image-20231007124913307.png)
>
> ![image-20231007124920577](.\img\image-20231007124920577.png)

> 什么是域名解析（主机名映射）
>
> 可以通过主机名找到对应计算机的IP地址，这就是主机名映射（域名解析）
>
> 先通过系统本地的记录去查找，如果找不到就联网去公开DNS服务器去查找

# 配置主机名

主机名放在：/etc/hostname

hostnamectl set-hostname spark10

hostname：查看主机名

配置主机映射：/etc/hosts

# 网络连接测试



## 35.配置Linux固定IP地址

**为什么需要固定IP**

> 当前我们虚拟机的Linux操作系统，其IP地址是通过DHCP服务获取的。
>
> DHCP：动态获取IP地址，即每次重启设备后都会获取一次，可能导致IP地址频繁变更
>
> 
>
> 原因1：办公电脑IP地址变化无所谓，但是我们要远程连接到Linux系统，如果IP地址经常变化我们就要频繁修改适配很麻烦
>
> 
>
> 原因2：在刚刚我们配置了虚拟机IP地址和主机名的映射，如果IP频繁更改，我们也需要频繁更新映射关系
>
> 
>
> 综上所述，我们需要IP地址固定下来，不要变化了。

**在VMware Workstation中配置固定IP**

> 配置固定IP需要2个大步骤：
>
> 1.在VMware Workstation（或Fusion）中配置IP地址网关和网段（IP地址的范围）
>
> 2.在Linux系统中手动修改配置文件，固定IP
>
> 首先让我们，先进行第一步，跟随图片进行操作
>
> ![image-20231007125637788](.\img\image-20231007125637788.png)
>
> ![image-20231007125651598](.\img\image-20231007125651598.png)
>
> > 下面88.0可以任意的修改，这是一个网段，表示我们的IP地址的范围是192.168.88.0到192.168.88.254之间，但推荐使用88
> >
> > 子网掩码一定要确认是255.255.255.0
>
> ![image-20231007125704924](.\img\image-20231007125704924.png)
>
> ![image-20231007125715331](.\img\image-20231007125715331.png)

> 现在进行第二步，在Linux系统中修改固定IP
>
> 使用vim编辑/etc/sysconfig（系统的配置文件）/network-scripts/ifcfg-ens33（网卡的配置文件）文件，填入如下内容
>
> dhcp是自动获取的意思
>
> IPADDR只要是192.168.88.0到192.168.88.254之间都可以，这里的IP地址一定要和VMWare里面配置的ip一致
>
> DNS1：域名解析的服务器这里设置为网关即可，VMWare会自动去做域名解析的
>
> ![image-20231007125954856](.\img\image-20231007125954856.png)
>
> •执行：systemctl restart network 重启网卡，执行ifconfig即可看到ip地址固定为192.168.88.130了
>
> 或者service network restart

## 36.网络请求和下载

查看windows的网络：

![image-20231201154844431](.\img\image-20231201154844431.png)

![image-20231201155734412](.\img\image-20231201155734412.png)

VMware提供了三种网络连接模式：

- 桥接模式

  虚拟机直接连接外部网络网络的模式，主机起到了网桥的作用。这种模式下，虚拟机可以直接访问外部网络，并且对外部网络是可见的。

  ![image-20231201163042296](.\img\image-20231201163042296.png)

- NAT模式(Network Address T)网络地址转换

  虚拟机和主机构建一个专用网络，并通过虚拟网络地址转换（NAT）设备对IP进行转换。虚拟机通过共享主机IP可以访问外部网络，但外部网络无法访问虚拟机。

  ![image-20231201163510416](.\img\image-20231201163510416.png)

- 仅主机模式

  虚拟机只与主机共享一个专用网络，与外部网络无法通信。



# **ping** **命令**

> 可以通过ping命令，检查指定的网络服务器是否是可联通状态
>
> 语法：![image-20231007132505071](.\img\image-20231007132505071.png)
>
> •选项：-c，检查的次数，不使用-c选项，将无限次数持续检查
>
> •参数：ip或主机名，被检查的服务器的ip地址或主机名地址
>
> 示例：
>
> •检查到baidu.com是否联通
>
> •![image-20231007132054056](.\img\image-20231007132054056.png)
>
> 结果表示联通，延迟8ms左右
>
> •检查到39.156.66.10是否联通，并检查3次
>
> ![image-20231007132110638](.\img\image-20231007132110638.png)

**5.2.4** 修改 **IP** 地址后可能会遇到的问题

（1）物理机能 ping 通虚拟机，但是虚拟机 ping 不通物理机,一般都是因为物理机的 防火墙问题,把防火墙关闭就行

（2）虚拟机能 Ping 通物理机,但是虚拟机 Ping 不通外网,一般都是因为 DNS 的设置有

问题

（3）虚拟机 Ping [www.baidu.com](http://www.baidu.com) 显示域名未知等信息,一般查看 GATEWAY 和 DNS 设

置是否正确

（4）如果以上全部设置完还是不行，需要关闭 NetworkManager 服务

systemctl stop NetworkManager 关闭

systemctl disable NetworkManager 禁用

（5）如果检查发现 systemctl status network 有问题 需要检查 ifcfg-ens33



**wget** **命令**

> wget是非交互式的文件下载器，可以在命令行内下载网络文件
>
> 语法：![image-20231007132518644](.\img\image-20231007132518644.png)
>
> •选项：-b，可选，后台下载，会将日志写入到当前工作目录的wget-log文件
>
> •参数：url，下载链接
>
> 示例：
>
> •下载apache-hadoop 3.3.0版本：wget http://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
>
> •![image-20231007132441563](.\img\image-20231007132441563.png)
>
> •在后台下载：wget -b http://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
>
> •通过tail命令可以监控后台下载进度：tail -f wget-log
>
> 注意：无论下载是否完成，都会生成要下载的文件，如果下载未完成，请及时清理未完成的不可用文件。

**curl** **命令**

> curl可以发送http网络请求，可用于：下载文件、获取信息等
>
> 语法：![image-20231007133850188](.\img\image-20231007133850188.png)
>
> •选项：-O，用于下载文件，当url是下载链接时，可以使用此选项保存文件
>
> •参数：url，要发起请求的网络地址

> 示例：
>
> •向cip.cc发起网络请求：curl cip.cc（公开的网站，可以帮助我们去获取到主机的公网ip地址
>
> •![image-20231007134053151](.\img\image-20231007134053151.png)
>
> •向python.itheima.com发起网络请求：curl python.itheima.com
> 此时会获取到这个页面的html代码
>
> 浏览器输入这个地址是打开这个网站，本质是也是获取到请求，拿到html代码，然后渲染成看见网页的样子。
>
> •通过curl下载hadoop-3.3.0安装包：curl -O http://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz 

## 37.端口

**端口**

> 端口，是设备与外界通讯交流的出入口。端口可以分为：物理端口和虚拟端口两类
>
> •物理端口：又可称之为接口，是可见的端口，如USB接口，RJ45网口，HDMI端口等
>
> •虚拟端口：是指计算机内部的端口，是不可见的，是用来操作系统和外部进行交互使用的

> 计算机程序之间的通讯，通过IP只能锁定计算机，但是无法锁定具体的程序。
>
> 通过端口可以锁定计算机上具体的程序，确保程序之间进行沟通
>
> IP地址相当于小区地址，在小区内可以有许多住户（程序），而门牌号（端口）就是各个住户（程序）的联系地址

> Linux系统是一个超大号小区，可以支持65535个端口，这6万多个端口分为3类进行使用：
>
> •公认端口：1~1023，通常用于一些系统内置或知名程序的预留使用，如SSH服务的22端口，HTTPS服务的443端口
>
> 非特殊需要，不要占用这个范围的端口
>
> •注册端口：1024~49151，通常可以随意使用，用于松散的绑定一些程序\服务
>
> •动态端口：49152~65535，通常不会固定绑定程序，而是当程序对外进行网络链接时，用于临时使用。
>
> ![image-20231007190415341](.\img\image-20231007190415341.png)
>
> 如图中，计算机A的微信连接计算机B的微信，A使用的50001即动态端口，临时找一个端口作为出口
>
> 计算机B的微信使用端口5678，即注册端口，长期绑定此端口等待别人连接
>
> **PS****：上述微信的端口仅为演示，具体微信的端口使用非图中示意**

**查看端口占用**

> 可以通过Linux命令去查看端口的占用情况
>
> •使用nmap命令，安装nmap：yum -y install nmap
>
> 语法：nmap 被查看的IP地址
>
> ![image-20231007190616163](.\img\image-20231007190616163.png)
>
> 可以看到，本机（127.0.0.1）上有5个端口现在被程序占用了。
>
> 其中：
>
> •22端口，一般是SSH服务使用，即FinalShell远程连接Linux所使用的端口

> •可以通过netstat命令，查看指定端口的占用情况
>
> 语法：netstat -anp | grep 端口号，安装netstat：yum -y install net-tools
>
> ![image-20231007190833213](.\img\image-20231007190833213.png)
>
> 如图，可以看到当前系统6000端口被程序（进程号7174）占用了
>
> 其中，0.0.0.0:6000，表示端口绑定在0.0.0.0这个IP地址上，表示允许外部访问
>
> ![image-20231007190851982](.\img\image-20231007190851982.png)
>
> 可以看到，当前系统12345端口，无人使用哦。

## 38.进程管理

**进程**

> 程序运行在操作系统中，是被操作系统所管理的。
>
> 为管理运行的程序，每一个程序在运行的时候，便被操作系统注册为系统中的一个：进程
>
> 并会为每一个进程都分配一个独有的：进程ID（进程号）PID
>
> ![image-20231007191250227](.\img\image-20231007191250227.png)
>
> ![image-20231007191301677](.\img\image-20231007191301677.png)

**查看进程**

> 可以通过ps命令查看Linux系统中的进程信息
>
> 语法：![image-20231007191326798](.\img\image-20231007191326798.png)
>
> 选项：-e，显示出全部的进程
>
> 选项：-f，以完全格式化的形式展示信息（展示全部信息）
>
> 一般来说，固定用法就是： ps -ef 列出全部进程的全部信息

> ![image-20231007191350716](.\img\image-20231007191350716.png)
>
> **从左到右分别是：**
>
> •**UID：进程所属的用户ID**
>
> •**PID****：进程的进程号****ID**
>
> •**PPID****：进程的父****ID****（启动此进程的其它进程）**
>
> •**C****：此进程的****CPU****占用率（百分比）**
>
> •**STIME****：进程的启动时间**
>
> •**TTY****：启动此进程的终端序号，如显示****?****，表示非终端启动**，而是系统
>
> •**TIME****：进程占用****CPU****的时间**
>
> •**CMD****：进程对应的名称或启动路径或启动命令**

**查看指定进程**

> •在FinalShell中，执行命令：tail，可以看到，此命令一直阻塞在那里
>
> •在FinalShell中，复制一个标签页，执行：ps -ef 找出tail这个程序的进程信息
>
> •问题：是否会发现，列出的信息太多，无法准确的找到或很麻烦怎么办？
>
> 
>
> 我们可以使用管道符配合grep来进行过滤，如：
>
> ps -ef | grep tail，即可准确的找到tail命令的信息
>
> ![image-20231007191519724](.\img\image-20231007191519724.png)
>
> •过滤不仅仅过滤名称，进程号，用户ID等等，都可以被grep过滤哦
>
> •如：ps -ef | grep 30001，过滤带有30001关键字的进程信息（一般指代过滤30001进程号）
>
> > 一般来说ps -ef进行prep的时候，至少会出现两个，除非没有结果。
> >
> > 第二个表示的是我们当前执行这个程序的本身，在执行的一瞬间，这也是一个完整的程序，grep也有了过滤。

**关闭进程**

> 在Windows系统中，可以通过任务管理器选择进程后，点击结束进程从而关闭它。
>
> 同样，在Linux中，可以通过kill命令关闭进程。
>
> 语法：![image-20231007192121680](.\img\image-20231007192121680.png)
>
> 选项：-9，表示强制关闭进程。不使用此选项会向进程发送信号要求其关闭，但是否关闭看进程自身的处理机制。
>
> ![image-20231007192158801](.\img\image-20231007192158801.png)
>
> 自我关闭：
>
> ![image-20231007192328349](.\img\image-20231007192328349.png)
>
> 强制关闭：
>
> ![image-20231007192314205](.\img\image-20231007192314205.png)

## 39.主机状态监控

**查看****系统资源占用**

> •可以通过top命令查看CPU、内存使用情况，类似Windows的任务管理器
>
>    默认每5秒刷新一次，语法：直接输入top即可，按q或ctrl + c退出
>
> ![image-20231007192556552](.\img\image-20231007192556552.png)

**top****命令内容详解**

> •第一行：![image-20231007192648101](.\img\image-20231007192648101.png)
>
> top：命令名称，14:39:58：当前系统时间，up 6 min：启动了6分钟，2 users：2个用户登录，load：1、5、15分钟负载（如果负载是1的话，有一颗cpu百分百繁忙；如果负载是4的话，有四颗cpu百分百繁忙，这里负载是0.0几，表名当前系统的压力很低）
>
> •第二行：![image-20231007192719768](.\img\image-20231007192719768.png)
>
> Tasks：175个进程，1 running：1个进程子在运行，174 sleeping：174个进程睡眠，0个停止进程，0个僵尸进程
>
> •第三行：![image-20231007192737254](.\img\image-20231007192737254.png)
>
> %Cpu(s)：CPU使用率，us：用户CPU使用率，sy：系统CPU使用率，（一般情况下只需要看su和sy的占用率即可）。ni：高优先级进程占用CPU时间百分比，id：空闲CPU率，wa：IO等待CPU占用率，hi：CPU硬件中断率，si：CPU软件中断率，st：强制等待占用CPU率
>
> •第四、五行：![image-20231007192756005](.\img\image-20231007192756005.png)
>
> Kib Mem：物理内存，total：总量，free：空闲，used：使用，buff/cache：buff和cache占用
>
> KibSwap：虚拟内存（交换空间），total：总量，free：空闲，used：使用，buff/cache：buff和cache占用
> PS：一般来说，交换空间一般很少去看，因为交换空间很难把它用完。
> 对于操作系统来说，物理内存可能是有上线的，但是虚拟内存，即假内存是可以无限扩容的，所以一般情况下虚拟内存大部分时候都不需要关心他，只需要关心物理内存的使用情况即可

> ![image-20231007193417222](.\img\image-20231007193417222.png)
>
> •PID：进程id
>
> •USER：进程所属用户
>
> •PR：进程优先级，越小越高
>
> •NI：负值表示高优先级，正表示低优先级
>
> •VIRT：进程使用虚拟内存，单位KB
>
> •RES：进程使用物理内存，单位KB
>
> •SHR：进程使用共享内存，单位KB
>
> •S：进程状态（S休眠，R运行，Z僵死状态，N负数优先级，I空闲状态）
>
> •%CPU：进程占用CPU率
>
> •%MEM：进程占用内存率
>
> •TIME+：进程使用CPU时间总计，单位10毫秒
>
> •COMMAND：进程的命令或名称或程序文件路径
>
> > 一般关心的是：进程号（PID）、物理内存的使用情况（RES）、CUP占用（%CPU）、内存占用（%MEM）

> top命令也支持选项：
>
> ![image-20231007193634651](.\img\image-20231007193634651.png)

**top****交互式选项**

> 当top以交互式运行（非-b选项启动），可以用以下交互式命令进行控制
>
> ![image-20231007193944259](.\img\image-20231007193944259.png)

**磁盘信息监控**

> •使用df命令，可以查看硬盘的使用情况
>
> 语法：df [-h]
>
> 选项：-h，以更加人性化的单位显示
>
> ![image-20231007194052286](.\img\image-20231007194052286.png)

> •可以使用iostat查看CPU、磁盘的相关信息
>
> 语法：iostat [-x] [num1] [num2]
>
> •选项：-x，显示更多信息
>
> •num1：数字，刷新间隔，num2：数字，刷新几次
>
> ![image-20231007194307581](.\img\image-20231007194307581.png)
>
> tps：该设备每秒的传输次数（Indicate the number of transfers per second that were issued to the device.）。"一次传输"意思是"一次I/O请求"。多个逻辑请求可能会被合并为"一次I/O请求"。"一次传输"请求的大小是未知的。
>
> •使用iostat的-x选项，可以显示更多信息
>
> ![image-20231007194400078](.\img\image-20231007194400078.png)
>
> rrqm/s： 每秒这个设备相关的读取请求有多少被Merge了（当系统调用需要读取数据的时候，VFS将请求发到各个FS，如果FS发现不同的读取请求读取的是相同Block的数据，FS会将这个请求合并Merge, 提高IO利用率, 避免重复调用）；
>
> wrqm/s： 每秒这个设备相关的写入请求有多少被Merge了。
>
> rsec/s： 每秒读取的扇区数；sectors
>
> wsec/： 每秒写入的扇区数。
>
> rKB/s： 每秒发送到设备的读取请求数
>
> wKB/s： 每秒发送到设备的写入请求数
>
> avgrq-sz  平均请求扇区的大小
>
> avgqu-sz  平均请求队列的长度。毫无疑问，队列长度越短越好。  
>
> await：  每一个IO请求的处理的平均时间（单位是微秒毫秒）。
>
> svctm   表示平均每次设备I/O操作的服务时间（以毫秒为单位）
>
> %util：  磁盘利用率（重点关注这个）

**网络状态监控**

> •可以使用sar命令查看网络的相关统计（sar命令非常复杂，这里仅简单用于统计网络）
>
> 语法：sar -n DEV num1 num2
>
> 选项：-n，查看网络，DEV表示查看网络接口(network)
>
> num1：刷新间隔（不填就查看一次结束），num2：查看次数（不填无限次数）
>
> •![image-20231007194448414](.\img\image-20231007194448414.png)
>
> •![image-20231007194456592](.\img\image-20231007194456592.png)
>
> **信息解读：**
>
> •**IFACE 本地网卡接口的名称**
>
> •**rxpck/s 每秒钟接受的数据包**
>
> •**txpck/s 每秒钟发送的数据包**
>
> •**rxKB/S 每秒钟接受的数据包大小，单位为KB**(这个)
>
> •**txKB/S 每秒钟发送的数据包大小，单位为KB**（这个）
>
> •**rxcmp/s 每秒钟接受的压缩数据包**
>
> •**txcmp/s 每秒钟发送的压缩包**
>
> •**rxmcst/s 每秒钟接收的多播数据包**
>
> 如图，查看2次，隔3秒刷新一次，并最终汇总平均记录

## 39.环境变量

> 在讲解which命令的时候，我们知道使用的一系列命令其实本质上就是一个个的可执行程序。
>
> 比如，cd命令的本体就是：/usr/bin/cd 这个程序文件。
>
> 我们是否会有疑问，为何无论当前工作目录在哪里，都能执行：/usr/bin/cd这个程序呢？
>
> 这就是环境变量的作用啦。

**环境变量**

> 环境变量是操作系统（Windows、Linux、Mac）在运行的时候，记录的一些关键性信息，用以辅助系统运行。
>
> 在Linux系统中执行：env命令即可查看当前系统中记录的环境变量
>
> 环境变量是一种KeyValue型结构，即名称和值，如下图：
>
> ![image-20231007194814999](.\img\image-20231007194814999.png)
>
> **如左图，图中记录了：**
>
> •**HOME****：****/home/itheima****，用户的****HOME****路径**
>
> •**USER****：****itheima****，当前的操作用户**
>
> •**PWD****：当前工作路径**
>
> •**......**
>
> **等等一系列信息，用于辅助系统在运行的时候**
>
> **从环境变量中获取关键信息**

**环境变量****：****PATH**

> 在前面提出的问题中，我们说无论当前工作目录是什么，都能执行/usr/bin/cd这个程序，这个就是借助环境变量中：PATH这个项目的值来做到的。
>
> ![image-20231007195137941](.\img\image-20231007195137941.png)
>
> PATH记录了系统执行任何命令的搜索路径，如上图记录了（路径之间以:隔开）：
>
> •/usr/local/bin
>
> •/usr/bin
>
> •/usr/local/sbin
>
> •/usr/sbin
>
> •/home/itheima/.local/bin
>
> •/home/itheima/bin
>
> 当执行任何命令，都会按照顺序，从上述路径中搜索要执行的程序的本体
>
> 比如执行cd命令，就从第二个目录/usr/bin中搜索到了cd命令，并执行

**$符号**

> 在Linux系统中，$符号被用于取”变量”的值。
>
> 环境变量记录的信息，除了给操作系统自己使用外，如果我们想要取用，也可以使用。
>
> 取得环境变量的值就可以通过语法：$环境变量名 来取得
>
> 比如： echo $PATH
> 如果直接输入$PATH是会出问题的。
>
> 就可以取得PATH这个环境变量的值，并通过echo语句输出出来。
>
> ![image-20231007195200992](.\img\image-20231007195200992.png)
>
> 又或者：echo ${PATH}ABC
>
> ![image-20231007195210771](.\img\image-20231007195210771.png)
>
> 当和其它内容混合在一起的时候，可以通过{}来标注取的变量是谁

**自行设置环境变量**

> Linux环境变量可以用户自行设置，其中分为：
>
> •临时设置，语法：export 变量名=变量值(FinallShell关闭再打开就会发现取不到了)
>
> •永久生效
>
> •针对当前用户生效，配置在当前用户的： ~/.bashrc文件中
>
> ![image-20231007195952037](.\img\image-20231007195952037.png)
>
> •针对所有用户生效，配置在系统的： /etc/profile文件中（记得切换root用户）
> 只需要在这个文件的最下面添加即可
>
> ![image-20231007200435869](.\img\image-20231007200435869.png)
>
> •并通过语法：source 配置文件，进行立刻生效，或重新登录FinalShell生效
>
> source .bashrc
> source /etc/profile
>
> ![image-20231007195556425](.\img\image-20231007195556425.png)

**自定义环境变量PATH**

> 环境变量PATH这个项目里面记录了系统执行命令的搜索路径。
>
> 这些搜索路径我们也可以自行添加到PATH中去。
>
> 
>
> 测试：
>
> •在当前HOME目录内创建文件夹，myenv，在文件夹内创建文件mkhaha
>
> •通过vim编辑器，在mkhaha文件内填入：echo 哈哈哈哈哈
>
> 完成上述操作后，随意切换工作目录，执行mkhaha命令尝试一下，会发现无法执行
>
> 
>
> •修改PATH的值
>
> 临时修改PATH：export PATH=$PATH:/home/itheima/myenv（这个的意思是：来自于原有的PATH，再追加上我们刚刚程序的目录），再次执行mkhaha，无论在哪里都能执行了
>
> 或将export PATH=$PATH:/home/itheima/myenv，填入用户环境变量文件或系统环境变量文件中去

## 40.Linux文件的上传和下载

**上传、下载**

> 我们可以通过FinalShell工具，方便的和虚拟机进行数据交换。
>
> 在FinalShell软件的下方窗体中，提供了Linux的文件系统视图，可以方便的：
>
> •浏览文件系统，找到合适的文件，右键点击下载，即可传输到本地电脑
>
> •浏览文件系统，找到合适的目录，将本地电脑的文件拓展进入，即可方便的上传数据到Linux中
>
> ![image-20231007201230640](.\img\image-20231007201230640.png)
>
> > 但是会发现一个问题：上面显示的是root，而下面依旧是itheima，这是因为上面是通过su去切换的，上面有root权限，但是下面是没有root权限的！
> >
> > 这是由于我们连接FinalShell的时候是以itheima登录的。
> > 如果想要使用最大的权限就需要使用root用户登录！
> >
> > ![image-20231007201500125](.\img\image-20231007201500125.png)

**rz、sz命令**

> 当然，除了通过FinalShell的下方窗体进行文件的传输以外，也可以通过rz、sz命令进行文件传输。（r：receive接收，s：send发送
>
> rz、sz命令需要安装，可以通过：yum -y install lrzsz，即可安装。
>
> •rz命令，进行上传，语法：直接输入rz即可
> 但是这种方式很慢！通过拖拽的方式上传就很快！
>
> 使用tab键可以自动补全
>
> •![image-20231007201626792](.\img\image-20231007201626792.png)
>
> •sz命令进行下载，语法：sz 要下载的文件
>
> 文件会自动下载到桌面的：fsdownload文件夹中。
>
> 注意，rz、sz命令需要终端软件支持才可正常运行
>
> FinalShell、SecureCRT、XShell等常用终端软件均支持此操作

## 41.tar压缩和解压

**压缩格式**

> 市面上有非常多的压缩格式
>
> •zip格式：Linux、Windows、MacOS，常用
>
> •7zip：Windows系统常用
>
> •rar：Windows系统常用
>
> •tar：Linux、MacOS常用
>
> •gzip：Linux、MacOS常用
>
> 在Windows系统中常用的软件如：winrar、bandizip等软件，都支持各类常见的压缩格式，这里不多做讨论。
>
> 我们现在要学习，如何在Linux系统中操作：tar、gzip、zip这三种压缩格式
>
> 并且在命令行完成文件的压缩、解压操作。

**tar****命令**

> Linux和Mac系统常用有2种压缩格式，后缀名分别是：
>
> •.tar，称之为tarball，归档文件，即简单的将文件组装到一个.tar的文件内，并没有太多文件体积的减少，仅仅是简单的封装
>
> •.gz，也常见为.tar.gz，gzip格式压缩文件，即使用gzip压缩算法将文件压缩到一个文件内，可以极大的减少压缩后的体积
>
> 针对这两种格式，使用tar命令均可以进行压缩和解压缩的操作
>
> 语法：![image-20231007202117494](.\img\image-20231007202117494.png)
>
> •-c（create），创建压缩文件，用于压缩模式
>
> •-v，显示压缩、解压过程，用于查看进度，即把过程可视化
>
> •-x，解压模式
>
> •-f，要创建的文件，或要解压的文件，-f选项必须在所有选项中位置处于最后一个！！！   
>
> •-z，gzip模式，不使用-z就是普通的tarball格式
>
> •-C，选择解压的目的地，用于解压模式

**tar** **命令压缩**

> tar的常用组合为：
>
> **创建一个标准的tar格式的压缩包**
>
> •tar -cvf test.tar 1.txt 2.txt 3.txt
>
> 将1.txt 2.txt 3.txt 压缩到test.tar文件内
>
> **创建gzip格式的压缩包**
>
> •tar -zcvf test.tar.gz 1.txt 2.txt 3.txt
>
> 将1.txt 2.txt 3.txt 压缩到test.tar.gz文件内，使用gzip模式
>
> gzip的后缀可以为.gz或者.tar.gz，不管怎么样都需要以.gz作为后缀，这是一个标识。
>
> 
>
> 注意：
>
> •-z选项如果使用的话，一般处于选项位第一个
>
> •-f选项，必须在选项位最后一个，目的是为了接收后面的参数

**tar** **解压**

> 常用的tar解压组合有
>
> •tar -xvf test.tar
>
> （c和x二选一！）
>
> 解压test.tar，将文件解压至当前目录
>
> •tar -xvf test.tar -C /home/itheima
>
> 解压test.tar，将文件解压至指定目录（/home/itheima）
>
> •tar -zxvf test.tar.gz -C /home/itheima（可以不用提前创好）
>
> 以Gzip模式解压test.tar.gz，将文件解压至指定目录（/home/itheima）
>
> 
>
> 注意：
>
> •-f选项，必须在选项组合体的最后一位
>
> •-z选项，建议在开头位置
>
> •-C选项单独使用，和解压所需的其它参数分开

**zip** **命令压缩文件**

> 可以使用zip命令，压缩文件为zip压缩包
>
> 语法：![image-20231007203636073](.\img\image-20231007203636073.png)
>
> •-r，被压缩的包含文件夹的时候，需要使用-r选项，和rm、cp等命令的-r效果一致
>
> 
>
> 示例：
>
> •zip test.zip a.txt b.txt c.txt
>
> 将a.txt b.txt c.txt 压缩到test.zip文件内
>
> •zip -r test.zip test itheima a.txt
>
> 将test、itheima两个文件夹和a.txt文件，压缩到test.zip文件内

**unzip** **命令解压文件**

> 使用unzip命令，可以方便的解压zip压缩包
>
> 语法：![image-20231007203848174](.\img\image-20231007203848174.png)
>
> •-d，指定要解压去的位置，同tar的-C选项
>
> •参数，被解压的zip压缩包文件
>
> •
>
> 示例：
>
> •unzip test.zip，将test.zip解压到当前目录
>
> •unzip test.zip -d /home/itheima，将test.zip解压到指定文件夹内（/home/itheima）
>
> PS：如果解压的地方有同名的内容，它会直接替换掉
>
> 清除：rm -f *.txt

## 42.实战节章-前言

## 44.MySQL5.7在CenOS安装【单机软件】

> 注意：安装需要root权限！

MySQL数据库管理系统（后续简称MySQL），是一款知名的数据库系统，其特点是：轻量、简单、功能丰富。

MySQL数据库可谓是软件行业的明星产品，无论是后端开发、大数据、AI、运维、测试等各类岗位，基本上都会和MySQL打交道。

本次课程分为2个版本进行安装：

- MySQL 5.7版本安装
- MySQL 8.x版本安装

> 由于MySQL5.x和8.x各自有许多使用者，所以这两个版本我们都演示安装一遍

MySQL的安装我们可以通过前面学习的yum命令进行。

> yum连接的远程仓库中并没有我们需要的mysql5.7，所以我们必须给它配置一个额外的远程仓库
>
> rpm是一个适用于CenOS的安装文件，用于安装rpm包的命令叫做rpm。它有个选项--import，即导入一个秘钥。
>
> 因为只有秘钥对上了，我们才可以联网去安装

### 安装

1. 配置yum仓库

   ```shell
   # 更新密钥
   rpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2022
   
   # 安装Mysql yum库
   # 去网络中获取软件包，并且将它安装，类似于windows系统的.exe
   # 此时它就会去给yum程序安装mysql的yum仓库
   rpm -Uvh http://repo.mysql.com//mysql57-community-release-el7-7.noarch.rpm
   ```

   ![image-20221012182514865](.\img\20221012182514.png)

   > 由于MySQL并不在CentOS的官方仓库中，所以我们通过上述rpm命令：
   >
   > - 导入MySQL仓库的密钥
   > - 配置MySQLQ的yum仓库

2. 使用yum安装MySQL

   ```shell
   # yum安装Mysql
   yum -y install mysql-community-server
   ```

   ![image-20221012182555420](.\img\20221012182556.png)

3. 安装完成后，启动MySQL并配置开机自启动

   ```shell
   # systemctl可以去管理系统内置的一些服务以及额外安装的第三方软件
   # mysql软件并不懒惰，它安装完成之后会自动把它自己配置成系统服务
   systemctl start mysqld		# 启动
   systemctl enable mysqld		# 开机自启
   ```

   > MySQL安装完成后，会自动配置为名称叫做：`mysqld`的服务，可以被systemctl所管理

4. 检查MySQL的运行状态

   ```shell
   systemctl status mysqld
   ```

   ![image-20221012182716598](.\img\20221012182716.png)



### 配置

主要配置管理员用户root的密码以及配置允许远程登录的权限。



1. 获取MySQL的初始密码

   ```shell
   # 通过grep命令，在/var/log/mysqld.log文件中，过滤temporary password关键字，得到初始密码
   grep 'temporary password' /var/log/mysqld.log
   ```

   ![image-20221012182744115](.\img\20221012182744.png)

2. 登陆MySQL数据库系统

   ```shell
   # 执行
   mysql -uroot -p
   # 解释
   # -u，登陆的用户，MySQL数据库的管理员用户同Linux一样，是root
   # -p，表示使用密码登陆
   
   # 执行完毕后输入刚刚得到的初始密码，即可进入MySQL数据库
   ```

   ![image-20221012182805966](.\img\20221012182806.png)

3. 修改root用户密码

   ```sql
   # 在MySQL控制台内执行
   ALTER USER 'root'@'localhost' IDENTIFIED BY '密码';	-- 密码需要符合：大于8位，有大写字母，有特殊符号，不能是连续的简单语句如123，abc
   ```

4. [扩展]，配置root的简单密码

   > 我们可以给root设置简单密码，如123456.
   >
   > 请注意，此配置仅仅是用于测试环境或学习环境的MySQL，如果是正式使用，请勿设置简单密码

   ```sql
   # 如果你想设置简单密码，需要降低Mysql的密码安全级别
   set global validate_password_policy=LOW; # 密码安全级别低
   set global validate_password_length=4;	 # 密码长度最低4位即可
   
   # 然后就可以用简单密码了（课程中使用简单密码，为了方便，生产中不要这样）
   ALTER USER 'root'@'localhost' IDENTIFIED BY '简单密码';
   ```

5. [扩展]，配置root运行远程登录

   > 默认情况下，root用户是不运行远程登录的，只允许在MySQL所在的Linux服务器登陆MySQL系统
   >
   > 请注意，允许root远程登录会带来安全风险

   ```sql
   # 授权root远程登录
   grant all privileges on *.* to root@"IP地址" identified by '密码' with grant option;  
   # IP地址即允许登陆的IP地址，也可以填写%，表示允许任何地址
   # 密码表示给远程登录独立设置密码，和本地登陆的密码可以不同
   
   # 刷新权限，生效
   flush privileges;
   ```

6. 退出MySQL控制台页面

   ```sql
   # 退出命令
   exit
   
   # 或者通过快捷键退出：ctrl + d
   ```

7. 检查端口

   MySQL默认绑定了3306端口，可以通过端口占用检查MySQL的网络状态

   ```shell
   netstat -anp | grep 3306
   ```

   ![image-20221012183746802](.\img\20221012183746.png)



至此，MySQL就安装完成并可用了，请妥善保存好MySQL的root密码。

## 45.MySQL8.0版本在CentOS系统安装

> 注意：安装操作需要root权限

> 由于安装两个版本会冲突
>
> 使用rpm -e mysql57-community-release删除之前的版本即可下载新版的了

### 安装

1. 配置yum仓库

   ```shell
   # 更新密钥
   rpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2022
   
   # 安装Mysql8.x版本 yum库
   rpm -Uvh https://dev.mysql.com/get/mysql80-community-release-el7-2.noarch.rpm
   ```

2. 使用yum安装MySQL

   ```shell
   # yum安装Mysql
   yum -y install mysql-community-server
   ```

3. 安装完成后，启动MySQL并配置开机自启动

   ```shell
   systemctl start mysqld		# 启动
   systemctl enable mysqld		# 开机自启
   ```

   > MySQL安装完成后，会自动配置为名称叫做：`mysqld`的服务，可以被systemctl所管理

4. 检查MySQL的运行状态

   ```shell
   systemctl status mysqld
   ```



### 配置

主要修改root密码和允许root远程登录

1. 获取MySQL的初始密码

   ```shell
   # 通过grep命令，在/var/log/mysqld.log文件中，过滤temporary password关键字，得到初始密码
   grep 'temporary password' /var/log/mysqld.log
   ```

2. 登录MySQL数据库系统

   ```shell
   # 执行
   mysql -uroot -p
   # 解释
   # -u，登陆的用户，MySQL数据库的管理员用户同Linux一样，是root
   # -p，表示使用密码登陆
   
   # 执行完毕后输入刚刚得到的初始密码，即可进入MySQL数据库
   ```

3. 修改root密码

   ```sql
   ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '密码';	-- 密码需要符合：大于8位，有大写字母，有特殊符号，不能是连续的简单语句如123，abc
   ```

4. [扩展]，配置root的简单密码

   > 我们可以给root设置简单密码，如123456.
   >
   > 请注意，此配置仅仅是用于测试环境或学习环境的MySQL，如果是正式使用，请勿设置简单密码

   ```sql
   set global validate_password.policy=0;		# 密码安全级别低
   set global validate_password.length=4;		# 密码长度最低4位即可
   ```

   

5. 允许root远程登录，并设置远程登录密码

   > 默认情况下，root用户是不运行远程登录的，只允许在MySQL所在的Linux服务器登陆MySQL系统
   >
   > 请注意，允许root远程登录会带来安全风险

   ```sql
   # 第一次设置root远程登录，并配置远程密码使用如下SQL命令
   create user 'root'@'%' IDENTIFIED WITH mysql_native_password BY '密码!';	-- 密码需要符合：大于8位，有大写字母，有特殊符号，不能是连续的简单语句如123，abc
   
   # 后续修改密码使用如下SQL命令
   ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '密码';
   ```

6. 退出MySQL控制台页面

   ```sql
   # 退出命令
   exit
   
   # 或者通过快捷键退出：ctrl + d
   ```

7. 检查端口

   MySQL默认绑定了3306端口，可以通过端口占用检查MySQL的网络状态

   ```shell
   netstat -anp | grep 3306
   ```

   ![image-20221012192303607](.\img\20221012192303.png)

至此，MySQL就安装完成并可用了，请妥善保存好MySQL的root密码。





## MySQL5.7版本在Ubuntu（WSL环境）系统安装

> 课程中配置的WSL环境是最新的Ubuntu22.04版本，这个版本的软件商店内置的MySQL是8.0版本
>
> 所以我们需要额外的步骤才可以安装5.7版本的MySQL



安装操作需root权限，你可以：

1. 通过 sudo su -，切换到root用户

   > 课程中选择这种方式操作

2. 或在每一个命令前，加上sudo，用来临时提升权限





### 安装

1. 下载apt仓库文件

   ```shell
   # 下载apt仓库的安装包，Ubuntu的安装包是.deb文件
   wget https://dev.mysql.com/get/mysql-apt-config_0.8.12-1_all.deb
   ```

   ![image-20221016094103315](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016094103.png)

2. 配置apt仓库

   ```shell
   # 使用dpkg命令安装仓库
   dpkg -i mysql-apt-config_0.8.12-1_all.deb
   ```

   弹出框中选择：`ubuntu bionic` （Ubuntu18.04系统的代号是bionic，选择18.04的版本库用来安装）

   ![image-20221016094142343](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016094142.png)

   弹出框中选择：`MySQL Server & Cluster`

   ![image-20221016094216377](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016094216.png)

   弹出框中选择：`mysql-5.7`

   ![image-20221016094254397](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016094254.png)

   最后选择：`ok`

   ![image-20221016094306917](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016094306.png)

3. 更新apt仓库的信息

   ```shell
   # 首先导入仓库的密钥信息
   apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 467B942D3A79BD29
   # 更新仓库信息
   apt update
   ```

4. 检查是否成功配置MySQL5.7的仓库

   ```shell
   apt-cache policy mysql-server
   ```

   ![image-20221016094546943](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016094546.png)

   看到如图所示字样，即成功

5. 安装MySQL5.7

   ```shell
   # 使用apt安装mysql客户端和mysql服务端
   apt install -f -y mysql-client=5.7* mysql-community-server=5.7*
   ```

   弹出框中输入root密码并选择ok，密码任意，课程中以123456代替

   ![image-20221016094941439](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016094941.png)

   再次输入root密码确认

   ![image-20221016094954505](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016094954.png)

6. 启动MySQL

   ```shell
   /etc/init.d/mysql start			# 启动
   /etc/init.d/mysql stop			# 停止
   /etc/init.d/mysql status		# 查看状态
   ```

   ![image-20221016095259172](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016095259.png)

7. 对MySQL进行初始化

   ```shell
   # 执行如下命令，此命令是MySQL安装后自带的配置程序
   mysql_secure_installation
   # 可以通过which命令查看到这个自带程序所在的位置
   root@DESKTOP-Q89USRE:~# which mysql_secure_installation
   /usr/bin/mysql_secure_installation
   ```

   1. 输入密码：

      ![image-20221016095458755](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016095458.png)

   2. 是否开启密码验证插件，如果需要增强密码安全性，输入`y`并回车，不需要直接回车（课程中选择直接回车）

      ![image-20221016095537716](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016095537.png)

   3. 是否更改root密码，需要输入`y`回车，不需要直接回车（课程不更改）

      ![image-20221016095621386](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016095621.png)

   4. 是否移除匿名用户，移除输入`y`回车，不移除直接回车（课程选择移除）

      ![image-20221016101232827](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016101232.png)

   5. 是否进制root用户远程登录，禁止输入`y`回车，不禁止直接回车（课程选择不禁止）

      ![image-20221016101324577](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016101324.png)

   6. 是否移除自带的测试数据库，移除输入`y`回车，不移除直接回车（课程选择不移除）

      ![image-20221016101404392](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016101404.png)

   7. 是否刷新权限，刷新输入`y`回车，不刷新直接回车（课程选择刷新）

      ![image-20221016101442459](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016101442.png)

8. 登陆MySQL

   ```shell
   mysql -uroot -p
   # 输入密码即可登陆成功
   ```

   ![image-20221016101524498](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016101524.png)



至此，在Ubuntu上安装MySQL5.7版本成功。





## MySQL8.0版本在Ubuntu（WSL环境）系统安装

> 课程中配置的WSL环境是最新的Ubuntu22.04版本，这个版本的软件商店内置的MySQL是8.0版本
>
> 所以直接可以通过apt安装即可

> 注意，课程是以WSL获得的Ubuntu操作系统环境。
>
> 如果你通过VMware虚拟机的方式获得了Ubuntu操作系统环境，操作步骤不用担心，和课程中使用WSL环境是==完全一致的==



安装操作需root权限，你可以：

1. 通过 sudo su -，切换到root用户

   > 课程中选择这种方式操作

2. 或在每一个命令前，加上sudo，用来临时提升权限



### 安装

1. 如果已经安装过MySQL5.7版本，需要卸载仓库信息哦

   ```shell
   # 卸载MySQL5.7版本
   apt remove -y mysql-client=5.7* mysql-community-server=5.7*
   
   # 卸载5.7的仓库信息
   dpkg -l | grep mysql | awk '{print $2}' | xargs dpkg -P
   ```

2. 更新apt仓库信息

   ```shell
   apt update
   ```

3. 安装mysql

   ```shell
   apt install -y mysql-server
   ```

4. 启动MySQL

   ```shell
   /etc/init.d/mysql start			# 启动
   /etc/init.d/mysql stop			# 停止
   /etc/init.d/mysql status		# 查看状态
   ```

5. 登陆MySQL设置密码

   ```shell
   # 直接执行：mysql
   mysql
   ```

6. 设置密码

   ```sql
   ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password';
   ```

7. 退出MySQL控制台

   ```shell
   exit
   ```

8. 对MySQL进行初始化

   ```shell
   # 执行如下命令，此命令是MySQL安装后自带的配置程序
   mysql_secure_installation
   # 可以通过which命令查看到这个自带程序所在的位置
   root@DESKTOP-Q89USRE:~# which mysql_secure_installation
   /usr/bin/mysql_secure_installation
   ```

   1. 输入密码：

      ![image-20221016095458755](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016095458.png)

   2. 是否开启密码验证插件，如果需要增强密码安全性，输入`y`并回车，不需要直接回车（课程中选择直接回车）

      ![image-20221016095537716](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016095537.png)

   3. 是否更改root密码，需要输入`y`回车，不需要直接回车（课程不更改）

      ![image-20221016095621386](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016095621.png)

   4. 是否移除匿名用户，移除输入`y`回车，不移除直接回车（课程选择移除）

      ![image-20221016101232827](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016101232.png)

   5. 是否进制root用户远程登录，禁止输入`y`回车，不禁止直接回车（课程选择不禁止）

      ![image-20221016101324577](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016101324.png)

   6. 是否移除自带的测试数据库，移除输入`y`回车，不移除直接回车（课程选择不移除）

      ![image-20221016101404392](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016101404.png)

   7. 是否刷新权限，刷新输入`y`回车，不刷新直接回车（课程选择刷新）

      ![image-20221016101442459](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016101442.png)

9. 重新登陆MySQL（用更改后的密码）

   ```shell
   mysql -uroot -p
   ```

   ![image-20221016110414182](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/16/20221016110414.png)

   



至此，在Ubuntu上安装MySQL5.7版本成功。



# Tomcat安装部署【简单】

## 简介

Tomcat 是由 Apache 开发的一个 Servlet 容器，实现了对 Servlet 和 JSP 的支持，并提供了作为Web服务器的一些特有功能，如Tomcat管理和控制平台、安全域管理和Tomcat阀等。



简单来说，Tomcat是一个WEB应用程序的托管平台，可以让用户编写的WEB应用程序，被Tomcat所托管，并提供网站服务。

> 即让用户开发的WEB应用程序，变成可以被访问的网页。



## 安装

Tomcat的安装非常简单，主要分为2部分：

1. 安装JDK环境
2. 解压并安装Tomcat



> 本次安装使用Tomcat版本是：10.0.27版本，需要Java（JDK）版本最低为JDK8或更高版本
>
> 课程中使用的JDK版本是：JDK8u351版本



### 安装JDK环境

1. 下载JDK软件

   https://www.oracle.com/java/technologies/downloads

   在页面下方找到：

   <img src="https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/17/20221017163411.png" alt="image-20221017163411651" style="zoom: 67%;" />

   下载`jdk-8u351-linux-x64.tar.gz`

   ![image-20221017163440491](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/17/20221017163440.png)

   ==在弹出的页面中输入Oracle的账户密码即可下载（如无账户，请自行注册，注册是免费的）==

2. 登陆Linux系统，切换到root用户

   ![](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/17/20221017163607.png)

3. 通过FinalShell，上传下载好的JDK安装包

   ![image-20221017163706026](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/17/20221017163706.png)

4. 创建文件夹，用来部署JDK，将JDK和Tomcat都安装部署到：/export/server 内

   ```shell
   mkdir -p /export/server
   ```

5. 解压缩JDK安装文件

   ```shell
   tar -zxvf jdk-8u351-linux-x64.tar.gz -C /export/server
   ```

6. 配置JDK的软链接

   ```shell
   ln -s /export/server/jdk1.8.0_351 /export/server/jdk
   ```

7. 配置JAVA_HOME环境变量，以及将$JAVA_HOME/bin文件夹加入PATH环境变量中

   ```shell
   # 编辑/etc/profile文件
   export JAVA_HOME=/export/server/jdk
   export PATH=$PATH:$JAVA_HOME/bin
   ```

8. 生效环境变量

   ```shell
   source /etc/profile
   ```

9. 配置java执行程序的软链接

   ```shell
   # 删除系统自带的java程序
   rm -f /usr/bin/java
   # 软链接我们自己安装的java程序
   ln -s /export/server/jdk/bin/java /usr/bin/java
   ```

10. 执行验证：

    ```shell
    java -version
    javac -version
    ```



### 解压并部署Tomcat

> Tomcat建议使用非Root用户安装并启动
>
> 可以创建一个用户：tomcat用以部署



1. 首先，放行tomcat需要使用的8080端口的外部访问权限

   > CentOS系统默认开启了防火墙，阻止外部网络流量访问系统内部
   >
   > 所以，如果想要Tomcat可以正常使用，需要对Tomcat默认使用的8080端口进行放行
   >
   > 放行有2种操作方式：
   >
   > 1. 关闭防火墙
   > 2. 配置防火墙规则，放行端口

   ```shell
   # 以下操作2选一即可
   # 方式1：关闭防火墙
   systemctl stop firewalld		# 关闭防火墙
   systemctl disable firewalld		# 停止防火墙开机自启
   
   # 方式2：放行8080端口的外部访问
   firewall-cmd --add-port=8080/tcp --permanent		# --add-port=8080/tcp表示放行8080端口的tcp访问，--permanent表示永久生效
   firewall-cmd --reload								# 重新载入防火墙规则使其生效
   ```

   > 方便起见，建议同学们选择方式1，直接关闭防火墙一劳永逸
   >
   > 防火墙的配置非常复杂，后面会视情况独立出一集防火墙配置规则的章节。

2. 以root用户操作，创建tomcat用户

   ```shell
   # 使用root用户操作
   useradd tomcat
   # 可选，为tomcat用户配置密码
   passwd tomcat
   ```

3. 下载Tomcat安装包

   ```shell
   # 使用root用户操作
   wget https://dlcdn.apache.org/tomcat/tomcat-10/v10.0.27/bin/apache-tomcat-10.0.27.tar.gz
   # 如果出现https相关错误，可以使用--no-check-certificate选项
   wget --no-check-certificate https://dlcdn.apache.org/tomcat/tomcat-10/v10.0.27/bin/apache-tomcat-10.0.27.tar.gz
   ```

   > 如果Linux内下载过慢，可以复制下载链接在Windows系统中使用迅雷等软件加速下载然后上传到Linux内即可
   >
   > 或者使用课程资料中提供的安装包

4. 解压Tomcat安装包

   ```shell
   # 使用root用户操作，否则无权限解压到/export/server内，除非修改此文件夹权限
   tar -zxvf apache-tomcat-10.0.27.tar.gz -C /export/server
   ```

5. 创建Tomcat软链接

   ```shell
   # 使用root用户操作
   ln -s /export/server/apache-tomcat-10.0.27 /export/server/tomcat
   ```

6. 修改tomcat安装目录权限

   ```shell
   # 使用root用户操作，同时对软链接和tomcat安装文件夹进行修改，使用通配符*进行匹配
   chown -R tomcat:tomcat /export/server/*tomcat*
   ```

7. 切换到tomcat用户

   ```shell
   su - tomcat
   ```

8. 启动tomcat

   ```shell
   /export/server/tomcat/bin/startup.sh
   ```

9. tomcat启动在8080端口，可以检查是否正常启动成功

   ```shell
   netstat -anp | grep 8080
   ```

   ![image-20221017223814737](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/17/20221017223814.png)

10. 打开浏览器，输入：

    http://centos:8080或http://192.168.88.130:8080

    使用主机名（需配置好本地的主机名映射）或IP地址访问Tomcat的WEB页面

    ![image-20221017223915498](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/17/20221017223915.png)



至此，Tomcat安装配置完成。





# Nginx安装部署【简单】

## 简介

*Nginx* (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。

同Tomcat一样，Nginx可以托管用户编写的WEB应用程序成为可访问的网页服务，同时也可以作为流量代理服务器，控制流量的中转。



Nginx在WEB开发领域，基本上也是必备组件之一了。



## 安装

Nginx同样需要配置额外的yum仓库，才可以使用yum安装

> 安装Nginx的操作需要root身份



1. 安装yum依赖程序

   ```shell
   # root执行
   yum install -y yum-utils
   ```

2. 手动添加，nginx的yum仓库

   yum程序使用的仓库配置文件，存放在：`/etc/yum.repo.d`内。

   ```shell
   # root执行
   # 创建文件使用vim编辑
   vim /etc/yum.repos.d/nginx.repo
   # 填入如下内容并保存退出
   [nginx-stable]
   name=nginx stable repo
   baseurl=http://nginx.org/packages/centos/$releasever/$basearch/
   gpgcheck=1
   enabled=1
   gpgkey=https://nginx.org/keys/nginx_signing.key
   module_hotfixes=true
   
   [nginx-mainline]
   name=nginx mainline repo
   baseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/
   gpgcheck=1
   enabled=0
   gpgkey=https://nginx.org/keys/nginx_signing.key
   module_hotfixes=true
   ```

   > 通过如上操作，我们手动添加了nginx的yum仓库

3. 通过yum安装最新稳定版的nginx

   ```shell
   # root执行
   yum install -y nginx
   ```

4. 启动

   ```shell
   # nginx自动注册了systemctl系统服务
   systemctl start nginx		# 启动
   systemctl stop nginx		# 停止
   systemctl status nginx		# 运行状态
   systemctl enable nginx		# 开机自启
   systemctl disable nginx		# 关闭开机自启
   ```

5. 配置防火墙放行

   nginx默认绑定80端口，需要关闭防火墙或放行80端口

   ```shell
   # 方式1（推荐），关闭防火墙
   systemctl stop firewalld		# 关闭
   systemctl disable firewalld		# 关闭开机自启
   
   # 方式2，放行80端口
   firewall-cmd --add-port=80/tcp --permanent		# 放行tcp规则下的80端口，永久生效
   firewall-cmd --reload							# 重新加载防火墙规则
   ```

6. 启动后浏览器输入Linux服务器的IP地址或主机名即可访问

   http://192.168.88.130 或 http://centos

   > ps：80端口是访问网站的默认端口，所以后面无需跟随端口号
   >
   > 显示的指定端口也是可以的比如：
   >
   > - http://192.168.88.130:80
   > - http://centos:80



至此，Nginx安装配置完成。

![image-20221018143113053](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/18/20221018143113.png)







# RabbitMQ安装部署【简单】

## 简介

RabbitMQ一款知名的开源消息队列系统，为企业提供消息的发布、订阅、点对点传输等消息服务。

RabbitMQ在企业开发中十分常见，课程为大家演示快速搭建RabbitMQ环境。



## 安装

> rabbitmq在yum仓库中的版本比较老，所以我们需要手动构建yum仓库



1. 准备yum仓库

   ```shell
   # root执行
   # 1. 准备gpgkey密钥
   rpm --import https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc
   rpm --import https://packagecloud.io/rabbitmq/erlang/gpgkey
   rpm --import https://packagecloud.io/rabbitmq/rabbitmq-server/gpgkey
   
   # 2. 准备仓库文件
   vim /etc/yum.repos.d/rabbitmq.repo
   # 填入如下内容
   ##
   ## Zero dependency Erlang
   ##
   
   [rabbitmq_erlang]
   name=rabbitmq_erlang
   baseurl=https://packagecloud.io/rabbitmq/erlang/el/7/$basearch
   repo_gpgcheck=1
   gpgcheck=1
   enabled=1
   # PackageCloud's repository key and RabbitMQ package signing key
   gpgkey=https://packagecloud.io/rabbitmq/erlang/gpgkey
          https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc
   sslverify=1
   sslcacert=/etc/pki/tls/certs/ca-bundle.crt
   metadata_expire=300
   
   [rabbitmq_erlang-source]
   name=rabbitmq_erlang-source
   baseurl=https://packagecloud.io/rabbitmq/erlang/el/7/SRPMS
   repo_gpgcheck=1
   gpgcheck=0
   enabled=1
   # PackageCloud's repository key and RabbitMQ package signing key
   gpgkey=https://packagecloud.io/rabbitmq/erlang/gpgkey
          https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc
   sslverify=1
   sslcacert=/etc/pki/tls/certs/ca-bundle.crt
   metadata_expire=300
   
   ##
   ## RabbitMQ server
   ##
   
   [rabbitmq_server]
   name=rabbitmq_server
   baseurl=https://packagecloud.io/rabbitmq/rabbitmq-server/el/7/$basearch
   repo_gpgcheck=1
   gpgcheck=0
   enabled=1
   # PackageCloud's repository key and RabbitMQ package signing key
   gpgkey=https://packagecloud.io/rabbitmq/rabbitmq-server/gpgkey
          https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc
   sslverify=1
   sslcacert=/etc/pki/tls/certs/ca-bundle.crt
   metadata_expire=300
   
   [rabbitmq_server-source]
   name=rabbitmq_server-source
   baseurl=https://packagecloud.io/rabbitmq/rabbitmq-server/el/7/SRPMS
   repo_gpgcheck=1
   gpgcheck=0
   enabled=1
   gpgkey=https://packagecloud.io/rabbitmq/rabbitmq-server/gpgkey
   sslverify=1
   sslcacert=/etc/pki/tls/certs/ca-bundle.crt
   metadata_expire=300
   ```

2. 安装RabbitMQ

   ```shell
   # root执行
   yum install erlang rabbitmq-server -y
   ```

   ```shell
   Installed:
     erlang.x86_64 0:23.3.4.11-1.el7           rabbitmq-server.noarch 0:3.10.0-1.el7
   ```

3. 启动

   ```shell
   # root执行
   # 使用systemctl管控，服务名：rabbitmq-server
   systemctl enable rabbitmq-server		# 开机自启
   systemctl disable rabbitmq-server		# 关闭开机自启
   systemctl start rabbitmq-server			# 启动
   systemctl stop rabbitmq-server			# 关闭
   systemctl status rabbitmq-server		# 查看状态
   ```

4. 放行防火墙，RabbitMQ使用5672、15672、25672 3个端口

   ```shell
   # 方式1（推荐），关闭防火墙
   systemctl stop firewalld		# 关闭
   systemctl disable firewalld		# 关闭开机自启
   
   # 方式2，放行5672 25672端口
   firewall-cmd --add-port=5672/tcp --permanent		# 放行tcp规则下的5672端口，永久生效
   firewall-cmd --add-port=15672/tcp --permanent		# 放行tcp规则下的15672端口，永久生效
   firewall-cmd --add-port=25672/tcp --permanent		# 放行tcp规则下的25672端口，永久生效
   firewall-cmd --reload								# 重新加载防火墙规则
   ```

5. 启动RabbitMQ的WEB管理控制台

   ```shell
   rabbitmq-plugins enable rabbitmq_management
   ```

6. 添加admin用户，并赋予权限

   ```shell
   rabbitmqctl add_user admin 'Itheima66^'
   rabbitmqctl set_permissions -p "/" "admin" ".*" ".*" ".*"
   rabbitmqctl set_user_tags admin administrator
   ```

   

7. 浏览器打开管理控制台

   http://192.168.88.130:15672

   ![image-20221018154823983](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/18/20221018154824.png)



至此，RabbitMQ已经安装完成了。



# Redis安装部署【简单】

## 简介

redis是一个开源的、使用C语言编写的、支持网络交互的、可基于内存也可持久化的Key-Value数据库。

redis的特点就是：`快`，可以基于内存存储数据并提供超低延迟、超快的检索速度

一般用于在系统中提供快速缓存的能力。



## 安装



1. 配置`EPEL`仓库

   > EPEL 的全称叫 Extra Packages for Enterprise Linux 。EPEL是由 Fedora 社区打造，为 RHEL 及衍生发行版如 CentOS、Scientific Linux 等提供高质量软件包的项目。装上了 EPEL之后，就相当于添加了一个第三方源。EPEL则为服务器版本提供大量的rpm包(yum程序所使用的程序安装包，类似Windows的exe)，而且大多数rpm包在官方 repository 中是找不到的。

   ```shell
   # root执行
   yum install -y epel-release
   ```

2. 安装redis

   ```shell
   # root执行
   yum install -y redis
   ```

3. 启动redis

   ```shell
   # root执行
   # 使用systemctl管控，服务名：redis
   systemctl enable redis		# 开机自启
   systemctl disable redis		# 关闭开机自启
   systemctl start redis		# 启动
   systemctl stop redis		# 关闭
   systemctl status redis		# 查看状态
   ```

4. 放行防火墙，redis使用端口6379

   ```shell
   # 方式1（推荐），关闭防火墙
   systemctl stop firewalld		# 关闭
   systemctl disable firewalld		# 关闭开机自启
   
   # 方式2，放行6379端口
   firewall-cmd --add-port=6379/tcp --permanent		# 放行tcp规则下的6379端口，永久生效
   firewall-cmd --reload	
   ```

5. 进入redis服务

   ```shell
   # 执行redis-cli
   [root@centos ~]# redis-cli
   127.0.0.1:6379> set mykey hello
   OK
   127.0.0.1:6379> get mykey
   "hello"
   127.0.0.1:6379> 
   ```



至此，redis安装完成。



# ElasticSearch安装部署

## 简介

[全文搜索](https://baike.baidu.com/item/全文搜索引擎)属于最常见的需求，开源的 [Elasticsearch](https://www.elastic.co/) （以下简称 es）是目前全文搜索引擎的首选。

它可以快速地储存、搜索和分析海量数据。维基百科、Stack Overflow、Github 都采用它。



Elasticsearch简称es，在企业内同样是一款应用非常广泛的搜索引擎服务。

很多服务中的搜索功能，都是基于es来实现的。



## 安装

1. 添加yum仓库

   ```shell
   # root执行
   # 导入仓库密钥
   rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch
   
   # 添加yum源
   # 编辑文件 
   vim /etc/yum.repos.d/elasticsearch.repo
   
   [elasticsearch-7.x]
   name=Elasticsearch repository for 7.x packages
   baseurl=https://artifacts.elastic.co/packages/7.x/yum
   gpgcheck=1
   gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
   enabled=1
   autorefresh=1
   type=rpm-md
   
   
   # 更新yum缓存
   yum makecache
   ```

2. 安装es

   ```shell
   yum install -y elasticsearch
   ```

3. 配置es

   ```shell
   vim /etc/elasticsearch/elasticsearch.yml
   
   # 17行，设置集群名称
   cluster.name: my-cluster
   
   # 23行，设置节点名称
   node.name: node-1
   
   # 56行，允许外网访问
   network.host: 0.0.0.0
   
   # 74行，配置集群master节点
   cluster.initial_master_nodes: ["node-1"]
   ```

4. 启动es

   ```shell
   systemctl start | stop | status | enable | disable elasticsearch
   ```

5. 关闭防火墙

   ```shell
   systemctl stop firewalld
   systemctl disable firewalld
   ```

6. 测试

   浏览器打开：http://ip:9200/?pretty

   ![image-20221025085432335](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/25/20221025085432.png)







# 集群化环境前置准备

## 介绍

在前面，我们所学习安装的软件，都是以单机模式运行的。

后续，我们将要学习大数据相关的软件部署，所以后续我们所安装的软件服务，大多数都是以集群化（多台服务器共同工作）模式运行的。



所以，在当前小节，我们需要完成集群化环境的前置准备，包括创建多台虚拟机，配置主机名映射，SSH免密登录等等。

## 部署



### 配置多台Linux虚拟机

安装集群化软件，首要条件就是要有多台Linux服务器可用。

我们可以使用VMware提供的克隆功能，将我们的虚拟机额外克隆出3台来使用。

1. 首先，关机当前CentOS系统虚拟机（可以使用root用户执行`init 0`来快速关机）

2. 新建文件夹

   ![image-20221025104157628](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/25/20221025104157.png)

   文件夹起名为：`虚拟机集群`

3. 克隆

   ![image-20221025104131303](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/25/20221025104131.png)

   ![image-20221025104312091](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/25/20221025104312.png)

   ![image-20221025104329109](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/25/20221025104329.png)

   ![image-20221025104345484](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/25/20221025104345.png)

   ![image-20221025104414576](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/25/20221025104414.png)

   ![image-20221025104427160](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/25/20221025104427.png)

   ![image-20221025104432927](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/25/20221025104432.png)

   ![image-20221025104446044](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/25/20221025104446.png)

4. 同样的操作克隆出：node2和node3

   ![image-20221025104825204](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/25/20221025104825.png)

5. 开启node1，修改主机名为node1，并修改固定ip为：192.168.88.131

   ```shell
   # 修改主机名
   hostnamectl set-hostname node1
   
   # 修改IP地址
   vim /etc/sysconfig/network-scripts/ifcfg-ens33
   IPADDR="192.168.88.131"
   
   # 重启网卡
   systemctl stop network
   systemctl start network
   # 或者直接
   systemctl restart network
   ```

6. 同样的操作启动node2和node3,

   修改node2主机名为node2，设置ip为192.168.88.132

   修改node2主机名为node3，设置ip为192.168.88.133

7. 配置FinalShell，配置连接到node1、node2、node3的连接

   > 为了简单起见，建议配置root用户登录



### 准备主机名映射

1. 在Windows系统中修改hosts文件，填入如下内容：

   > 如果同学们使用MacOS系统，请：
   >
   > 1. sudo su -，切换到root
   > 2. 修改/etc/hosts文件

   ```shell
   192.168.88.131 node1
   192.168.88.132 node2
   192.168.88.133 node3
   ```

2. 在3台Linux的/etc/hosts文件中，填入如下内容（==3台都要添加==）

   ```shell
   192.168.88.131 node1
   192.168.88.132 node2
   192.168.88.133 node3
   ```



### 配置SSH免密登录

#### 简介

SSH服务是一种用于远程登录的安全认证协议。

我们通过FinalShell远程连接到Linux，就是使用的SSH服务。

SSH服务支持：

1. 通过账户+密码的认证方式来做用户认证
2. 通过账户+秘钥文件的方式做用户认证



SSH可以让我们通过SSH命令，远程的登陆到其它的主机上，比如：

在node1执行：ssh root@node2，将以root用户登录node2服务器，输入密码即可成功登陆

或者ssh node2，将以当前用户直接登陆到node2服务器。



#### SSH免密配置

后续安装的集群化软件，多数需要远程登录以及远程执行命令，我们可以简单起见，配置三台Linux服务器之间的免密码互相SSH登陆

1. 在每一台机器都执行：`ssh-keygen -t rsa -b 4096`，一路回车到底即可

2. 在每一台机器都执行：

   ```shell
   ssh-copy-id node1
   ssh-copy-id node2
   ssh-copy-id node3
   ```

3. 执行完毕后，node1、node2、node3之间将完成root用户之间的免密互通



### 配置JDK环境

后续的大数据集群软件，多数是需要Java运行环境的，所以我们为==每一台==机器都配置JDK环境。



JDK配置参阅：`Tomcat`安装部署环节。



### 关闭防火墙和SELinux

集群化软件之间需要通过端口互相通讯，为了避免出现网络不通的问题，我们可以简单的在集群内部关闭防火墙。

==在每一台机器都执行==

```shell
systemctl stop firewalld
systemctl disable firewalld
```



Linux有一个安全模块：SELinux，用以限制用户和程序的相关权限，来确保系统的安全稳定。

SELinux的配置同防火墙一样，非常复杂，课程中不多涉及，后续视情况可以出一章SELinux的配置课程。

在当前，我们只需要关闭SELinux功能，避免导致后面的软件运行出现问题即可，

==在每一台机器都执行==

```shell
vim /etc/sysconfig/selinux

# 将第七行，SELINUX=enforcing 改为
SELINUX=disabled
# 保存退出后，重启虚拟机即可，千万要注意disabled单词不要写错，不然无法启动系统
```





### 添加快照

为了避免后续出现问题，在完成上述设置后，为==每一台虚拟机==都制作快照，留待使用。





## 补充命令 - scp

后续的安装部署操作，我们将会频繁的在多台服务器之间相互传输数据。

为了更加方面的互相传输，我们补充一个命令：scp



scp命令是cp命令的升级版，即：ssh cp，通过SSH协议完成文件的复制。

其主要的功能就是：在不同的Linux服务器之间，通过`SSH`协议互相传输文件。

只要知晓服务器的账户和密码（或密钥），即可通过SCP互传文件。



语法：

```shell
scp [-r] 参数1 参数2
- -r选项用于复制文件夹使用，如果复制文件夹，必须使用-r
- 参数1：本机路径 或 远程目标路径
- 参数2：远程目标路径 或 本机路径

如：
scp -r /export/server/jdk root@node2:/export/server/
将本机上的jdk文件夹， 以root的身份复制到node2的/export/server/内
同SSH登陆一样，账户名可以省略（使用本机当前的同名账户登陆）

如：
scp -r node2:/export/server/jdk /export/server/
将远程node2的jdk文件夹，复制到本机的/export/server/内


# scp命令的高级用法
cd /export/server
scp -r jdk node2:`pwd`/    # 将本机当前路径的jdk文件夹，复制到node2服务器的同名路径下
scp -r jdk node2:$PWD      # 将本机当前路径的jdk文件夹，复制到node2服务器的同名路径下
```











# Zookeeper集群安装部署

## 简介

ZooKeeper是一个[分布式](https://baike.baidu.com/item/分布式/19276232?fromModule=lemma_inlink)的，开放源码的[分布式应用程序](https://baike.baidu.com/item/分布式应用程序/9854429?fromModule=lemma_inlink)协调服务，是Hadoop和[Hbase](https://baike.baidu.com/item/Hbase/7670213?fromModule=lemma_inlink)的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。



除了为Hadoop和HBase提供协调服务外，Zookeeper也被其它许多软件采用作为其分布式状态一致性的依赖，比如Kafka，又或者一些软件项目中，也经常能见到Zookeeper作为一致性协调服务存在。



Zookeeper不论是大数据领域亦或是其它服务器开发领域，涉及到分布式状态一致性的场景，总有它的身影存在。



## 安装

Zookeeper是一款分布式的集群化软件，可以在多台服务器上部署，并协同组成分布式集群一起工作。



1. 首先，要确保已经完成了`集群化环境前置准备`环节的全部内容

2. 【node1上操作】下载Zookeeper安装包，并解压

   ```shell
   # 下载
   wget http://archive.apache.org/dist/zookeeper/zookeeper-3.5.9/apache-zookeeper-3.5.9-bin.tar.gz
   
   # 确保如下目录存在，不存在就创建
   mkdir -p /export/server
   
   # 解压
   tar -zxvf apache-zookeeper-3.5.9-bin.tar.gz -C /export/server
   ```

3. 【node1上操作】创建软链接

   ```shell
   ln -s /export/server/apache-zookeeper-3.5.9 /export/server/zookeeper
   ```

4. 【node1上操作】修改配置文件

   ```shell
   vim /export/server/zookeeper/conf/zoo.cfg
   
   tickTime=2000
   # zookeeper数据存储目录
   dataDir=/export/server/zookeeper/data
   clientPort=2181
   initLimit=5
   syncLimit=2
   server.1=node1:2888:3888
   server.2=node2:2888:3888
   server.3=node3:2888:3888
   ```

5. 【node1上操作】配置`myid`

   ```shell
   # 1. 创建Zookeeper的数据目录
   mkdir /export/server/zookeeper/data
   
   # 2. 创建文件，并填入1
   vim /export/server/zookeeper/data/myid
   # 在文件内填入1即可
   ```

6. 【在node2和node3上操作】，创建文件夹

   ```shell
   mkdir -p /export/server
   ```

7. 【node1上操作】将Zookeeper 复制到node2和node3

   ```shell
   cd /export/server
   
   scp -r apache-zookeeper-3.5.9 node2:`pwd`/
   scp -r apache-zookeeper-3.5.9 node3:`pwd`/
   ```

8. 【在node2上操作】

   ```shell
   # 1. 创建软链接
   ln -s /export/server/apache-zookeeper-3.5.9 /export/server/zookeeper
   
   # 2. 修改myid文件
   vim /export/server/zookeeper/data/myid
   # 修改内容为2
   ```

9. 【在node3上操作】

   ```shell
   # 1. 创建软链接
   ln -s /export/server/apache-zookeeper-3.5.9 /export/server/zookeeper
   
   # 2. 修改myid文件
   vim /export/server/zookeeper/data/myid
   # 修改内容为3
   ```

10. 【在node1、node2、node3上分别执行】启动Zookeeper

    ```shell
    # 启动命令
    /export/server/zookeeper/bin/zkServer.sh start		# 启动Zookeeper
    ```

11. 【在node1、node2、node3上分别执行】检查Zookeeper进程是否启动

    ```shell
    jps
    
    # 结果中找到有：QuorumPeerMain 进程即可
    ```

12. 【node1上操作】验证Zookeeper

    ```shell
    /export/server/zookeeper/zkCli.sh
    
    # 进入到Zookeeper控制台中后，执行
    ls /
    
    # 如无报错即配置成功
    ```



至此Zookeeper安装完成







# Kafka集群安装部署

## 简介

Kafka是一款`分布式的、去中心化的、高吞吐低延迟、订阅模式`的消息队列系统。



同RabbitMQ一样，Kafka也是消息队列。不过RabbitMQ多用于后端系统，因其更加专注于消息的延迟和容错。

Kafka多用于大数据体系，因其更加专注于数据的吞吐能力。

Kafka多数都是运行在分布式（集群化）模式下，所以课程将以3台服务器，来完成Kafka集群的安装部署。



## 安装



1. 确保已经跟随前面的视频，安装并部署了JDK和Zookeeper服务

   > Kafka的运行依赖JDK环境和Zookeeper请确保已经有了JDK环境和Zookeeper

2. 【在node1操作】下载并上传Kafka的安装包

   ```shell
   # 下载安装包
   wget http://archive.apache.org/dist/kafka/2.4.1/kafka_2.12-2.4.1.tgz
   ```

3. 【在node1操作】解压

   ```shell
   mkdir -p /export/server			# 此文件夹如果不存在需先创建
   
   # 解压
   tar -zxvf kafka_2.12-2.4.1.tgz -C /export/server/
   
   # 创建软链接
   ln -s /export/server/kafka_2.12-2.4.1 /export/server/kafka
   ```

4. 【在node1操作】修改Kafka目录内的config目录内的`server.properties`文件

   ````shell
   cd /export/server/kafka/config
   # 指定broker的id
   broker.id=1
   # 指定 kafka的绑定监听的地址
   listeners=PLAINTEXT://node1:9092
   # 指定Kafka数据的位置
   log.dirs=/export/server/kafka/data
   # 指定Zookeeper的三个节点
   zookeeper.connect=node1:2181,node2:2181,node3:2181
   ````

5. 【在node1操作】将node1的kafka复制到node2和node3

   ```shell
   cd /export/server
   
   # 复制到node2同名文件夹
   scp -r kafka_2.12-2.4.1 node2:`pwd`/
   # 复制到node3同名文件夹
   scp -r kafka_2.12-2.4.1 node3:$PWD
   ```

6. 【在node2操作】

   ```shell
   # 创建软链接
   ln -s /export/server/kafka_2.12-2.4.1 /export/server/kafka
   
   cd /export/server/kafka/config
   # 指定broker的id
   broker.id=2
   # 指定 kafka的绑定监听的地址
   listeners=PLAINTEXT://node2:9092
   # 指定Kafka数据的位置
   log.dirs=/export/server/kafka/data
   # 指定Zookeeper的三个节点
   zookeeper.connect=node1:2181,node2:2181,node3:2181
   ```

7. 【在node3操作】

   ```shell
   # 创建软链接
   ln -s /export/server/kafka_2.12-2.4.1 /export/server/kafka
   
   cd /export/server/kafka/config
   # 指定broker的id
   broker.id=3
   # 指定 kafka的绑定监听的地址
   listeners=PLAINTEXT://node3:9092
   # 指定Kafka数据的位置
   log.dirs=/export/server/kafka/data
   # 指定Zookeeper的三个节点
   zookeeper.connect=node1:2181,node2:2181,node3:2181
   ```

8. 启动kafka

   ```shell
   # 请先确保Zookeeper已经启动了
   
   # 方式1：【前台启动】分别在node1、2、3上执行如下语句
   /export/server/kafka/bin/kafka-server-start.sh /export/server/kafka/config/server.properties
   
   # 方式2：【后台启动】分别在node1、2、3上执行如下语句
   nohup /export/server/kafka/bin/kafka-server-start.sh /export/server/kafka/config/server.properties 2>&1 >> /export/server/kafka/kafka-server.log &
   ```

9. 验证Kafka启动

   ```shell
   # 在每一台服务器执行
   jps
   ```

   ![image-20221025174522487](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/25/20221025174522.png)





## 测试Kafka能否正常使用

1. 创建测试主题

```shell
# 在node1执行，创建一个主题
/export/server/kafka_2.12-2.4.1/bin/kafka-topics.sh --create --zookeeper node1:2181 --replication-factor 1 --partitions 3 --topic test
```

2. 运行测试，请在FinalShell中打开2个node1的终端页面

```shell
# 打开一个终端页面，启动一个模拟的数据生产者
/export/server/kafka_2.12-2.4.1/bin/kafka-console-producer.sh --broker-list node1:9092 --topic test
# 再打开一个新的终端页面，在启动一个模拟的数据消费者
/export/server/kafka_2.12-2.4.1/bin/kafka-console-consumer.sh --bootstrap-server node1:9092 --topic test --from-beginning
```





# 大数据集群（Hadoop生态）安装部署

## 简介

1）Hadoop是一个由Apache基金会所开发的分布式系统基础架构。
2）主要解决，海量数据的存储和海量数据的分析计算问题。

Hadoop HDFS 提供分布式海量数据存储能力

Hadoop YARN 提供分布式集群资源管理能力

Hadoop MapReduce 提供分布式海量数据计算能力





### 前置要求

- 请确保完成了集群化环境前置准备章节的内容
- 即：JDK、SSH免密、关闭防火墙、配置主机名映射等前置操作



### Hadoop集群角色

Hadoop生态体系中总共会出现如下进程角色：

1. Hadoop HDFS的管理角色：Namenode进程（`仅需1个即可（管理者一个就够）`）
2. Hadoop HDFS的工作角色：Datanode进程（`需要多个（工人，越多越好，一个机器启动一个）`）
3. Hadoop YARN的管理角色：ResourceManager进程（`仅需1个即可（管理者一个就够）`）
4. Hadoop YARN的工作角色：NodeManager进程（`需要多个（工人，越多越好，一个机器启动一个）`）
5. Hadoop 历史记录服务器角色：HistoryServer进程（`仅需1个即可（功能进程无需太多1个足够）`）
6. Hadoop 代理服务器角色：WebProxyServer进程（`仅需1个即可（功能进程无需太多1个足够）`）
7. Zookeeper的进程：QuorumPeerMain进程（`仅需1个即可（Zookeeper的工作者，越多越好）`）





### 角色和节点分配



角色分配如下：

1. node1:Namenode、Datanode、ResourceManager、NodeManager、HistoryServer、WebProxyServer、QuorumPeerMain
2. node2:Datanode、NodeManager、QuorumPeerMain
3. node3:Datanode、NodeManager、QuorumPeerMain

![image-20221026202935745](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/26/20221026202935.png)



## 安装

### 调整虚拟机内存

如上图，可以看出node1承载了太多的压力。同时node2和node3也同时运行了不少程序

为了确保集群的稳定，需要对虚拟机进行内存设置。



请在VMware中，对：

1. node1设置4GB或以上内存
2. node2和node3设置2GB或以上内存



> 大数据的软件本身就是集群化（一堆服务器）一起运行的。
>
> 现在我们在一台电脑中以多台虚拟机来模拟集群，确实会有很大的内存压力哦。



### Zookeeper集群部署

略



### Hadoop集群部署

1. 下载Hadoop安装包、解压、配置软链接

   ```shell
   # 1. 下载
   wget http://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
   
   # 2. 解压
   # 请确保目录/export/server存在
   tar -zxvf hadoop-3.3.0.tar.gz -C /export/server/
   
   # 3. 构建软链接
   ln -s /export/server/hadoop-3.3.0 /export/server/hadoop
   ```

2. 修改配置文件：`hadoop-env.sh`

   > Hadoop的配置文件要修改的地方很多，请细心

   cd 进入到/export/server/hadoop/etc/hadoop，文件夹中，配置文件都在这里

   修改hadoop-env.sh文件

   > 此文件是配置一些Hadoop用到的环境变量
   >
   > 这些是临时变量，在Hadoop运行时有用
   >
   > 如果要永久生效，需要写到/etc/profile中

   ```shell
   # 在文件开头加入：
   # 配置Java安装路径
   export JAVA_HOME=/export/server/jdk
   # 配置Hadoop安装路径
   export HADOOP_HOME=/export/server/hadoop
   # Hadoop hdfs配置文件路径
   export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
   # Hadoop YARN配置文件路径
   export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
   # Hadoop YARN 日志文件夹
   export YARN_LOG_DIR=$HADOOP_HOME/logs/yarn
   # Hadoop hdfs 日志文件夹
   export HADOOP_LOG_DIR=$HADOOP_HOME/logs/hdfs
   
   # Hadoop的使用启动用户配置
   export HDFS_NAMENODE_USER=root
   export HDFS_DATANODE_USER=root
   export HDFS_SECONDARYNAMENODE_USER=root
   export YARN_RESOURCEMANAGER_USER=root
   export YARN_NODEMANAGER_USER=root
   export YARN_PROXYSERVER_USER=root
   ```

3. 修改配置文件：`core-site.xml`

   如下，清空文件，填入如下内容

   ```xml
   <?xml version="1.0" encoding="UTF-8"?>
   <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
   <!--
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
   
       http://www.apache.org/licenses/LICENSE-2.0
   
     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License. See accompanying LICENSE file.
   -->
   
   <!-- Put site-specific property overrides in this file. -->
   <configuration>
     <property>
       <name>fs.defaultFS</name>
       <value>hdfs://node1:8020</value>
       <description></description>
     </property>
   
     <property>
       <name>io.file.buffer.size</name>
       <value>131072</value>
       <description></description>
     </property>
   </configuration>
   ```

4. 配置：`hdfs-site.xml`文件

   ```xml
   <?xml version="1.0" encoding="UTF-8"?>
   <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
   <!--
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
   
       http://www.apache.org/licenses/LICENSE-2.0
   
     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License. See accompanying LICENSE file.
   -->
   
   <!-- Put site-specific property overrides in this file. -->
   
   <configuration>
       <property>
           <name>dfs.datanode.data.dir.perm</name>
           <value>700</value>
       </property>
   
     <property>
       <name>dfs.namenode.name.dir</name>
       <value>/data/nn</value>
       <description>Path on the local filesystem where the NameNode stores the namespace and transactions logs persistently.</description>
     </property>
   
     <property>
       <name>dfs.namenode.hosts</name>
       <value>node1,node2,node3</value>
       <description>List of permitted DataNodes.</description>
     </property>
   
     <property>
       <name>dfs.blocksize</name>
       <value>268435456</value>
       <description></description>
     </property>
   
   
     <property>
       <name>dfs.namenode.handler.count</name>
       <value>100</value>
       <description></description>
     </property>
   
     <property>
       <name>dfs.datanode.data.dir</name>
       <value>/data/dn</value>
     </property>
   </configuration>
   ```

5. 配置：`mapred-env.sh`文件

   ```shell
   # 在文件的开头加入如下环境变量设置
   export JAVA_HOME=/export/server/jdk
   export HADOOP_JOB_HISTORYSERVER_HEAPSIZE=1000
   export HADOOP_MAPRED_ROOT_LOGGER=INFO,RFA
   ```

6. 配置：`mapred-site.xml`文件

   ```xml
   <?xml version="1.0"?>
   <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
   <!--
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
   
       http://www.apache.org/licenses/LICENSE-2.0
   
     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License. See accompanying LICENSE file.
   -->
   
   <!-- Put site-specific property overrides in this file. -->
   
   <configuration>
     <property>
       <name>mapreduce.framework.name</name>
       <value>yarn</value>
       <description></description>
     </property>
   
     <property>
       <name>mapreduce.jobhistory.address</name>
       <value>node1:10020</value>
       <description></description>
     </property>
   
   
     <property>
       <name>mapreduce.jobhistory.webapp.address</name>
       <value>node1:19888</value>
       <description></description>
     </property>
   
   
     <property>
       <name>mapreduce.jobhistory.intermediate-done-dir</name>
       <value>/data/mr-history/tmp</value>
       <description></description>
     </property>
   
   
     <property>
       <name>mapreduce.jobhistory.done-dir</name>
       <value>/data/mr-history/done</value>
       <description></description>
     </property>
   <property>
     <name>yarn.app.mapreduce.am.env</name>
     <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
   </property>
   <property>
     <name>mapreduce.map.env</name>
     <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
   </property>
   <property>
     <name>mapreduce.reduce.env</name>
     <value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
   </property>
   </configuration>
   ```

7. 配置：`yarn-env.sh`文件

   ```shell
   # 在文件的开头加入如下环境变量设置
   export JAVA_HOME=/export/server/jdk
   export HADOOP_HOME=/export/server/hadoop
   export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
   export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
   export YARN_LOG_DIR=$HADOOP_HOME/logs/yarn
   export HADOOP_LOG_DIR=$HADOOP_HOME/logs/hdfs
   ```

8. 配置：`yarn-site.xml`文件

   ```xml
   <?xml version="1.0"?>
   <!--
     Licensed under the Apache License, Version 2.0 (the "License");
     you may not use this file except in compliance with the License.
     You may obtain a copy of the License at
   
       http://www.apache.org/licenses/LICENSE-2.0
   
     Unless required by applicable law or agreed to in writing, software
     distributed under the License is distributed on an "AS IS" BASIS,
     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     See the License for the specific language governing permissions and
     limitations under the License. See accompanying LICENSE file.
   -->
   <configuration>
   
   <!-- Site specific YARN configuration properties -->
   <property>
       <name>yarn.log.server.url</name>
       <value>http://node1:19888/jobhistory/logs</value>
       <description></description>
   </property>
   
     <property>
       <name>yarn.web-proxy.address</name>
       <value>node1:8089</value>
       <description>proxy server hostname and port</description>
     </property>
   
   
     <property>
       <name>yarn.log-aggregation-enable</name>
       <value>true</value>
       <description>Configuration to enable or disable log aggregation</description>
     </property>
   
     <property>
       <name>yarn.nodemanager.remote-app-log-dir</name>
       <value>/tmp/logs</value>
       <description>Configuration to enable or disable log aggregation</description>
     </property>
   
   
   <!-- Site specific YARN configuration properties -->
     <property>
       <name>yarn.resourcemanager.hostname</name>
       <value>node1</value>
       <description></description>
     </property>
   
     <property>
       <name>yarn.resourcemanager.scheduler.class</name>
       <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler</value>
       <description></description>
     </property>
   
     <property>
       <name>yarn.nodemanager.local-dirs</name>
       <value>/data/nm-local</value>
       <description>Comma-separated list of paths on the local filesystem where intermediate data is written.</description>
     </property>
   
   
     <property>
       <name>yarn.nodemanager.log-dirs</name>
       <value>/data/nm-log</value>
       <description>Comma-separated list of paths on the local filesystem where logs are written.</description>
     </property>
   
   
     <property>
       <name>yarn.nodemanager.log.retain-seconds</name>
       <value>10800</value>
       <description>Default time (in seconds) to retain log files on the NodeManager Only applicable if log-aggregation is disabled.</description>
     </property>
   
   
   
     <property>
       <name>yarn.nodemanager.aux-services</name>
       <value>mapreduce_shuffle</value>
       <description>Shuffle service that needs to be set for Map Reduce applications.</description>
     </property>
   </configuration>
   ```

9. 修改workers文件

   ```shell
   # 全部内容如下
   node1
   node2
   node3
   ```

10. 分发hadoop到其它机器

   ```shell
   # 在node1执行
   cd /export/server
   
   scp -r hadoop-3.3.0 node2:`pwd`/
   scp -r hadoop-3.3.0 node2:`pwd`/
   ```

11. 在node2、node3执行

    ```shell
    # 创建软链接
    ln -s /export/server/hadoop-3.3.0 /export/server/hadoop
    ```

12. 创建所需目录

    - 在node1执行：

      ```shell
      mkdir -p /data/nn
      mkdir -p /data/dn
      mkdir -p /data/nm-log
      mkdir -p /data/nm-local
      ```

    - 在node2执行：

      ```shell
      mkdir -p /data/dn
      mkdir -p /data/nm-log
      mkdir -p /data/nm-local
      ```

    - 在node3执行：

      ```shell
      mkdir -p /data/dn
      mkdir -p /data/nm-log
      mkdir -p /data/nm-local
      ```

13. 配置环境变量

    在node1、node2、node3修改/etc/profile

    ```shell
    export HADOOP_HOME=/export/server/hadoop
    export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
    ```

    执行`source /etc/profile`生效

14. 格式化NameNode，在node1执行

    ```shell
    hadoop namenode -format
    ```

    > hadoop这个命令来自于：$HADOOP_HOME/bin中的程序
    >
    > 由于配置了环境变量PATH，所以可以在任意位置执行hadoop命令哦

15. 启动hadoop的hdfs集群，在node1执行即可

    ```shell
    start-dfs.sh
    
    # 如需停止可以执行
    stop-dfs.sh
    ```

    > start-dfs.sh这个命令来自于：$HADOOP_HOME/sbin中的程序
    >
    > 由于配置了环境变量PATH，所以可以在任意位置执行start-dfs.sh命令哦

16. 启动hadoop的yarn集群，在node1执行即可

    ```shell
    start-yarn.sh
    
    # 如需停止可以执行
    stop-yarn.sh
    ```

17. 启动历史服务器

    ```shell
    mapred --daemon start historyserver
    
    # 如需停止将start更换为stop
    ```

18. 启动web代理服务器

    ```shell
    yarn-daemon.sh start proxyserver
    
    # 如需停止将start更换为stop
    ```



#### 验证Hadoop集群运行情况

1. 在node1、node2、node3上通过jps验证进程是否都启动成功

2. 验证HDFS，浏览器打开：http://node1:9870

   创建文件test.txt，随意填入内容，并执行：

   ```shell
   hadoop fs -put test.txt /test.txt
   
   hadoop fs -cat /test.txt
   ```

3. 验证YARN，浏览器打开：http://node1:8088

   执行：

   ```shell
   # 创建文件words.txt，填入如下内容
   itheima itcast hadoop
   itheima hadoop hadoop
   itheima itcast
   
   # 将文件上传到HDFS中
   hadoop fs -put words.txt /words.txt
   
   # 执行如下命令验证YARN是否正常
   hadoop jar /export/server/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar wordcount -Dmapred.job.queue.name=root.root /words.txt /output
   ```



# 大数据NoSQL数据库HBase集群部署

## 简介

HBase 是一种[分布式](https://so.csdn.net/so/search?q=分布式&spm=1001.2101.3001.7020)、可扩展、支持海量数据存储的 NoSQL 数据库。



和Redis一样，HBase是一款KeyValue型存储的数据库。

不过和Redis设计方向不同

- Redis设计为少量数据，超快检索
- HBase设计为海量数据，快速检索

HBase在大数据领域应用十分广泛，现在我们来在node1、node2、node3上部署HBase集群。



## 安装



1. HBase依赖Zookeeper、JDK、Hadoop（HDFS），请确保已经完成前面

   - 集群化软件前置准备（JDK）
   - Zookeeper
   - Hadoop
   - 这些环节的软件安装

2. 【node1执行】下载HBase安装包

   ```shell
   # 下载
   wget http://archive.apache.org/dist/hbase/2.1.0/hbase-2.1.0-bin.tar.gz
   
   # 解压
   tar -zxvf hbase-2.1.0-bin.tar.gz -C /export/server
   
   # 配置软链接
   ln -s /export/server/hbase-2.1.0 /export/server/hbase
   ```

3. 【node1执行】，修改配置文件，修改`conf/hbase-env.sh`文件

   ```shell
   # 在28行配置JAVA_HOME
   export JAVA_HOME=/export/server/jdk
   # 在126行配置：
   # 意思表示，不使用HBase自带的Zookeeper，而是用独立Zookeeper
   export HBASE_MANAGES_ZK=false
   # 在任意行，比如26行，添加如下内容：
   export HBASE_DISABLE_HADOOP_CLASSPATH_LOOKUP="true"
   ```

4. 【node1执行】，修改配置文件，修改`conf/hbase-site.xml`文件

   ```shell
   # 将文件的全部内容替换成如下内容：
   <configuration>
           <!-- HBase数据在HDFS中的存放的路径 -->
           <property>
               <name>hbase.rootdir</name>
               <value>hdfs://node1:8020/hbase</value>
           </property>
           <!-- Hbase的运行模式。false是单机模式，true是分布式模式。若为false,Hbase和Zookeeper会运行在同一个JVM里面 -->
           <property>
               <name>hbase.cluster.distributed</name>
               <value>true</value>
           </property>
           <!-- ZooKeeper的地址 -->
           <property>
               <name>hbase.zookeeper.quorum</name>
               <value>node1,node2,node3</value>
           </property>
           <!-- ZooKeeper快照的存储位置 -->
           <property>
               <name>hbase.zookeeper.property.dataDir</name>
               <value>/export/server/apache-zookeeper-3.6.0-bin/data</value>
           </property>
           <!--  V2.1版本，在分布式情况下, 设置为false -->
           <property>
               <name>hbase.unsafe.stream.capability.enforce</name>
               <value>false</value>
           </property>
   </configuration>
   ```

5. 【node1执行】，修改配置文件，修改`conf/regionservers`文件

   ```shell
   # 填入如下内容
   node1
   node2
   node3
   ```

6. 【node1执行】，分发hbase到其它机器

   ```shell
   scp -r /export/server/hbase-2.1.0 node2:/export/server/
   scp -r /export/server/hbase-2.1.0 node3:/export/server/
   ```

7. 【node2、node3执行】，配置软链接

   ```shell
   ln -s /export/server/hbase-2.1.0 /export/server/hbase
   ```

8. 【node1、node2、node3执行】，配置环境变量

   ```shell
   # 配置在/etc/profile内，追加如下两行
   export HBASE_HOME=/export/server/hbase
   export PATH=$HBASE_HOME/bin:$PATH
   
   source /etc/profile
   ```

9. 【node1执行】启动HBase

   > 请确保：Hadoop HDFS、Zookeeper是已经启动了的

   ```shell
   start-hbase.sh
   
   # 如需停止可使用
   stop-hbase.sh
   ```

   > 由于我们配置了环境变量export PATH=$PATH:$HBASE_HOME/bin
   >
   > start-hbase.sh即在$HBASE_HOME/bin内，所以可以无论当前目录在哪，均可直接执行

10. 验证HBase

    浏览器打开：http://node1:16010，即可看到HBase的WEB UI页面

11. 简单测试使用HBase

    【node1执行】

    ```shell
    hbase shell
    
    # 创建表
    create 'test', 'cf'
    
    # 插入数据
    put 'test', 'rk001', 'cf:info', 'itheima'
    
    # 查询数据
    get 'test', 'rk001'
    
    # 扫描表数据
    scan 'test'
    ```





# 分布式内存计算Spark环境部署

## 注意

本小节的操作，基于：`大数据集群（Hadoop生态）安装部署`环节中所构建的Hadoop集群

如果没有Hadoop集群，请参阅前置内容，部署好环境。



## 简介

Spark是一款分布式内存计算引擎，可以支撑海量数据的分布式计算。



Spark在大数据体系是明星产品，作为最新一代的综合计算引擎，支持离线计算和实时计算。

在大数据领域广泛应用，是目前世界上使用最多的大数据分布式计算引擎。



我们将基于前面构建的Hadoop集群，部署Spark Standalone集群。



## 安装



1. 【node1执行】下载并解压

   ```shell
   wget https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz
   
   # 解压
   tar -zxvf spark-2.4.5-bin-hadoop2.7.tgz -C /export/server/
   
   # 软链接
   ln -s /export/server/spark-2.4.5-bin-hadoop2.7 /export/server/spark
   ```

2. 【node1执行】修改配置文件名称

   ```shell
   # 改名
   cd /export/server/spark/conf
   mv spark-env.sh.template spark-env.sh
   mv slaves.template slaves
   ```

3. 【node1执行】修改配置文件，`spark-env.sh`

   ```shell
   ## 设置JAVA安装目录
   JAVA_HOME=/export/server/jdk
   
   ## HADOOP软件配置文件目录，读取HDFS上文件和运行YARN集群
   HADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop
   YARN_CONF_DIR=/export/server/hadoop/etc/hadoop
   
   ## 指定spark老大Master的IP和提交任务的通信端口
   export SPARK_MASTER_HOST=node1
   export SPARK_MASTER_PORT=7077
   
   SPARK_MASTER_WEBUI_PORT=8080
   SPARK_WORKER_CORES=1
   SPARK_WORKER_MEMORY=1g
   ```

4. 【node1执行】修改配置文件，`slaves`

   ```shell
   node1
   node2
   node3
   ```

5. 【node1执行】分发

   ```shell
   scp -r spark-2.4.5-bin-hadoop2.7 node2:$PWD
   scp -r spark-2.4.5-bin-hadoop2.7 node3:$PWD
   ```

6. 【node2、node3执行】设置软链接

   ```shell
   ln -s /export/server/spark-2.4.5-bin-hadoop2.7 /export/server/spark
   ```

7. 【node1执行】启动Spark集群

   ```shell
   /export/server/spark/sbin/start-all.sh
   
   # 如需停止，可以
   /export/server/spark/sbin/stop-all.sh
   ```

8. 打开Spark监控页面，浏览器打开：http://node1:8081

9. 【node1执行】提交测试任务

   ```shell
   /export/server/spark/bin/spark-submit --master spark://node1:7077 --class org.apache.spark.examples.SparkPi /export/server/spark/examples/jars/spark-examples_2.11-2.4.5.jar
   ```







# 分布式内存计算Flink环境部署

## 注意

本小节的操作，基于：`大数据集群（Hadoop生态）安装部署`环节中所构建的Hadoop集群

如果没有Hadoop集群，请参阅前置内容，部署好环境。



## 简介

Flink同Spark一样，是一款分布式内存计算引擎，可以支撑海量数据的分布式计算。



Flink在大数据体系同样是明星产品，作为最新一代的综合计算引擎，支持离线计算和实时计算。

在大数据领域广泛应用，是目前世界上除去Spark以外，应用最为广泛的分布式计算引擎。



我们将基于前面构建的Hadoop集群，部署Flink Standalone集群

Spark更加偏向于离线计算而Flink更加偏向于实时计算。



## 安装



1. 【node1操作】下载安装包

   ```shell
   wget https://archive.apache.org/dist/flink/flink-1.10.0/flink-1.10.0-bin-scala_2.11.tgz
   
   # 解压
   tar -zxvf flink-1.10.0-bin-scala_2.11.tgz -C /export/server/
   
   # 软链接
   ln -s /export/server/flink-1.10.0 /export/server/flink
   ```

2. 【node1操作】修改配置文件，`conf/flink-conf.yaml`

   ```yaml
   # jobManager 的IP地址
   jobmanager.rpc.address: node1
   # JobManager 的端口号
   jobmanager.rpc.port: 6123
   # JobManager JVM heap 内存大小
   jobmanager.heap.size: 1024m
   # TaskManager JVM heap 内存大小
   taskmanager.heap.size: 1024m
   # 每个 TaskManager 提供的任务 slots 数量大小
   taskmanager.numberOfTaskSlots: 2
   #是否进行预分配内存，默认不进行预分配，这样在我们不使用flink集群时候不会占用集群资源
   taskmanager.memory.preallocate: false
   # 程序默认并行计算的个数
   parallelism.default: 1
   #JobManager的Web界面的端口（默认：8081）
   jobmanager.web.port: 8081
   ```

3. 【node1操作】，修改配置文件，`conf/slaves`

   ```shell
   node1
   node2
   node3
   ```

4. 【node1操作】分发Flink安装包到其它机器

   ```shell
   cd /export/server
   scp -r flink-1.10.0 node2:`pwd`/
   scp -r flink-1.10.0 node3:`pwd`/
   ```

5. 【node2、node3操作】

   ```shell
   # 配置软链接
   ln -s /export/server/flink-1.10.0 /export/server/flink
   ```

6. 【node1操作】，启动Flink

   ```shell
   /export/server/flink/bin/start-cluster.sh
   ```

7. 验证Flink启动

   ```shell
   # 浏览器打开
   http://node1:8081
   ```

8. 提交测试任务

   【node1执行】

   ```shell
   /export/server/flink/bin/flink run /export/server/flink-1.10.0/examples/batch/WordCount.jar
   ```







# 运维监控Zabbix部署

## 简介

Zabbix 由 Alexei Vladishev 创建，目前由其成立的公司—— Zabbix SIA 积极的持续开发更新维护， 并为用户提供技术支持服务。

Zabbix 是一个==企业级分布式开源监控解决方案==。

Zabbix 软件能够==监控==众多网络参数和服务器的==健康度、完整性==。Zabbix 使用灵活的告警机制，允许用户为几乎任何事件配置基于邮件的告警。这样用户可以快速响应服务器问题。Zabbix 基于存储的数据提供出色的报表和数据可视化功能。这些功能使得 Zabbix 成为容量规划的理想选择。



## 安装



>  安装整体步骤:

1. 准备Linux 服务器(虚拟机)
2. 安装Mysql
3. 安装zabbix( 包含 server  agent  web)
4. 配置 mysql, 为zabbix创建表结构
5. 配置zabbix server
6. 启动并开启开机自启动



![1574338996145](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/26/20221026175324.png)



### 安装前准备 - Mysql

安装ZabbixServer需要先安装好`Mysql`数据库

课程使用`Mysql 5.7`

安装步骤：

```shell
# 安装Mysql yum库
rpm -Uvh http://repo.mysql.com//mysql57-community-release-el7-7.noarch.rpm

# yum安装Mysql
yum -y install mysql-community-server

# 启动Mysql设置开机启动
systemctl start mysqld
systemctl enable mysqld

# 检查Mysql服务状态
systemctl status mysqld

# 第一次启动mysql，会在日志文件中生成root用户的一个随机密码，使用下面命令查看该密码
grep 'temporary password' /var/log/mysqld.log

# 修改root用户密码
mysql -u root -p -h localhost
Enter password:
 
mysql> ALTER USER 'root'@'localhost' IDENTIFIED BY 'Root!@#$';

# 如果你想设置简单密码，需要降低Mysql的密码安全级别
set global validate_password_policy=LOW; # 密码安全级别低
set global validate_password_length=4;	 # 密码长度最低4位即可

# 然后就可以用简单密码了（课程中使用简单密码，为了方便，生产中不要这样）
ALTER USER 'root'@'localhost' IDENTIFIED BY 'root';
mysql> grant all privileges on *.* to root@'%' identified by 'root';
```





### 安装Zabbix Server 和 Zabbix Agent

> 初始安装，我们先安装ZabbixServer以及在Server本机安装Agent。

打开官网下载页面：https://www.zabbix.com/download?zabbix=4.0&os_distribution=centos&os_version=7&db=mysql

![1571981197131](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/26/20221026175330.png)

选择对应的版本，然后再下面官网给出了具体的安装命令，使用`rpm`和`yum`来进行安装。

需要有网络。



`以下内容来自官方页面`

#### a. 安装Zabbix yum库

[documentation](https://www.zabbix.com/documentation/4.0/manual/installation/install_from_packages)

```shell
rpm -Uvh https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-2.el7.noarch.rpm
yum clean all
```

#### b. 安装Zabbix Server、前端、Agent

```shell
yum -y install zabbix-server-mysql zabbix-web-mysql zabbix-agent
# 如果只需要安装Agent的话
yum -y install zabbix-agent
```

#### c. 初始化Mysql数据库

[documentation](https://www.zabbix.com/documentation/4.0/manual/appendix/install/db_scripts)

> 在Mysql中操作

```shell
# 登录Mysql 数据库
mysql -uroot -pYourPassword
mysql> create database zabbix character set utf8 collate utf8_bin;
mysql> grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix';
# 或者: grant all privileges on zabbix.* to zabbix@'%' identified by 'zabbix';
mysql> quit;
```

测试在Zabbix Server服务器上能否远程登录Mysql，如果可以登录继续向下走。

Import initial schema and data. You will be prompted to enter your newly created password.

```shell
# zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix
```

#### d. 为Zabbix Server配置数据库

Edit file /etc/zabbix/zabbix_server.conf

```shell
DBPassword=password
DBHost=mysql-host-ip-or-hostname
```

#### e. 配置Zabbix的PHP前端

Edit file `/etc/httpd/conf.d/zabbix.conf`, uncomment and set the right timezone for you.`# php_value date.timezone Asia/Shanghai`

Start Zabbix server and agent processes and make it start at system boot:

```shell
systemctl restart zabbix-server zabbix-agent httpd # 启动、重启
systemctl enable zabbix-server zabbix-agent httpd  # 开机自启
```

Now your Zabbix server is up and running!



### 配置zabbix 前端（WEB UI）

**打开:`http://192.168.88.131/zabbix`**

即可进入Zabbix页面，在首次打开的时候，会进入设置页面，如图：

![1571993951841](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/26/20221026175338.png)

**点击下一步，会检查相应的设置是否都正常**

![1571994018126](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/26/20221026175341.png)

如果一切正常，点击下一步。



**配置DB连接**

![1571994069689](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/26/20221026175344.png)

按具体情况填写即可



**配置Server细节**

![1571994111921](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/26/20221026175347.png)



具体配置即可，Name表示这个Zabbix服务的名字，这里起名叫`ITHEIMA-TEST`



**安装前总结预览**

检查确认没有问题就下一步

![1571994206902](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/26/20221026175349.png)

**配置完成**

![1571994221531](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/26/20221026175351.png)



**初始管理员账户Admin密码zabbix**



输入账户密码后，就能进入zabbix页面了。

如下图：

![1571994287036](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/26/20221026175354.png)

现在是一个崭新的zabbix等待我们去探索。









# 运维监控Grafana部署

## 简介



## 安装

### 部署形式

`Grafana`支持两种部署形式

1. 自行部署, 可以部署在操作系统之上. 自行提供服务器, 域名等.
2. `Grafana`官方托管. 无需安装, 在线注册即可得到一个专属于自己的`Grafana`, 但是要花钱的. 是一种`SaaS`服务

我们课程选择方式1

### 安装

`Grafana`支持常见的绝大多数操作系统, 如`windows` `mac` `linux` 同时也支持部署在`docker`中.

大多数情况下, `Grafana`都是部署在`linux`服务器之上. 所以本课程也是基于`Linux`系统来讲解.

对`windows` `mac`系统 或 `docker`部署有兴趣的同学, 请参考:  https://grafana.com/grafana/download



我们部署`Grafana`可以使用`YUM`来进行部署.

```shell
# 创建一个文件
vim /etc/yum.repos.d/grafana.repo

# 将下面的内容复制进去
[grafana]
name=grafana
baseurl=https://packages.grafana.com/oss/rpm
repo_gpgcheck=1
enabled=1
gpgcheck=1
gpgkey=https://packages.grafana.com/gpg.key
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt

# 最后安装
yum install grafana
```



### 配置说明

`grafana-server`具有许多配置选项，这些选项可以在`.ini`配置文件中指定，也可以使用环境变量指定。

>  **Note.** `Grafana ` needs to be restarted for any configuration changes to take effect. 

#### 配置文件注释

`;`符号在`.ini`文件中全局表示注释 ()

#### 配置文件路径

如果是自己解压安装, 或者自行编译的方式安装, 配置文件在:

- 默认: `$WORKING_DIR/conf/defaults.ini`
- 自定义:`$WORKING_DIR/conf/custom.ini`
- 自定义配置文件路径可以被参数`--config`覆盖

> 对于`YUM` `RPM` 安装的方式, 配置文件在: `/etc/grafana/grafana.ini`

#### 使用环境变量

可以使用以下语法使用环境变量来覆盖配置文件中的所有选项：

```bash
GF_<SectionName>_<KeyName>
```

其中`SectionName`是方括号内的文本。一切都应为大写，`.`应替换为`_` 例如，给定以下配置设置：

```bash
# default section
instance_name = ${HOSTNAME}

[security]
admin_user = admin

[auth.google]
client_secret = 0ldS3cretKey
```

Then you can override them using:

```bash
export GF_DEFAULT_INSTANCE_NAME=my-instance
export GF_SECURITY_ADMIN_USER=true	# GF_ 固定 SECURITY 是SectionName ADMIN_USER 是配置的key 转大写 . 转 _
export GF_AUTH_GOOGLE_CLIENT_SECRET=newS3cretKey
```



### 开始配置

`Grafana`支持使用`Sqlite3` `Postgresql` `Mysql`这三种数据库作为其`元数据`的存储.

我们课程使用`Mysql`. 和`zabbix`的元数据mysql共用一个实例

只需要配置如下内容即可:

![1573635500521](https://image-set.oss-cn-zhangjiakou.aliyuncs.com/img-out/2022/10/26/20221026175713.png)

并登陆mysql, 执行:

`create database grafana CHARACTER SET utf8 COLLATE utf8_general_ci;`

创建`Grafana`使用的数据库作为元数据存储.

### 启动

```bash
systemctl daemon-reload
systemctl start grafana-server
systemctl enable grafana-server
```



浏览器打开：http://node1:3000

默认账户密码：admin/admin



**7.9** 磁盘查看和分区类

**7.9****.1** **du** 查看文件和目录占用的磁盘空间

du: disk usage 磁盘占用情况

**1**）基本语法

du  目录/文件 （功能描述：显示目录下每个子目录的磁盘使用情况）

**2**）选项说明

表 7-26

 

| 选项          | 功能                                                       |
| ------------- | ---------------------------------------------------------- |
| -h            | 以人们较易阅读的 GBytes, MBytes,  KBytes  等格式自行显示； |
| - a           | 不仅查看子目录大小，还要包括文件                           |
| - c           | 显示所有的文件和子目录大小后，显示总和                     |
| -s            | 只显示总和                                                 |
| --max-depth=n | 指定统计子目录的深度为第 n 层                              |

**3**）案例实操

（1）查看当前用户主目录占用的磁盘空间大小

**7.9.2** **df** 查看磁盘空间使用情况

df: disk free 空余磁盘

**1**）基本语法

df 选项 （功能描述：列出文件系统的整体磁盘使用量，检查文件系统的磁盘空间占

用情况）

**2**）选项说明

| 选项 | 功能                                                       |
| ---- | ---------------------------------------------------------- |
| -h   | 以人们较易阅读的 GBytes, MBytes,  KBytes  等格式自行显示； |

**3**）案例实操

（1）查看磁盘使用情况

![文本框: [root@hadoop101 ~]# df -h Filesystem      Size  Used Avail Use% Mounted on /dev/sda2        15G  3.5G   11G  26% / tmpfs           939M  224K  939M   1% /dev/shm /dev/sda1       190M   39M  142M  22% /boot ](file:///C:/Users/Epiphany/AppData/Local/Temp/msohtmlclip1/01/clip_image001.gif)

**7****.****9****.****3** **ls****b****l****k** 查看设备挂载情况

 



**1**）基本语法

lsblk

**2**）选项说明

 

 





 

（功能描述：查看设备挂载情况）

 

 

表 7-28



 

| 选项 | 功能                                     |
| ---- | ---------------------------------------- |
| -f   | 查看详细的设备挂载情况，显示文件系统信息 |

**7****.****9****.****5** **m****oun****t/****u****m****oun****t** 挂载**/**卸载

对于Linux用户来讲，不论有几个分区，分别分给哪一个目录使用，它总归就是一个根 目录、一个独立且唯一的文件结构。

Linux中每个分区都是用来组成整个文件系统的一部分，它在用一种叫做“挂载”的处理 方法，它整个文件系统中包含了一整套的文件和目录，并将一个分区和一个目录联系起来，

要载入的那个分区将使它的存储空间在这个目录下获得。

**1**）挂载前准备（必须要有光盘或者已经连接镜像文件），如图 **7-5** ， **7-6** 所示

# 63.软件包管理

Ubuntu是德邦的，它使用的软件包管理工具是apt

centos是红帽的，红帽使用的包管理工具都是rpm

setup.exe主要负责软件的安装，其他功能是没有的，而rpm不仅可以安装，还可以卸载、更新，甚至可以从源码包里去build一个软件出来。

其他系统里面有些也是支持rpm软件包管理的

q：query，a：all，i：information，即查询出来要展示详细信息

**8.1** **R****PM**

**8.1.1** **RPM** 概述

RPM （RedHat Package Manager），RedHat软件包管理工具，类似windows里面的setup.exe 是Linux这系列操作系统里面的打包安装工具，它虽然是RedHat的标志，但理念是通用的。

RPM包的名称格式

Apache- 1.3.23- 11.i386.rpm

\-   “apache” 软件名称

\-   “1.3.23- 11”软件的版本号，主版本和此版本

\-   “i386”是软件所运行的硬件平台，Intel 32位处理器的统称

\-   “rpm”文件扩展名，代表RPM包

**8.1.2** **RPM** 查询命令（**rpm** **-qa**）

**1**）基本语法

rpm -qa                （功能描述：查询所安装的所有 rpm 软件包）

**2**）经验技巧

由于软件包比较多，一般都会采取过滤。rpm -qa | grep rpm软件包

**3**）案例实操

（1）查询firefox软件安装情况

![文本框: [root@hadoop101 Packages]# rpm -qa |grep firefox firefox-45.0.1-1.el6.centos.x86 64 _ ](file:///C:/Users/Epiphany/AppData/Local/Temp/msohtmlclip1/01/clip_image001.gif)

（1）查询firefox软件安装详细情况

rpm -qi firefox



**8.1.3** **RPM** 卸载命令（**rpm** **-e**）

**1**）基本语法

（1）rpm -e RPM软件包

（2） rpm -e --nodeps 软件包

**2**）选项说明

| 选项     | 功能                                                     |
| -------- | -------------------------------------------------------- |
| -e       | 卸载软件包                                               |
| --nodeps | 卸载软件时，不检查依赖。这样的话，那些使用该软件包的软件 |
|          | 在此之后可能就不能正常工作了。                           |

**3**）案例实操

（1）卸载firefox软件

![文本框: [root@hadoop101 Packages]# rpm -e firefox](file:///C:/Users/Epiphany/AppData/Local/Temp/msohtmlclip1/01/clip_image001.gif)

**8.1.4** **RPM** 安装命令（**rpm** **-ivh**）

**1**）基本语法

rpm -ivh RPM 包全名

**2**）选项说明

表 8-2

 

| 选项     | 功能                     |
| -------- | ------------------------ |
| -i       | install ，安装           |
| -v       | --verbose ，显示详细信息 |
| -h       | --hash ，进度条          |
| --nodeps | 安装前不检查依赖         |

**3**）案例实操

（1）安装firefox软件

![img](file:///C:/Users/Epiphany/AppData/Local/Temp/msohtmlclip1/01/clip_image002.gif)

**8.2.1** **YUM** 概述

YUM （全称为 Yellow dog Updater, Modified）是一个在 Fedora 和 RedHat 以及 CentOS 中的 Shell 前端软件包管理器。基于 RPM 包管理，能够从指定的服务器自动下载 RPM 包 并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软件包，无须繁琐地一次 次下载、安装，如图 8- 1 所示

![img](file:///C:/Users/Epiphany/AppData/Local/Temp/msohtmlclip1/01/clip_image001.jpg)

图 8- 1 YUM 概述

**8.2.2** **YUM** 的常用命令

**1**）基本语法

yum [选项] [参数]

**2**）选项说明

表 8-3

 

| 选项 | 功能                  |
| ---- | --------------------- |
| -y   | 对所有提问都回答“yes” |

**3**）参数说明

表 8-4

 

| 参数         | 功能                            |
| ------------ | ------------------------------- |
| install      | 安装 rpm 软件包                 |
| update       | 更新 rpm 软件包                 |
| check-update | 检查是否有可用的更新 rpm 软件包 |
| remove       | 删除指定的 rpm 软件包           |
| list         | 显示软件包信息                  |
| clean        | 清理 yum过期的缓存              |
| deplist      | 显示 yum软件包的所有依赖关系    |

**4**）案例实操实操

（1）采用 yum 方式安装 firefox

![文本框: [root@hadoop101 ~]#yum -y install firefox](file:///C:/Users/Epiphany/AppData/Local/Temp/msohtmlclip1/01/clip_image002.gif)

**8****.2.3** 修改网络 **YU****M** 源

默认的系统 YUM 源，需要连接国外 apache 网站，网速比较慢，可以修改关联的网络

YUM 源为国内镜像的网站，比如网易 163,aliyun 等

**1**）安装 wget, wget 用来从指定的 URL 下载文件

![文本框: [root@hadoop101 ~] yum install wget](file:///C:/Users/Epiphany/AppData/Local/Temp/msohtmlclip1/01/clip_image001.gif)

**2**）在/etc/yum.repos.d/目录下，备份默认的 repos 文件,

![文本框: [root@hadoop101 yum.repos.d] pwd /etc/yum.repos.d [root@hadoop101 yum.repos.d] cp CentOS-Base.repo   CentOS-Base .repo.backup ](file:///C:/Users/Epiphany/AppData/Local/Temp/msohtmlclip1/01/clip_image002.gif)

**3**）下载网易 163 或者是 aliyun 的 repos 文件,任选其一，如图 8-2

![文本框: [root@hadoop101 yum.repos.d] wget http://mirrors.aliyun.com/repo/Centos-7.repo  //阿里云 [root@hadoop101 yum.repos.d] wget http://mirrors.163.com/.help/CentOS7-Base-163.repo //网易 163 ](file:///C:/Users/Epiphany/AppData/Local/Temp/msohtmlclip1/01/clip_image003.gif)

![img](file:///C:/Users/Epiphany/AppData/Local/Temp/msohtmlclip1/01/clip_image004.jpg)

图 8-2

**4**）使用下载好的 repos 文件替换默认的 repos 文件

例如:用 CentOS7-Base- 163.repo 替换 CentOS-Base.repo

 [root@hadoop101 yum.repos.d]# mv CentOS7-Base-163.repo  CentOS-Base.repo  

**5**）清理旧缓存数据，缓存新数据

![文本框: [root@hadoop101 [root@hadoop101	yum.repos.d]#yum clean all yum.repos.d]#yum makecache  ](file:///C:/Users/Epiphany/AppData/Local/Temp/msohtmlclip1/01/clip_image005.gif)

yum makecache 就是把服务器的包信息下载到本地电脑缓存起来

**6**）测试

![文本框: [root@hadoop101 [root@hadoop101	yum.repos.d]# yum list | grep firefox ~]#yum -y install firefox  ](file:///C:/Users/Epiphany/AppData/Local/Temp/msohtmlclip1/01/clip_image006.gif)





# 65.克隆

如果要从别人那里打开它的虚拟机，只需要赋值它虚拟机里的文件，然后点击这里的打开即可

![image-20231127202127670](.\img\image-20231127202127670.png)

# 66.Shell概述

![image-20231127213131894](.\img\image-20231127213131894.png)

Shell：包在内核外面的一个壳，把我们外部操作的一些命令解释成内核可以执行的指令，起到的就是翻译官的作用

Shell是一个命令行解释器，它接收应用程序/用户命令，然后调用操作系统内核。

Linux里不光可以在控制台一句一句执行，也可以把很多命令串起来，直接写入到一个文件中，然后直接把这个文件交给Linux系统，让它直接去执行，但这个它也是一行一行去执行的。我们把这个可执行文件称之为脚本。

Shell还是一个功能相当强大的编程语言，易编写、易调试、灵活性强。

**1**）**Linux** 提供的 **Shell** 解析器有

![文本框: [atguigu@hadoop101 ~]$ cat /etc/shells /bin/sh /bin/bash /usr/bin/sh /usr/bin/bash /bin/tcsh /bin/csh ](.\img\clip_image001.gif)

> 最初的Shell版本它是来源于UNIX，最初的版本叫Bourne Shell，这个Shell版本它可以进行非常灵活的操作，只不过跟用户的交互就会稍微差点。
>
> 后来基于bourne Shell后来就发明出了bash。
>
> bash基于最前的shell就扩展出了很多功能，目前大部分的Linux发行版，默认的Shell其实都是bash Shell。
>
> 红帽系的几乎都是bash shell
>
> Debian，比如说Ubuntu，它默认是用的shell就是dash。
>
> 但其实它们都差不多，大同小异，就像不同的Linux发行版一样
>
> 在系统直接查看到当前默认的shell：
>
> - ls  -l /bin/ | grep bash，如图：默认的Shell解析器就是bash
>
>   ![image-20231127214256714](.\img\image-20231127214256714.png)
>
> - 第二种方式：echo $SHELL（大写的环境变量）
>
>   ![image-20231127214415422](.\img\image-20231127214415422.png)

# 67.Shell脚本入门

**2**）**bash** 和 **s****h** 的关系

![文本框: [atguigu@hadoop101 bin]$ ll | grep bash -rwxr-xr-x. 1 root root 941880 5 月  11 2016 bash lrwxrwxrwx. 1 root root     4 5 月  27 2017 sh -> bash ](.\img\clip_image002.gif)

**3**）Centos 默认的解析器是 bash

![文本框: [atguigu@hadoop101 bin]$ echo $SHELL /bin/bash ](.\img\clip_image003.gif)

第 **2** 章 **Shell** 脚本入门

**1**）脚本格式

> 在Shell解析的过程中，它对后缀名是没有要求的，只要它是一个可执行文件，里面是按照Shell标准去写的话，其实是什么后缀都无所谓，只不过约定俗成，一般加一个.sh作为后缀

脚本以#!/bin/bash 开头（指定解析器），有时候会看见#!/bin/sh，因为sh连接指向了bash，但一般都写成bash

**2**）第一个 Shell 脚本：helloworld.sh

（1）需求：创建一个 Shell 脚本，输出 helloworld

（2）案例实操：

```
[atguigu@hadoop101 shells]$ touch helloworld.sh
[atguigu@hadoop101 shells]$ vim helloworld.sh
```

在 helloworld.sh 中输入如下内容

```sh
# !/bin/bash
echo "helloworld"
```



（3）脚本的常用执行方式

第一种：采用bash 或 sh（因为sh软连接到了bash）+脚本的相对路径或绝对路径（不用赋予脚本+x 权限）

sh+脚本的相对路径

sh+脚本的绝对路径

bash+脚本的相对路径

bash+脚本的绝对路径

第二种：采用输入脚本的绝对路径或相对路径执行脚本（必须具有可执行权限+x）

①首先要赋予 helloworld.sh 脚本的+x 权限

②执行脚本

相对路径

绝对路径

不加.，Linux下会当做一个一个命令去执行

![image-20231201192621123](.\img\image-20231201192621123.png)

注意：第一种执行方法，本质是 bash 解析器帮你执行脚本，所以脚本本身不需要执行

权限。第二种执行方法，本质是脚本需要自己执行，所以需要执行权限。

【了解】第三种：在脚本的路径前加上“. ”或者 source

> ps：这里的 . 和./是不一样的，这里的点是一个命令

![image-20231201194135082](.\img\image-20231201194135082.png)



原因：

前两种方式都是在当前 shell 中打开一个子 shell 来执行脚本内容，当脚本内容结束，则 子 shell 关闭，回到父 shell 中。

第三种，也就是使用在脚本路径前加“. ”或者 source 的方式，可以使脚本内容在当前 shell 里执行，而无需打开子 shell！这也是为什么我们每次要修改完/etc/profile 文件以后，需要 source 一下的原因。

开子 shell 与不开子 shell 的区别就在于，环境变量的继承关系，如在子 shell 中设置的 当前变量，父 shell 是不可见的。



# 68.系统预定义变量

**1**）常用系统变量

$HOME 、$PWD 、$SHELL 、$USER 等

> 全局变量：父Shell访问子Shell都是可见的
>
> 局部变量：只针对当前的bash环境时有效的



**2**）案例实操

（1）查看系统变量的值

```
[atguigu@hadoop101 shells]$ echo $HOME
/home/atguigu
```



（2）显示当前 Shell 中所有变量：set

```
[atguigu@hadoop101 shells]$ set
BASH=/bin/bash
BASH_ALIASES= ()
BASH_ARGC= ()
BASH_ARGV= ()
```



# 69.自定义变量

**1**）基本语法

（1）定义变量：变量名=变量值，注意，=号前后不能有空格

（2）撤销变量：unset 变量名

（3）声明静态变量：readonly 变量，注意：不能 unset

**2**）变量定义规则

（1）变量名称可以由字母、数字和下划线组成，但是不能以数字开头，环境变量名建 议大写。

（2）**等号两侧不能有空格**

（3）在 bash 中，变量默认类型都是字符串类型，无法直接进行数值运算。

（4）变量的值如果有空格，需要使用双引号或单引号括起来。

**3**）案例实操

（1）定义变量 A

```
[atguigu@hadoop101 shells]$ A=5
[atguigu@hadoop101 shells]$ echo $A
```



（2）给变量 A 重新赋值
```
[atguigu@hadoop101 shells]$ A=8
[atguigu@hadoop101 shells]$ echo $A
```


（3）撤销变量 A
```
[atguigu@hadoop101 shells]$ unset A
[atguigu@hadoop101 shells]$ echo $A
```

（4）声明静态的变量 B=2 ，不能 unset

```
[atguigu@hadoop101 shells]$ readonly B=2
[atguigu@hadoop101 shells]$ echo $B
2
[atguigu@hadoop101 shells]$ B=9
-bash: B: readonly variable
```

（5）在 bash 中，变量默认类型都是字符串类型，无法直接进行数值运算
```
[atguigu@hadoop102 ~]$ C=1+2
[atguigu@hadoop102 ~]$ echo $C
1+2
```

（6）变量的值如果有空格，需要使用双引号或单引号括起来
```
[atguigu@hadoop102 ~]$ D=I love banzhang
-bash: world: command not found
[atguigu@hadoop102 ~]$ D="I love banzhang"
[atguigu@hadoop102 ~]$ echo $D
I love banzhang
```
（7）可把变量提升为全局环境变量，可供其他 Shell 程序使用

> 但如果在子shell里进行了更改，则只在子shell和子shell的子shell有效，在父shell是无效的。
>
> 就算在子shell更改export 变量名，父shell依旧不会改变
>
> PS：export后面无需加$

```
export 变量名
[atguigu@hadoop101 shells]$ vim helloworld.sh
```

在 helloworld.sh 文件中增加 echo $B
```
# !/bin/bash
echo "helloworld"
echo $B
```

发现并没有打印输出变量 B 的值。

```
[atguigu@hadoop101 shells]$ ./helloworld.sh
Helloworld
```

> 改进方法：使用.或者source去执行，或者将B提升为全局变量

```
[atguigu@hadoop101 shells]$ export B
[atguigu@hadoop101 shells]$ ./helloworld.sh
helloworld
2
```



> 如果想要把hello.sh当成一个命令来运行：
>
> ```
> # cp hello.sh /bin/ 
> hello.sh
> ```
>
> 但是一般/bin存放的都是系统的命令，最好不要去更改
>
> 当前我们找的系统目录的路径它是可以配置的，这种配置通过PATH来设置。
>
> 一下这些目录都是可以直接执行的
>
> ```
> [root@centos test3]# echo $PATH
> /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
> ```

# 71.特殊变量

## **$n**（位置参数）

**1**）基本语法

$n   （功能描述：n 为数字，$0 代表该脚本名称，$1-$9 代表第一到第九个参数，十以上的参数，十以上的参数需要用大括号包含，如${ 10}）

**2**）案例实操
> 单引号：把里面的内容原封不动的输出
> $0比较特殊，它是我们的脚本名
> 如果不想让它输出路径，只想获得最后的脚本名称：basename
```
[atguigu@hadoop101 shells]$ touch parameter.sh
[atguigu@hadoop101 shells]$ vim parameter.sh
# !/bin/bash
echo '==========$n========== ' 
echo $0
echo $1
echo $2
[atguigu@hadoop101 shells]$ chmod 777 parameter.sh
[atguigu@hadoop101 shells]$ ./parameter.sh cls xz
==========$n==========
./parameter.sh
cls
xz
```

## **$#**

**1**）基本语法

$#   （功能描述：获取所有输入参数个数，常用于循环,判断参数的个数是否正确以及 加强脚本的健壮性）。

**2**）案例实操
```
[atguigu@hadoop101 shells]$ vim parameter.sh
# !/bin/bash
echo '==========$n========== '
echo $0
echo $1
echo $2
echo '==========$#========== '
echo $#
[atguigu@hadoop101 shells]$ chmod 777 parameter.sh
[atguigu@hadoop101 shells]$ ./parameter.sh cls xz
==========$n==========
./parameter.sh
cls
xz
==========$#==========
2
```

## **$\*** 、**$@**

**1**）基本语法

$*   （功能描述：这个变量代表命令行中所有的参数，$*把所有的参数看成一个整体） 

$@  （功能描述：这个变量也代表命令行中所有的参数，不过$@把每个参数区分对待，可以理解为得到的是数组或集合）

**2**）案例实操
```
[atguigu@hadoop101 shells]$ vim parameter.sh
# !/bin/bash
echo '==========$n========== '
echo $0
echo $1
echo $2
echo '==========$#========== '
echo $#
echo '==========$*========== '
echo $*
echo '==========$@========== '
echo $@
[atguigu@hadoop101 shells]$ ./parameter.sh a b c d e f g
==========$n==========
./parameter.sh
a
b
==========$#==========
7
==========$*==========
a b c d e f g
==========$@==========
a b c d e f g
```

**$**

**1**）基本语法

$？  （功能描述：最后一次执行的命令的返回状态。如果这个变量的值为 0 ，证明上一 个命令正确执行；如果这个变量的值为非 0（具体是哪个数，由命令自己来决定），则证明 上一个命令执行不正确了。）

**2**）案例实操

判断 helloworld.sh 脚本是否正确执行
```
[atguigu@hadoop101 shells]$ ./helloworld.sh
hello world
[atguigu@hadoop101 shells]$ echo $?
0
```

# 72.运算符
1 + 2分别当做expr的三个参数传进去
> 这里注意，如果是乘法，不能直接写*，因为在Linux里，*有通配符的意思，还可以表示当前所有的参数
> 此时就需要做一个转义：\*
> 所以这种方式太麻烦了！！！
```
expr 1 + 2
```

**1**）基本语法

“$((运算式))” 或 “$[运算式]”，如果需要输出，则需要自己echo

**2**）案例实操：

计算（2+3）* 4 的值
```
[atguigu@hadoop101 shells]# S=$ [ (2+3)*4]
[atguigu@hadoop101 shells]# echo $S
```



# 73.条件判断

**1**）基本语法

（1）test condition

（2）[  condition  ] （注意 condition 前后要有空格）

eg：第二种写法就可能会把$a=hello直接看做一个值，此时就算为假，也会返回0

```
[ $a = hello ]
[ $a=hello ]
```

判断不等于：!=



注意：条件非空即为 true ，[ atguigu ]返回 true ，[  ] 返回 false。

**2**）常用判断条件

（1）两个整数之间比较

-eq 等于（ equal）

-lt 小于（less than）

-gt 大于（greater than）

-ne 不等于（not equal）

-le 小于等于（less equal）

-ge 大于等于（greater equal）



注：如果是字符串之间的比较 ，用等号“= ”判断相等；用“ != ”判断不等。

（2）按照文件权限进行判断

-r 有读的权限（read）

-w 有写的权限（write）

-x 有执行的权限（ execute）

（3）按照文件类型进行判断

-e 文件存在（existence）

-f 文件存在并且是一个常规的文件（file）

-d 文件存在并且是一个目录（directory）

**3**）案例实操

（1）23 是否大于等于 22
```
[atguigu@hadoop101 shells]$ [ 23 -ge 22 ]
[atguigu@hadoop101 shells]$ echo $?
0
```

（2）helloworld.sh 是否具有写权限
```
[atguigu@hadoop101 shells]$ [ -w helloworld.sh ]
[atguigu@hadoop101 shells]$ echo $?
0
```

（3）/home/atguigu/cls.txt 目录中的文件是否存在

```
[atguigu@hadoop101 shells]$ [ -e /home/atguigu/cls.txt ]
[atguigu@hadoop101 shells]$ echo $?
1
```



（4）多条件判断（&& 表示前一条命令执行成功时，才执行后一条命令，|| 表示上一条命令执行失败后，才执行下一条命令）

> 中括号里只要有东西，它的返回值就为真，所以[ atguigu ]的返回值为真

```
[atguigu@hadoop101 ~]$ [ atguigu ] && echo OK | | echo notOK
OK
[atguigu@hadoop101 shells]$ [ ] && echo OK | | echo notOK
notOK
```



# 74.流程控制（重点）

**if** 判断

**1**）基本语法

（1）单分支

> 分号表示在一行里面出现了，相当于分开的两部分命令的实现

```
if [ 条件判断式 ];then
程序
fi

等价于

if [ 条件判断式 ]
then
程序
fi
```

或者

```
if  [ 条件判断式 ]
then
程序
fi
```

> 这里有个小技巧：
>
> > 如果直接这样写，并且执行的时候没有传参数，此时就会报错
>
> ```
> #!/bin/bash
> if [ $1 = atguigu]
> then
>         echo "welcom atguigu"
> fi
> ```
>
> > 一般会修改为：
>
> ```
> #!/bin/bash
> if [ "$1"x = "atguigu"x ]
> then
>         echo "welcom atguigu"
> fi
> ```

如果需要写成多条件判断

```
if [ $a -gt 18 ] && [ $a -lt 35 ]; then echo "OK"; fi
```

可以简写为：

-a ：逻辑与关机

-o：逻辑或关系

```
if [ $a -gt 18 -a $a -lt 35 ]; then echo "OK"; fi
```



75.（2）多分支

```
if [ 条件判断式 ]
then
程序
elif [ 条件判断式 ]
then
程序
else
程序
fi
```



# 76.case语句

**1**）基本语法

> "值 1"）：引号可加可不加，但是必须以右括号结束

```
case $变量名 in
"值 1"）
如果变量的值等于值 1，则执行程序 1
;;
"值 2"）
如果变量的值等于值 2，则执行程序 2
;;
…省略其他分支…
*）
如果变量的值都不是以上的值，则执行此程序
;;
esac
```

注意事项：

（1）case 行尾必须为单词“in ”，每一个模式匹配必须以右括号“） ”结束。

（2）双分号“**;;**”表示命令序列结束，相当于java 中的 break。

（3）最后的“*） ”表示默认模式，相当于java 中的 default。

**2**）案例实操

输入一个数字，如果是 1 ，则输出banzhang ，如果是 2 ，则输出 cls ，如果是其它，输出

renyao。
```
[atguigu@hadoop101 shells]$ touch case.sh
[atguigu@hadoop101 shells]$ vim case.sh
!/bin/bash
case $1 in
"1")
echo "banzhang"
;;
"2")
echo "cls"
;;
*)
```

# 77.for循环

**1**）基本语法 **1**

```
for ( ( 初始值;循环控制条件;变量变化 ))
do
程序
done
```

**2**）案例实操

从 1 加到 100

> Linux里面大于小于号不能乱用，因为它有重定向的意思，但是在这里能用是因为它这里有(())双小括号！！！
>
> if (($a > 2));then echo OK; else echo not OK; fi 也是可以的

```
[atguigu@hadoop101 shells]$ touch for1.sh
[atguigu@hadoop101 shells]$ vim for1.sh
# !/bin/bash
sum=0
for ( (i=0;i<=100;i++))

do
done
echo	sum=$ [$sum+$i]
$sum


[atguigu@hadoop101
[atguigu@hadoop101
5050	shells]$
shells]$	chmod 777
./for1.sh	for1.sh
```

**3**）基本语法 **2**

> in：在。。。匹配模式下执行对应的分支

```
for 变量 in 值 1 值 2 值 3…
do
程序
done
```

eg：

```
[root@centos ~]# for os in linux windows macos; do echo $os; done
linux
windows
macos
```

Linux Shell里面有一个内部运算符

> {  }里面类似于跟着一个集合类型，相当于java里的增强for循环

```
[root@centos ~]# for i in {1..10}; do sum=$[$sum+$i]; done; echo $sum
55
```




（2） 比较$*和$@区别

$*和$@都表示传递给函数或脚本的所有参数，不被双引号“”包含时，都以$1 $2 … $n

的形式输出所有参数。
```
[atguigu@hadoop101 shells]$ touch for3.sh
[atguigu@hadoop101 shells]$ vim for3.sh
# !/bin/bash
echo '=============$*============= '
for i in $*
do
echo "ban zhang love $i"
done
echo '=============$@============= '
for j in $@
do
echo "ban zhang love $j"
done
[atguigu@hadoop101 shells]$ chmod 777 for3.sh
[atguigu@hadoop101 shells]$ ./for3.sh cls mly wls
=============$*=============
banzhang love cls
banzhang love mly
banzhang love wls
=============$@=============
banzhang love cls
banzhang love mly
banzhang love wls
```

当它们被双引号“”包含时，$*会将所有的参数作为一个整体， 以“$1 $2 …$n”的形式输

出所有参数；$@会将各个参数分开，以“$1” “$2” …“$n”的形式输出所有参数。
```
[atguigu@hadoop101 shells]$ vim for4.sh
# !/bin/bash
echo '=============$*============= '
for i in "$*"
#$*中的所有参数看成是一个整体，所以这个 for 循环只会循环一次
do
echo "ban zhang love $i"
done
echo '=============$@============= '
for j in "$@"
#$@中的每个参数都看成是独立的，所以“$@”中有几个参数，就会循环几次
do
echo "ban zhang love $j"
done
[atguigu@hadoop101 shells]$ chmod 777 for4.sh
[atguigu@hadoop101 shells]$ ./for4.sh cls mly wls
=============$*=============
banzhang love cls mly wls
=============$@=============
banzhang love cls
banzhang love mly
banzhang love wls
```
# 77.**while** 循环

**1**）基本语法

```
while [ 条件判断式 ]
do
程序
done
```

**2**）案例实操

从 1 加到 100
```
#!/bin/bash
i=1
while [ $i -le $1 ]
do
        sum=$[ $sum + $i ]
        i=$[ $i + 1 ]
done
echo $sum
```

使用let后，后面的语法就可以像其他编程语言一样写了，但是+=两边依旧不能空格

```
#!/bin/bash
i=1
while [ $i -le $1 ]
do
        let sum+=i
        let i++
done
echo $sum
```



# 79.read 读取控制台输入

**1**）基本语法

read  (选项)  (参数)

①选项：

-p ：指定读取值时的提示符；

-t：指定读取值时等待的时间（秒）如果-t 不加表示一直等待

②参数

变量：指定读取值的变量名

**2**）案例实操

提示 7 秒内，读取控制台输入的名称

```
read -t 10 -p "请输入您的芳名：" name
echo "welcom,  $name"
```

# 80.函数

> bash脚本与函数的区别：
>
> 1. bash脚本没有返回值
>
> 2. 脚本的调用过程太笨重了。
>
> 3. 从某种意义上来讲，函数就是一个缩小版的脚本。
>
>    脚本就是一个笨重化的函数。

系统函数

> 从编程语言上来讲叫函数，从Linux Shell本质来讲，就是系统命名。
>
> 分为内部命令和外部命令。
>
> 外部命令就是在shell之外，我们可以去安装，放到usr/bin下面，我们就可以直接去使用这些命令。
> 所以有时候这些功能复杂的外部命令我们就会把它叫做工具。
>
> 所以本质上函数、脚本、命令、工具都是能模块化的实现我们某个特定需求的代码集合。只是调用方式不同。

> 当我们产生大量的日志数据的时候，我们就会把一些日志数据放在特定的文件夹里面，文件或者文件夹的命名往往就会带有一个时间信息或者时间戳信息，表示当前的文件是哪个时间点产生的。

```
[root@centos code]# date
Sat Dec  2 14:11:48 CST 2023
//显示当前的时间戳
[root@centos code]# date +%s
1701497513
```

命令替换：把expr所产生的值赋给某个变量

```
$(expr 1 + 2)
```

我们在脚本里使用系统函数的时候就需要使用到命令替换

> 从函数的角度讲，命令替换就是调用了一下系统的函数，后面`+%s`就相当于给它传入的实参，这个函数的到的返回结果，用$包起来，将返回值作为一个字符串的拼接，得到了当前的filename的文件组成。

```
filename="$1"_log_$(date +%s)
```





## basename

**1**）基本语法

basename [string / pathname] [suffix]       （功能描述：basename 命令会删掉所有的前缀包括最后一个（‘/’）字符，然后将字符串显示出来。其实就是字符串的截取）

basename 可以理解为取路径里的文件名称

> 区分于$0，$0获取到的是有路径的文件名称



**2**）案例实操

截取该/root/code/cmd_test.sh路径的文件名称。
```
[root@centos code]# basename /root/code/cmd_test.sh
cmd_test.sh
```

选项：

suffix 为后缀，如果 suffix 被指定了，basename 会将 pathname 或 string 中的 suffix 去掉。

```
[root@centos code]# basename /root/code/cmd_test.sh .sh
cmd_test
```

得到当前的脚本名称，并且不带后缀

```
#!/bin/bash
echo script name :$(basename $0 .sh)
```





## dirname

**1**）基本语法

dirname 文件绝对路径   （功能描述：从给定的包含绝对路径的文件名中去除文件名

（非目录的部分），然后返回剩下的路径（ 目录的部分））

dirname 可以理解为取文件路径的绝对路径名称

**2**）案例实操

> dirname其实就是对字符串做的一个剪切

```
[root@centos code]# dirname /root/code/parameter_for_test.sh
/root/code
[root@centos code]# dirname /root/code/ajdfajlkfj
/root/code
```



### 获取文件的路径

> 如果想要获取一个文件的路径，一般都应该获取绝对路径，而不是相对路径，因为相对路径在不同路径下执行就会导致进入的目录不一样。所以不建议直接在后面加$0。

```
echo script path：$(dirname $0)
```

建议做法：首先直接进入到当前的工作目录，然后使用pwd获取到当前工作目录的绝对路径

```
cd $(dirname $0)
echo $(pwd)
```

简写：

```
echo $(cd $(dirname $0) ; pwd)
```





# 81.自定义函数

**1**）基本语法

> [ ]里面的部分是可选的。
>
> 当函数名后面的( )省略之后，自定义函数里，形参不需要定义。默认的形参就是$1 $2，即位置参数，和脚本是一样的。
>
> 返回值直接使用`$?`就能直接获取

```
[ function ] funname[()]
{

	Action;
	[return int;]
}
```


**2**）经验技巧

（1）必须在调用函数地方之前，先声明函数，shell 脚本是逐行运行。不会像其它语言一 样先编译。

（2）函数返回值，只能通过$?系统变量获得，可以显示加：return 返回，如果不加，将以函数体里最后一条命令运行结果，作为返回值。return 后跟数值 n(0-255)，0表示成功。

**3**）案例实操

计算两个输入参数的和。
```
#!/bin/bash

function add(){
  s=$[$1 + $2]
  echo "和："$s
}

# 调用执行
read -p "请输入第一个整数：" a
read -p "请输入第二个整数：" b

#调用函数，将参数传入
add $a $b
```

如果想要获取返回值

> 以下这种方式，由于$?出来的结果只能在0~255，当两数相加结果很大时，执行不会报错，但是出来的结果是错的

```
#!/bin/bash

function add(){
  s=$[$1 + $2]
  return $s
}

# 调用执行
read -p "请输入第一个整数：" a
read -p "请输入第二个整数：" b

#调用函数，将参数传入
add $a $b
echo $?
```

> 正确写法：使用命令替换

```
#!/bin/bash

function add(){
  s=$[$1 + $2]
  echo $s
}

# 调用执行
read -p "请输入第一个整数：" a
read -p "请输入第二个整数：" b

#做命令替换
sum=$(add $a $b)
echo "和："$sum
echo "和的平方："$[$sum * $sum]
```



# 82.归档文件

实际生产应用中，往往需要对重要数据进行归档备份。

需求：实现一个每天对指定目录归档备份的脚本，输入一个目录名称（末尾不带/）， 将目录下所有文件按天归档保存，并将归档日期附加在归档文件名上，放在/root/archive 下。

这里用到了归档命令：tar

后面可以加上-c 选项表示归档，加上-z 选项表示同时进行压缩，得到的文件后缀名 为.tar.gz。

脚本实现如下：

 ```
#!/bin/bash
# 首先判断输入参数个数是否为1
if [ $# -ne 1 ]
then
        echo "参数个数错误！应该输入一个参数，作为归档目录名"
        exit
fi

# 从参数中获取目录名称
if [ -d $1 ]
then
        echo
else
        echo
        echo "目录不存在！"
        echo
        exit
fi

DIR_NAME=$(basename $1)
DIR_PATH=$(cd $(dirname $1) ; pwd)

# 获取当前日期。%y%m%d：年月日
DATE=$(date +%y%m%d)

# 定义生成的归档文件名称
FILE=archive_${DIR_NAME}_$DATE.tar.gz
DEST=/root/archive/$FILE

# 开始归档目录文件
echo "开始归档..."
echo

tar -zcvf $DEST $DIR_PATH/$DIR_NAME

if [ $? -eq  0 ]
then
        echo "归档成功"
        echo "归档文件为：$DEST"
        echo
else
        echo "归档出现问题"
fi

exit
 ```

设置定时任务：

查看定时任务：

```
crontab -l
```

crontab  -e做编辑：

分钟数 小时数：0和2就是表示凌晨的两点整。

天数，月数，星期几，*就表示随意。

最后跟的是执行的是哪个脚本，后面还有一个参数，即脚本的绝对路径

```
0 2 * * * /root/code/daily_archive.sh /root/code
```

每隔六分钟

```
*/6
```

在第1,2,3分钟执行

```
1,2,3
```

第2-3分钟执行

```
2-3
```





# 83. 正则表达式入门

正则表达式使用单个字符串来描述、匹配一系列符合某个语法规则的字符串。在很多文 本编辑器里，正则表达式通常被用来检索、替换那些符合某个模式的文本。在 Linux 中，grep， sed ，awk 等文本处理工具都支持通过正则表达式进行模式匹配。

**常规匹配**

一串不包含特殊字符的正则表达式匹配它自己，例如：

```
[atguigu@hadoop101 shells]$ cat /etc/passwd | grep atguigu
```

就会匹配所有包含 atguigu 的行。

**常用特殊字符**

**1**）特殊字符：**^**

^ 匹配一行的开头，例如：

会匹配出所有以 a 开头的行

```
[root@centos code]# cat /etc/passwd | grep ^a
adm:x:3:4:adm:/var/adm:/sbin/nologin
abrt:x:173:173::/etc/abrt:/sbin/nologin
avahi:x:70:70:Avahi mDNS/DNS-SD Stack:/var/run/avahi-daemon:/sbin/nologin
apache:x:48:48:Apache:/usr/share/httpd:/sbin/nologin
```



**2**）特殊字符：**$**

$应该放到最后

$ 匹配一行的结束，例如

```
[root@centos code]# cat /etc/passwd | grep bash$
root:x:0:0:root:/root:/bin/bash
itheima:x:1000:1000:itheima:/home/itheima:/bin/bash
test2:x:1001:1001::/home/test2:/bin/bash
test4:x:1002:1002::/home/test4:/bin/bash
```

会匹配出所有以 bash 结尾的行

思考：**^$** 匹配什么？ 匹配的是空行

eg：

以下匹配的就是以bash开头和结尾的，即一行只是bash就可以匹配到

```
cat /etc/passwd | grep ^bash$
```

加一个 -n 参数，显示当前行的行号

```
[root@centos code]# cat daily_archive.sh | grep -n ^$
8:
19:
22:
25:
29:
33:
35:
44:
46:
```





**3**）特殊字符：**.**

. 匹配一个任意的字符，即通配符，例如

```
[root@centos code]# cat /etc/passwd | grep r..t
root:x:0:0:root:/root:/bin/bash
operator:x:11:0:operator:/root:/sbin/nologin
ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin

[root@centos code]# cat /etc/passwd | grep r.t
operator:x:11:0:operator:/root:/sbin/nologin
sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin

[root@centos code]# cat /etc/passwd | grep r...t
rtkit:x:172:172:RealtimeKit:/proc:/sbin/nologin
unbound:x:994:989:Unbound DNS resolver:/etc/unbound:/sbin/nologin
apache:x:48:48:Apache:/usr/share/httpd:/sbin/nologin
gitlab-www:x:986:979::/var/opt/gitlab/nginx:/bin/false
git:x:985:978::/var/opt/gitlab:/bin/sh
gitlab-redis:x:984:977::/var/opt/gitlab/redis:/bin/false
gitlab-psql:x:983:976::/var/opt/gitlab/postgresql:/bin/sh
gitlab-prometheus:x:982:975::/var/opt/gitlab/prometheus:/bin/sh
```

会匹配包含 rabt,rbbt,rxdt,root 等的所有行

**4**）特殊字符：*****

\* 不单独使用，他和上一个字符连用，表示匹配上一个字符 0 次或多次，即出现任意次。例如

```
[root@centos code]# cat /etc/passwd | grep ro*t
root:x:0:0:root:/root:/bin/bash
operator:x:11:0:operator:/root:/sbin/nologin
abrt:x:173:173::/etc/abrt:/sbin/nologin
rtkit:x:172:172:RealtimeKit:/proc:/sbin/nologin
```

会匹配 rt, rot, root, rooot, roooot 等所有行



思考：.* 匹配什么？

任意一个字符出现任意次，就是随便匹配一个字符串都可以

用途：匹配一个以r开头，以bash结尾的行

```
[root@centos code]# cat /etc/passwd | grep ^r.*bash$
root:x:0:0:root:/root:/bin/bash
```

中间加一个bin

```
[root@centos code]# cat /etc/passwd | grep ^r.*bin.*bash$
root:x:0:0:root:/root:/bin/bash
```



# 84.

**5**）字符区间（中括号）：**[** **]**

[ ] 表示匹配某个范围内的一个字符，例如

[6,8]------ 匹配 6 或者 8

[0-9]------ 匹配一个 0-9 的数字

[0-9]*------ 匹配任意长度的数字字符串

[a-z]------ 匹配一个 a-z 之间的字符

[a-z]* ------ 匹配任意长度的字母字符串

[a-c, e-f]- 匹配 a-c 或者 e-f 之间的任意字符

```
[root@centos code]# cat /etc/passwd | grep r[a,b]t
operator:x:11:0:operator:/root:/sbin/nologin
sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin
```

也可以不加逗号

```
[root@centos code]# cat /etc/passwd | grep r[ab]t
operator:x:11:0:operator:/root:/sbin/nologin
sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin
```

```
[atguigu@hadoop101 shells]$ cat /etc/passwd | grep r [a,b,c]*t
```

会匹配 rt,rat, rbt, rabt, rbact,rabccbaaacbt 等等所有行



匹配r和t之间有任意字符串的内容

```
[root@centos code]# cat /etc/passwd | grep r[a-z]*t
root:x:0:0:root:/root:/bin/bash
operator:x:11:0:operator:/root:/sbin/nologin
libstoragemgmt:x:998:995:daemon account for libstoragemgmt:/var/run/lsm:/sbin/nologin
abrt:x:173:173::/etc/abrt:/sbin/nologin
rtkit:x:172:172:RealtimeKit:/proc:/sbin/nologin
setroubleshoot:x:990:984::/var/lib/setroubleshoot:/sbin/nologin
sshd:x:74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin
gitlab-prometheus:x:982:975::/var/opt/gitlab/prometheus:/bin/sh
```





**6**）特殊字符： \

\ 表示转义，并不会单独使用。由于所有特殊字符都有其特定匹配模式，当我们想匹配 某一特殊字符本身时（例如，我想找出所有包含 '$' 的行），就会碰到困难。此时我们就要

将转义字符和特殊字符连用，来表示特殊字符本身，例如

```
[root@centos code]# cat daily_archive.sh | grep '\$'
if [ $# -ne 1 ]
if [ -d $1 ]
DIR_NAME=$(basename $1)
DIR_PATH=$(cd $(dirname $1) ; pwd)
DATE=$(date +%y%m%d)
FILE=archive_${DIR_NAME}_$DATE.tar.gz
DEST=/root/archive/$FILE
tar -zcvf $DEST $DIR_PATH/$DIR_NAME
if [ $? -eq  0 ]
        echo "归档文件为：$DEST"
```

如果前面还有一个正斜杠/，直接加上就行，正斜杠不需要转义

```
[root@centos code]# cat daily_archive.sh | grep '/\$'
DEST=/root/archive/$FILE
tar -zcvf $DEST $DIR_PATH/$DIR_NAME
```



就会匹配所有包含 a$b 的行。注意需要使用单引号将表达式引起来。

```

```

 

扩展的正则规则：即a要出现两次

```
a{2}
```



扩展：用正则去匹配手机号

> -E表示支持扩展的正则表达式

```
[root@centos ~]# echo "13586258254" | grep -E ^1[345678][0-9]{9}
13586258254
```





# 85.文本处理工具

## **cut**

cut 的工作就是“剪” ，具体的说就是在文件中负责剪切数据用的。cut 命令从文件的每 一行剪切字节、字符和字段并将这些字节、字符和字段输出。

**1**）基本用法

cut  [选项参数]  filename

说明：默认分隔符是制表符

**2**）选项参数说明

| 选项参数 | 功能                                            |
| -------- | ----------------------------------------------- |
| -f       | 列号，提取第几列                                |
| -d       | 分隔符，按照指定分隔符分割列，默认是制表符“\t”  |
| -c       | 按字符进行切割  后加加 n 表示取第几列 比如 -c 1 |

**3**）案例实操

（1）数据准备

```
[atguigu@hadoop101 shells]$ touch cut.txt
[atguigu@hadoop101 shells]$ vim cut.txt
dong shen
guan zhen
wo wo
lai lai
le le
```

（2）切割 cut.txt 第一列

```
[root@centos code]# cut -d " " -f 1 cut.txt
dong
guan
wo
lai
le
```

（3）切割 cut.txt 第一、二列

```
[root@centos code]# cut -d " " -f 1,2 cut.txt
dong shen
guan zhen
wo wo
lai lai
le le
```

```
[root@centos code]# cat /etc/passwd | grep bash$ | cut -d ":" -f 1,6,7
root:/root:/bin/bash
itheima:/home/itheima:/bin/bash
test2:/home/test2:/bin/bash
test4:/home/test4:/bin/bash
```

从第6列开始，一直到最后

```
[root@centos code]# cat /etc/passwd | grep bash$ | cut -d ":" -f 6-
/root:/bin/bash
/home/itheima:/bin/bash
/home/test2:/bin/bash
/home/test4:/bin/bash
```

第6列之前

```
[root@centos code]# cat /etc/passwd | grep bash$ | cut -d ":" -f -6
root:x:0:0:root:/root
itheima:x:1000:1000:itheima:/home/itheima
test2:x:1001:1001::/home/test2
test4:x:1002:1002::/home/test4
```

（6）切割 ifconfig 后打印的 IP 地址

```
[root@centos code]# ifconfig ens33 | grep netmask | cut -d " " -f 10
192.168.88.130
```

（7）得到所有的IP地址

```
[root@centos code]# ifconfig | grep netmask | cut -d " " -f 10
172.18.0.1
172.17.0.1
192.168.88.130
127.0.0.1
192.168.122.1
```



# 86.awk

> 这三个字母就是它的三位创始人的首字母。
>
> gawk和awk其实是一个工具。awk是初始的unix环境下的标准的工具实现。gawk就是awk的GNU组织里具体的实现，总体来讲，它就有更多的扩展
>
> 在cent7里面，可以看见awk本身是一个软连接，它指向了gawk。
>
> 所以我们使用awk，本质上使用的就是gawk
>
> ```
> [root@centos code]# which awk
> /usr/bin/awk
> 
> [root@centos code]# ll /usr/bin | grep awk
> lrwxrwxrwx.   1 root root           4 Oct  6 13:34 awk -> gawk
> -rwxr-xr-x.   1 root root      514168 Jun 29  2017 dgawk
> -rwxr-xr-x.   1 root root      428584 Jun 29  2017 gawk
> -rwxr-xr-x.   1 root root        3188 Jun 29  2017 igawk
> -rwxr-xr-x.   1 root root      428672 Jun 29  2017 pgawk
> ```
>
> 

一个强大的文本分析工具，把文件逐行的读入，以空格为默认分隔符将每行切片，切开 的部分再进行分析处理。

**1**）基本用法

awk  [选项参数]  ‘/pattern1/{action1}  /pattern2/{action2}... ’ filename 

> 也可以使用管道，filename就可以不要了

pattern：表示 awk 在数据中查找的内容，就是匹配模式

action：在找到匹配内容时所执行的一系列命令

**2**）选项参数说明

| 选项参数 | 功能                 |
| -------- | -------------------- |
| -F       | 指定输入文件分隔符   |
| -v       | 赋值一个用户定义变量 |

**3**）案例实操

（1）数据准备

```
[atguigu@hadoop101 shells]$ sudo cp /etc/passwd ./
passwd 数据的含义
用户名 :密码(加密过后的):用户 id:组 id:注释 :用户家目录 :shell 解析器
```

（2）搜索 passwd 文件以 root 关键字开头的所有行，并输出该行的第 7 列。

```

```

（3）搜索 passwd 文件以 root 关键字开头的所有行，并输出该行的第 1 列和第 7 列，

中间以“ ， ”号分割。

```

```

注意：只有匹配了 pattern 的行才会执行 action。

（4）只显示/etc/passwd 的第一列和第七列，以逗号分割，且在所有行前面添加列名 user，

shell 在最后一行添加"dahaige ，/bin/zuishuai"。

```

```

注意：BEGIN 在所有数据读取行之前执行；END 在所有数据执行之后执行。 更多 Java –大数据 –前端 –python 人工智能资料下载，可百度访问： 尚硅谷官网



```

```



 

（5）将 passwd 文件中的用户 id 增加数值 1 并输出

```

```

**4**）**a****w****k** 的内置变量

 

| 变量     | 说明                                   |
| -------- | -------------------------------------- |
| FILENAME | 文件名                                 |
| NR       | 已读的记录数（行号）                   |
| NF       | 浏览记录的域的个数（切割后，列的个数） |

**5**）案例实操

（1）统计 passwd 文件名，每行的行号，每行的列数

```

```

（2）查询 ifconfig 命令输出结果中的空行所在的行号

```

```

（3）切割 IP

```

```



**11.2**  发送消息

我们可以利用 Linux 自带的mesg 和 write 工具，向其它用户发送消息。

需求：实现一个向某个用户快速发送消息的脚本，输入用户名作为第一个参数，后面直 接跟要发送的消息。脚本需要检测用户是否登录在系统中、是否打开消息功能，以及当前发 送消息是否为空。

脚本实现如下：

 

 

```

```



 

 

















